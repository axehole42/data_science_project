<!DOCTYPE html>
<!-- saved from url=(0100)https://medium.com/@ml.enesguler/understanding-xgboost-from-basics-to-advanced-insights-d88536d87038 -->
<html lang="en" data-rh="lang"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="origin-trial" content="A7vZI3v+Gz7JfuRolKNM4Aff6zaGuT7X0mf3wtoZTnKv6497cVMnhy03KDqX7kBz/q/iidW7srW31oQbBt4VhgoAAACUeyJvcmlnaW4iOiJodHRwczovL3d3dy5nb29nbGUuY29tOjQ0MyIsImZlYXR1cmUiOiJEaXNhYmxlVGhpcmRQYXJ0eVN0b3JhZ2VQYXJ0aXRpb25pbmczIiwiZXhwaXJ5IjoxNzU3OTgwODAwLCJpc1N1YmRvbWFpbiI6dHJ1ZSwiaXNUaGlyZFBhcnR5Ijp0cnVlfQ=="><title>XGBoost Guide: From Basics to Advanced Optimization in Python ML | Medium</title><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" name="apple-itunes-app" content="app-id=828256236, app-argument=/@ml.enesguler/understanding-xgboost-from-basics-to-advanced-insights-d88536d87038, affiliate-data=pt=698524&amp;ct=smart_app_banner&amp;mt=8"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-11-06T12:36:52.833Z"><meta data-rh="true" name="title" content="XGBoost Guide: From Basics to Advanced Optimization in Python ML | Medium"><meta data-rh="true" property="og:title" content="Understanding XGBoost: From Basics to Advanced Insights"><meta data-rh="true" property="al:android:url" content="medium://p/d88536d87038"><meta data-rh="true" property="al:ios:url" content="medium://p/d88536d87038"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="Unlock the power of XGBoost, the leading gradient boosting algorithm. Learn its core principles, from decision trees to regularization, and implement it effectively in Python for superior model performance."><meta data-rh="true" property="og:description" content="Explore XGBoost from fundamentals to advanced techniques, including hyperparameter tuning, interpretability, and practical applications."><meta data-rh="true" property="og:url" content="https://medium.com/@ml.enesguler/understanding-xgboost-from-basics-to-advanced-insights-d88536d87038"><meta data-rh="true" property="al:web:url" content="https://medium.com/@ml.enesguler/understanding-xgboost-from-basics-to-advanced-insights-d88536d87038"><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:1024/1*y0Zpd2U2nGIPmha5XniRgw.png"><meta data-rh="true" property="article:author" content="https://medium.com/@ml.enesguler"><meta data-rh="true" name="author" content="Enes Güler"><meta data-rh="true" name="robots" content="index,noarchive,follow,max-image-preview:large"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" property="twitter:title" content="Understanding XGBoost: From Basics to Advanced Insights"><meta data-rh="true" name="twitter:site" content="@Medium"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/d88536d87038"><meta data-rh="true" property="twitter:description" content="Explore XGBoost from fundamentals to advanced techniques, including hyperparameter tuning, interpretability, and practical applications."><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:1024/1*y0Zpd2U2nGIPmha5XniRgw.png"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="twitter:label1" content="Reading time"><meta data-rh="true" name="twitter:data1" content="17 min read"><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://medium.com/osd.xml"><link data-rh="true" rel="preconnect" href="https://glyph.medium.com/" crossorigin=""><link data-rh="true" rel="manifest" href="https://medium.com/manifest.json"><link data-rh="true" rel="preconnect" href="https://www.google.com/"><link data-rh="true" rel="preconnect" href="https://www.gstatic.com/" crossorigin=""><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/unbound.css"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/unbound.css"><link data-rh="true" rel="author" href="https://medium.com/@ml.enesguler"><link data-rh="true" rel="canonical" href="https://medium.com/@ml.enesguler/xgboost-basics-to-advanced-guide"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/d88536d87038"><script type="text/javascript" async="" charset="utf-8" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/recaptcha__de.js.Download" crossorigin="anonymous" integrity="sha384-jsehgnx3ppwloqfSKmiqpw/vc0Ym64b6pD4DdIcQa3EBFsRk2uai0sLapw9qHvBO"></script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@id":"https://medium.com/@ml.enesguler/xgboost-basics-to-advanced-guide","@type":"SocialMediaPosting","image":["https://miro.medium.com/1*y0Zpd2U2nGIPmha5XniRgw.png"],"url":"https://medium.com/@ml.enesguler/xgboost-basics-to-advanced-guide","dateCreated":"2025-09-27T07:25:24Z","datePublished":"2025-09-27T07:25:24Z","dateModified":"2025-11-06T12:36:52Z","headline":"Understanding XGBoost: From Basics to Advanced Insights","name":"Understanding XGBoost: From Basics to Advanced Insights","description":"Unlock the power of XGBoost, the leading gradient boosting algorithm. Learn its core principles, from decision trees to regularization, and implement it effectively in Python for superior model performance.","identifier":"d88536d87038","author":{"@context":"https://schema.org","@id":"https://medium.com/@ml.enesguler","@type":"Person","identifier":"ml.enesguler","name":"Enes Güler","url":"https://medium.com/@ml.enesguler"},"creator":{"@context":"https://schema.org","@id":"https://medium.com/@ml.enesguler","@type":"Person","identifier":"ml.enesguler","name":"Enes Güler","url":"https://medium.com/@ml.enesguler"},"publisher":{"@context":"https://schema.org","@type":"Organization","@id":"https://medium.com","name":"Medium","url":"https://medium.com","logo":{"@type":"ImageObject","width":500,"height":110,"url":"https://miro.medium.com/v2/resize:fit:500/7%2AV1_7XP4snlmqrc_0Njontw.png"}},"mainEntityOfPage":"https://medium.com/@ml.enesguler/xgboost-basics-to-advanced-guide","isAccessibleForFree":true}</script><script data-rh="true" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/enterprise.js.Download" async="true"></script><style type="text/css" data-fela-rehydration="564" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}.grecaptcha-badge{visibility:hidden}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="564" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-webkit-keyframes k2{0%{transform:translate(-50%, -100px)}100%{transform:translate(-50%, 0)}}@-moz-keyframes k2{0%{transform:translate(-50%, -100px)}100%{transform:translate(-50%, 0)}}@keyframes k2{0%{transform:translate(-50%, -100px)}100%{transform:translate(-50%, 0)}}@-webkit-keyframes k3{0%{transform:matrix(0.97, 0, 0, 1, 0, 12);opacity:0}20%{transform:matrix(0.99, 0, 0, 1, 0, 2);opacity:0.7}40%{transform:matrix(1, 0, 0, 1, 0, -1);opacity:1}70%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}100%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}}@-moz-keyframes k3{0%{transform:matrix(0.97, 0, 0, 1, 0, 12);opacity:0}20%{transform:matrix(0.99, 0, 0, 1, 0, 2);opacity:0.7}40%{transform:matrix(1, 0, 0, 1, 0, -1);opacity:1}70%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}100%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}}@keyframes k3{0%{transform:matrix(0.97, 0, 0, 1, 0, 12);opacity:0}20%{transform:matrix(0.99, 0, 0, 1, 0, 2);opacity:0.7}40%{transform:matrix(1, 0, 0, 1, 0, -1);opacity:1}70%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}100%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}}</style><style type="text/css" data-fela-rehydration="564" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.d{display:none}.m{display:block}.n{position:sticky}.o{top:0}.p{z-index:500}.q{padding:0 24px}.r{align-items:center}.s{border-bottom:solid 1px #F2F2F2}.z{height:41px}.ab{line-height:20px}.ac{display:flex}.ae{gap:32px}.af{height:57px}.ag{flex:1 0 auto}.ah{color:inherit}.ai{fill:inherit}.aj{font-size:inherit}.ak{border:none}.al{font-family:inherit}.am{letter-spacing:inherit}.an{font-weight:inherit}.ao{padding:0}.ap{margin:0}.aq{cursor:pointer}.ar:disabled{cursor:not-allowed}.as:disabled{color:#6B6B6B}.at:disabled{fill:#6B6B6B}.aw{width:auto}.ax path{fill:#242424}.ay{height:25px}.az{margin-left:24px}.ba{border-radius:20px}.bb{width:240px}.bc{background:#F9F9F9}.bd path{fill:#6B6B6B}.bf{outline:none}.bg{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bh{font-size:14px}.bi{width:100%}.bj{padding:10px 20px 10px 0}.bk{background-color:transparent}.bl{color:#242424}.bm::placeholder{color:#6B6B6B}.bn{display:inline-block}.bo{margin-left:12px}.bp{margin-right:12px}.bq{border-radius:4px}.br{height:24px}.bx{background-color:#F9F9F9}.by{border-radius:50%}.bz{height:32px}.ca{width:32px}.cb{flex:0 0 auto}.cd{flex:1 1 auto}.ci{justify-content:center}.co{max-width:680px}.cp{min-width:0}.cq{animation:k1 1.2s ease-in-out infinite}.cr{height:100vh}.cs{margin-bottom:16px}.ct{margin-top:48px}.cu{align-items:flex-start}.cv{flex-direction:column}.cw{justify-content:space-between}.cx{margin-bottom:24px}.dd{width:80%}.de{background-color:#F2F2F2}.dk{height:44px}.dl{width:44px}.dm{margin:auto 0}.dn{margin-bottom:4px}.do{height:16px}.dp{width:120px}.dq{width:80px}.dw{margin-bottom:8px}.dx{width:96%}.dy{width:98%}.dz{width:81%}.ea{margin-left:8px}.eb{color:#6B6B6B}.ec{font-size:13px}.ed{height:100%}.ew{color:#FFFFFF}.ex{fill:#FFFFFF}.ey{background:#1A8917}.ez{border-color:#1A8917}.fd:disabled{cursor:inherit !important}.fe:disabled{opacity:0.3}.ff:disabled:hover{background:#1A8917}.fg:disabled:hover{border-color:#1A8917}.fh{border-radius:99em}.fi{border-width:1px}.fj{border-style:solid}.fk{box-sizing:border-box}.fl{text-decoration:none}.fm{text-align:center}.fn{margin-left:16px}.fo{border:inherit}.fr{position:relative}.fs{fill:#6B6B6B}.ft{gap:8px}.fw{position:absolute}.fx{width:1px}.fy{height:1px}.fz{margin:-1px}.ga{overflow:hidden}.gb{clip:rect(0, 0, 0, 0)}.gc{white-space:nowrap}.gd{border-width:0}.ge{margin-right:32px}.gf{background:transparent}.gg svg{margin-left:4px}.gh svg{fill:#6B6B6B}.gj{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.gq{margin:0 24px}.gu{background:rgba(255, 255, 255, 1)}.gv{border:1px solid #F2F2F2}.gw{box-shadow:0 1px 4px #F2F2F2}.gx{max-height:100vh}.gy{overflow-y:auto}.gz{left:0}.ha{top:calc(100vh + 100px)}.hb{bottom:calc(100vh + 100px)}.hc{width:10px}.hd{pointer-events:none}.he{word-break:break-word}.hf{word-wrap:break-word}.hg:after{display:block}.hh:after{content:""}.hi:after{clear:both}.hj{line-height:1.23}.hk{letter-spacing:0}.hl{font-style:normal}.hm{font-weight:700}.iw{gap:12px}.ix{align-items:baseline}.iy{width:36px}.iz{height:36px}.ja{border:2px solid rgba(255, 255, 255, 1)}.jb{z-index:0}.jc{box-shadow:none}.jd{border:1px solid rgba(0, 0, 0, 0.05)}.je{margin-bottom:2px}.jf{flex-wrap:nowrap}.jh{width:12px}.ji{flex-wrap:wrap}.jj{padding-left:8px}.jk{padding-right:8px}.kl> *{flex-shrink:0}.km{overflow-x:scroll}.kn::-webkit-scrollbar{display:none}.ko{scrollbar-width:none}.kp{-ms-overflow-style:none}.kq{width:74px}.kr{flex-direction:row}.ks{z-index:2}.kt{margin-right:4px}.kw{-webkit-user-select:none}.kx{border:0}.ky{fill:rgba(117, 117, 117, 1)}.lb{outline:0}.lc{user-select:none}.ld> svg{pointer-events:none}.lm{cursor:progress}.ln{opacity:1}.lo{padding:4px 0}.lr{margin-top:0px}.ls{width:16px}.lu{display:inline-flex}.ma{max-width:100%}.mb{padding:8px 2px}.mc svg{color:#6B6B6B}.mt{margin-left:auto}.mu{margin-right:auto}.mv{max-width:1024px}.nb{clear:both}.nd{cursor:zoom-in}.ne{z-index:auto}.ng{height:auto}.nh{line-height:1.58}.ni{letter-spacing:-0.004em}.nj{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.oe{margin-bottom:-0.46em}.of{clear:left}.og{float:left}.oh{font-size:66px}.oi{line-height:.83}.oo{line-height:1.12}.op{letter-spacing:-0.022em}.oq{font-weight:600}.pl{margin-bottom:-0.28em}.pr{line-height:1.18}.qf{margin-bottom:-0.31em}.qg{list-style-type:disc}.qh{margin-left:30px}.qi{padding-left:0px}.qt{max-width:4200px}.qz{padding-top:5px}.ra{padding-bottom:5px}.rb{font-style:italic}.rc{max-width:3000px}.rd{max-width:3600px}.re{overflow-x:auto}.rf{font-family:source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace}.rg{padding:32px}.rh{border:1px solid #E5E5E5}.ri{line-height:1.4}.rj{margin-top:-0.2em}.rk{margin-bottom:-0.2em}.rl{white-space:pre}.rm{min-width:fit-content}.rn{padding:2px 4px}.ro{font-size:75%}.rp> strong{font-family:inherit}.rq{max-width:850px}.rr{box-shadow:inset 3px 0 0 0 #242424}.rs{padding-left:23px}.rt{margin-left:-20px}.ru{text-decoration:underline}.rv{margin-bottom:26px}.rw{margin-top:6px}.rx{margin-top:8px}.ry{margin-right:8px}.rz{padding:8px 16px}.sa{border-radius:100px}.sb{transition:background 300ms ease}.sd{border-top:none}.se{margin-bottom:50px}.sf{height:52px}.sg{max-height:52px}.sh{box-sizing:content-box}.si{position:static}.sj{z-index:1}.sl{max-width:155px}.sr{margin-right:20px}.ss{margin-bottom:64px}.tf{height:48px}.tg{width:48px}.ti{height:64px}.tj{width:64px}.tk{align-self:flex-end}.to{padding-right:4px}.tp{font-weight:500}.tw{white-space:pre-wrap}.tx{margin:0 8px}.ty{margin-top:16px}.tz{margin-bottom:54px}.ua{height:0px}.ub{gap:18px}.uc{fill:rgba(61, 61, 61, 1)}.uo{border-bottom:solid 1px #E5E5E5}.up{margin-top:72px}.uq{padding:24px 0}.ur{margin-bottom:0px}.us{margin-right:16px}.au:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.av:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.fa:hover{background:#156D12}.fb:hover{border-color:#156D12}.fc:hover{cursor:pointer}.fu:hover{color:#242424}.fv:hover{fill:#242424}.gi:hover svg{fill:#242424}.gk:hover{background-color:rgba(0, 0, 0, 0.1)}.jg:hover{text-decoration:underline}.la:hover{fill:rgba(8, 8, 8, 1)}.lp:hover{fill:#000000}.lq:hover p{color:#000000}.lt:hover{color:#000000}.md:hover svg{color:#000000}.sc:hover{background-color:#F2F2F2}.th:hover{background-color:none}.ud:hover{fill:rgba(25, 25, 25, 1)}.be:focus-within path{fill:#242424}.kz:focus{fill:rgba(8, 8, 8, 1)}.me:focus svg{color:#000000}.nf:focus{transform:scale(1.01)}.le:active{border-style:none}</style><style type="text/css" data-fela-rehydration="564" data-fela-type="RULE" media="all and (min-width: 1080px)">.e{display:none}.bw{width:64px}.cc{display:block}.cn{margin:0 64px}.dc{height:48px}.dj{margin-bottom:52px}.dv{margin-bottom:48px}.em{font-size:14px}.eo{line-height:20px}.eu{font-size:13px}.ev{padding:5px 12px}.fq{display:flex}.gp{margin-bottom:50px}.gt{max-width:680px}.ih{font-size:42px}.ii{margin-top:1.19em}.ij{margin-bottom:32px}.ik{line-height:52px}.il{letter-spacing:-0.011em}.iu{align-items:center}.iv{flex-direction:row}.jx{border-top:solid 1px #F2F2F2}.jy{border-bottom:solid 1px #F2F2F2}.jz{margin:32px 0 0}.ka{padding:3px 8px}.kj> *{margin-right:24px}.kk> :last-child{margin-right:0}.ll{margin-top:0px}.lz{margin:0}.na{margin-top:40px}.oa{font-size:20px}.ob{margin-top:2.14em}.oc{line-height:32px}.od{letter-spacing:-0.003em}.on{padding-top:7px}.ph{font-size:24px}.pi{margin-top:1.95em}.pj{line-height:30px}.pk{letter-spacing:-0.016em}.pq{margin-top:0.94em}.qc{margin-top:1.72em}.qd{line-height:24px}.qe{letter-spacing:0}.qn{margin-top:1.14em}.qs{max-width:1192px}.qy{margin-top:56px}.sq{display:inline-block}.sv{margin-bottom:0}.sw{margin-right:20px}.tl{max-width:500px}.ui{margin:40px 0 0}.un{padding-top:72px}</style><style type="text/css" data-fela-rehydration="564" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.f{display:none}.lk{margin-top:0px}.sp{display:inline-block}</style><style type="text/css" data-fela-rehydration="564" data-fela-type="RULE" media="all and (max-width: 903.98px)">.g{display:none}.lj{margin-top:0px}.so{display:inline-block}</style><style type="text/css" data-fela-rehydration="564" data-fela-type="RULE" media="all and (max-width: 727.98px)">.h{display:none}.lh{margin-top:0px}.li{margin-right:0px}.sn{display:inline-block}</style><style type="text/css" data-fela-rehydration="564" data-fela-type="RULE" media="all and (max-width: 551.98px)">.i{display:none}.t{display:flex}.u{justify-content:space-between}.bs{width:24px}.ce{min-width:100%}.cj{margin:0 24px}.cy{height:40px}.df{margin-bottom:44px}.dr{margin-bottom:32px}.ee{font-size:13px}.ef{line-height:20px}.ep{padding:0px 8px 1px}.gl{margin-bottom:2px}.hn{font-size:32px}.ho{margin-top:1.01em}.hp{margin-bottom:24px}.hq{line-height:38px}.hr{letter-spacing:-0.014em}.im{align-items:flex-start}.in{flex-direction:column-reverse}.jl{margin:24px -24px 0}.jm{padding:0}.kb> *{margin-right:8px}.kc> :last-child{margin-right:24px}.ku{margin-left:0px}.lf{margin-top:0px}.lg{margin-right:0px}.lv{margin:0}.mf{border:1px solid #F2F2F2}.mg{border-radius:99em}.mh{padding:0px 16px 0px 12px}.mi{height:38px}.mj{align-items:center}.ml svg{margin-right:8px}.mw{margin-top:32px}.nk{font-size:18px}.nl{margin-top:1.56em}.nm{line-height:28px}.nn{letter-spacing:-0.003em}.oj{padding-top:0}.or{font-size:20px}.os{margin-top:1.2em}.ot{line-height:24px}.ou{letter-spacing:0}.pm{margin-top:0.67em}.ps{font-size:16px}.pt{margin-top:1.23em}.qj{margin-top:1.34em}.qo{max-width:100%}.qu{margin-top:40px}.sm{display:inline-block}.su{flex-direction:column}.td{margin-bottom:20px}.te{margin-right:0}.tq{font-size:24px}.tr{line-height:30px}.ts{letter-spacing:-0.016em}.ue{margin:32px 0 0}.uj{padding-top:48px}.mk:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="564" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.j{display:none}.bv{width:64px}.ch{min-width:100%}.cm{margin:0 64px}.db{height:48px}.di{margin-bottom:52px}.du{margin-bottom:48px}.ek{font-size:14px}.el{line-height:20px}.es{font-size:13px}.et{padding:5px 12px}.fp{display:flex}.go{margin-bottom:50px}.gs{max-width:680px}.ic{font-size:42px}.id{margin-top:1.19em}.ie{margin-bottom:32px}.if{line-height:52px}.ig{letter-spacing:-0.011em}.is{align-items:center}.it{flex-direction:row}.jt{border-top:solid 1px #F2F2F2}.ju{border-bottom:solid 1px #F2F2F2}.jv{margin:32px 0 0}.jw{padding:3px 8px}.kh> *{margin-right:24px}.ki> :last-child{margin-right:0}.ly{margin:0}.mz{margin-top:40px}.nw{font-size:20px}.nx{margin-top:2.14em}.ny{line-height:32px}.nz{letter-spacing:-0.003em}.om{padding-top:7px}.pd{font-size:24px}.pe{margin-top:1.95em}.pf{line-height:30px}.pg{letter-spacing:-0.016em}.pp{margin-top:0.94em}.pz{margin-top:1.72em}.qa{line-height:24px}.qb{letter-spacing:0}.qm{margin-top:1.14em}.qr{max-width:1192px}.qx{margin-top:56px}.sx{margin-bottom:0}.sy{margin-right:20px}.tm{max-width:500px}.uh{margin:40px 0 0}.um{padding-top:72px}</style><style type="text/css" data-fela-rehydration="564" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.k{display:none}.x{display:flex}.y{justify-content:space-between}.bu{width:64px}.cg{min-width:100%}.cl{margin:0 48px}.da{height:48px}.dh{margin-bottom:52px}.dt{margin-bottom:48px}.ei{font-size:13px}.ej{line-height:20px}.er{padding:0px 8px 1px}.gn{margin-bottom:50px}.gr{max-width:680px}.hx{font-size:42px}.hy{margin-top:1.19em}.hz{margin-bottom:32px}.ia{line-height:52px}.ib{letter-spacing:-0.011em}.iq{align-items:center}.ir{flex-direction:row}.jp{border-top:solid 1px #F2F2F2}.jq{border-bottom:solid 1px #F2F2F2}.jr{margin:32px 0 0}.js{padding:3px 8px}.kf> *{margin-right:24px}.kg> :last-child{margin-right:0}.lx{margin:0}.my{margin-top:40px}.ns{font-size:20px}.nt{margin-top:2.14em}.nu{line-height:32px}.nv{letter-spacing:-0.003em}.ol{padding-top:7px}.oz{font-size:24px}.pa{margin-top:1.95em}.pb{line-height:30px}.pc{letter-spacing:-0.016em}.po{margin-top:0.94em}.pw{margin-top:1.72em}.px{line-height:24px}.py{letter-spacing:0}.ql{margin-top:1.14em}.qq{max-width:100%}.qw{margin-top:56px}.sz{margin-bottom:0}.ta{margin-right:20px}.tn{max-width:500px}.ug{margin:40px 0 0}.ul{padding-top:72px}</style><style type="text/css" data-fela-rehydration="564" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.l{display:none}.v{display:flex}.w{justify-content:space-between}.bt{width:24px}.cf{min-width:100%}.ck{margin:0 24px}.cz{height:40px}.dg{margin-bottom:44px}.ds{margin-bottom:32px}.eg{font-size:13px}.eh{line-height:20px}.eq{padding:0px 8px 1px}.gm{margin-bottom:2px}.hs{font-size:32px}.ht{margin-top:1.01em}.hu{margin-bottom:24px}.hv{line-height:38px}.hw{letter-spacing:-0.014em}.io{align-items:flex-start}.ip{flex-direction:column-reverse}.jn{margin:24px 0 0}.jo{padding:0}.kd> *{margin-right:8px}.ke> :last-child{margin-right:8px}.kv{margin-left:0px}.lw{margin:0}.mm{border:1px solid #F2F2F2}.mn{border-radius:99em}.mo{padding:0px 16px 0px 12px}.mp{height:38px}.mq{align-items:center}.ms svg{margin-right:8px}.mx{margin-top:32px}.no{font-size:18px}.np{margin-top:1.56em}.nq{line-height:28px}.nr{letter-spacing:-0.003em}.ok{padding-top:0}.ov{font-size:20px}.ow{margin-top:1.2em}.ox{line-height:24px}.oy{letter-spacing:0}.pn{margin-top:0.67em}.pu{font-size:16px}.pv{margin-top:1.23em}.qk{margin-top:1.34em}.qp{max-width:100%}.qv{margin-top:40px}.st{flex-direction:column}.tb{margin-bottom:20px}.tc{margin-right:0}.tt{font-size:24px}.tu{line-height:30px}.tv{letter-spacing:-0.016em}.uf{margin:32px 0 0}.uk{padding-top:48px}.mr:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="564" data-fela-type="RULE" media="print">.sk{display:none}</style><style type="text/css" data-fela-rehydration="564" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.nc{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style><link rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:228:228/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156" data-rh="true"><link rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:180:180/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156" data-rh="true"><link rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:114:114/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156" data-rh="true"><link rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:90:90/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156" data-rh="true"><link rel="mask-icon" href="https://miro.medium.com/v2/resize:fill:750:750/7*GAOKVe--MXbEJmV9230oOQ.png" color="#171717" data-rh="true"><script async="true" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/js" data-rh="true"></script><script data-rh="true">window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-7JY7T788PK');</script><style id="googleidentityservice_button_styles">.qJTHM{-moz-user-select:none;-webkit-user-select:none;-ms-user-select:none;color:#202124;direction:ltr;-webkit-touch-callout:none;font-family:"Roboto-Regular",arial,sans-serif;-webkit-font-smoothing:antialiased;font-weight:400;margin:0;overflow:hidden;-webkit-text-size-adjust:100%}.ynRLnc{left:-9999px;position:absolute;top:-9999px}.L6cTce{display:none}.bltWBb{overflow-wrap:break-word;word-break:break-word}.hSRGPd{color:#1a73e8;cursor:pointer;font-weight:500;text-decoration:none}.Bz112c-W3lGp{height:16px;width:16px}.Bz112c-E3DyYd{height:20px;width:20px}.Bz112c-r9oPif{height:24px;width:24px}.Bz112c-u2z5K{height:36px;width:36px}.Bz112c-uaxL4e{border-radius:10px}.LgbsSe-Bz112c{display:block}.S9gUrf-YoZ4jf{border:none;margin:0;padding:0}.S9gUrf-YoZ4jf *{border:none;margin:0;padding:0}.fFW7wc-ibnC6b>.aZ2wEe>div{border-color:#4285f4}.P1ekSe-ZMv3u{-webkit-transition:height linear .2s;transition:height linear .2s}.P1ekSe-ZMv3u>div:nth-child(1){background-color:#1a73e8!important;-webkit-transition:width linear .3s;transition:width linear .3s}.P1ekSe-ZMv3u>div:nth-child(2){background-image:-webkit-gradient(linear,left top,right top,from(rgba(255,255,255,.7)),to(rgba(255,255,255,.7))),-webkit-gradient(linear,left top,right top,from(#1a73e8),to(#1a73e8))!important;background-image:-webkit-linear-gradient(left,rgba(255,255,255,.7),rgba(255,255,255,.7)),-webkit-linear-gradient(left,#1a73e8,#1a73e8)!important;background-image:linear-gradient(to right,rgba(255,255,255,.7),rgba(255,255,255,.7)),linear-gradient(to right,#1a73e8,#1a73e8)!important}.P1ekSe-ZMv3u>div:nth-child(3){background-image:-webkit-gradient(linear,left top,right top,from(rgba(255,255,255,.7)),to(rgba(255,255,255,.7))),-webkit-gradient(linear,left top,right top,from(#1a73e8),to(#1a73e8))!important;background-image:-webkit-linear-gradient(left,rgba(255,255,255,.7),rgba(255,255,255,.7)),-webkit-linear-gradient(left,#1a73e8,#1a73e8)!important;background-image:linear-gradient(to right,rgba(255,255,255,.7),rgba(255,255,255,.7)),linear-gradient(to right,#1a73e8,#1a73e8)!important}.haAclf{display:inline-block}.nsm7Bb-HzV7m-LgbsSe{border-radius:4px;box-sizing:border-box;-webkit-transition:background-color .218s,border-color .218s;transition:background-color .218s,border-color .218s;-moz-user-select:none;-webkit-user-select:none;-ms-user-select:none;-webkit-appearance:none;background-color:#fff;background-image:none;border:1px solid #dadce0;color:#3c4043;cursor:pointer;font-family:"Google Sans",arial,sans-serif;font-size:14px;height:40px;letter-spacing:.25px;outline:none;overflow:hidden;padding:0 12px;position:relative;text-align:center;vertical-align:middle;white-space:nowrap;width:auto}@media screen and (-ms-high-contrast:active){.nsm7Bb-HzV7m-LgbsSe{border:2px solid windowText;color:windowText}}@media screen and (preferes-contrast:more){.nsm7Bb-HzV7m-LgbsSe{color:#000}}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe{font-size:14px;height:32px;letter-spacing:.25px;padding:0 10px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe{font-size:11px;height:20px;letter-spacing:.3px;padding:0 8px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe{padding:0;width:40px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.pSzOP-SxQuSe{width:32px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.purZT-SxQuSe{width:20px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK{border-radius:20px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK.pSzOP-SxQuSe{border-radius:16px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK.purZT-SxQuSe{border-radius:10px}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc{border:none;color:#fff}.nsm7Bb-HzV7m-LgbsSe.MFS4be-v3pZbf-Ia7Qfc{background-color:#1a73e8}.nsm7Bb-HzV7m-LgbsSe.MFS4be-JaPV2b-Ia7Qfc{background-color:#202124;color:#e8eaed}@media screen and (prefers-contrast:more){.nsm7Bb-HzV7m-LgbsSe.MFS4be-JaPV2b-Ia7Qfc{color:#fff}}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:18px;margin-right:8px;min-width:18px;width:18px}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:14px;min-width:14px;width:14px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:10px;min-width:10px;width:10px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin-left:8px;margin-right:-4px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin:0;padding:10px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{padding:8px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{padding:4px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{border-top-left-radius:3px;border-bottom-left-radius:3px;display:-webkit-box;display:-webkit-flex;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;justify-content:center;-webkit-box-align:center;-webkit-align-items:center;align-items:center;background-color:#fff;height:36px;margin-left:-10px;margin-right:12px;min-width:36px;width:36px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf .nsm7Bb-HzV7m-LgbsSe-Bz112c,.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin:0;padding:0}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{height:28px;margin-left:-8px;margin-right:10px;min-width:28px;width:28px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{height:16px;margin-left:-6px;margin-right:8px;min-width:16px;width:16px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{border-radius:3px;margin-left:2px;margin-right:0;padding:0}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{border-radius:18px}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{border-radius:14px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{border-radius:8px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-bN97Pc-sM5MNb{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-align-items:center;-webkit-box-align:center;align-items:center;-webkit-flex-direction:row;-webkit-box-orient:horizontal;-webkit-box-direction:normal;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;-webkit-flex-wrap:nowrap;flex-wrap:nowrap;height:100%;position:relative;width:100%}.nsm7Bb-HzV7m-LgbsSe .oXtfBe-l4eHX{-webkit-box-pack:center;-webkit-justify-content:center;justify-content:center}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-BPrWId{-webkit-flex-grow:1;-webkit-box-flex:1;flex-grow:1;font-family:"Google Sans",arial,sans-serif;font-weight:500;overflow:hidden;text-overflow:ellipsis;vertical-align:top}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-BPrWId{font-weight:300}.nsm7Bb-HzV7m-LgbsSe .oXtfBe-l4eHX .nsm7Bb-HzV7m-LgbsSe-BPrWId{-webkit-flex-grow:0;-webkit-box-flex:0;flex-grow:0}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-MJoBVe{-webkit-transition:background-color .218s;transition:background-color .218s;bottom:0;left:0;position:absolute;right:0;top:0}.nsm7Bb-HzV7m-LgbsSe:hover,.nsm7Bb-HzV7m-LgbsSe:focus{box-shadow:none;border-color:rgb(210,227,252);outline:none}.nsm7Bb-HzV7m-LgbsSe:focus-within{outline:2px solid #00639b;border-color:transparent}.nsm7Bb-HzV7m-LgbsSe:hover .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(66,133,244,.08)}.nsm7Bb-HzV7m-LgbsSe:active .nsm7Bb-HzV7m-LgbsSe-MJoBVe,.nsm7Bb-HzV7m-LgbsSe:focus .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(66,133,244,.1)}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:hover .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(255,255,255,.24)}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:active .nsm7Bb-HzV7m-LgbsSe-MJoBVe,.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:focus .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(255,255,255,.32)}.nsm7Bb-HzV7m-LgbsSe .n1UuX-DkfjY{border-radius:50%;display:-webkit-box;display:-webkit-flex;display:flex;height:20px;margin-left:-4px;margin-right:8px;min-width:20px;width:20px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId{font-family:"Roboto";font-size:12px;text-align:left}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .ssJRIf,.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff .fmcmS{overflow:hidden;text-overflow:ellipsis}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-align-items:center;-webkit-box-align:center;align-items:center;color:#5f6368;fill:#5f6368;font-size:11px;font-weight:400}.nsm7Bb-HzV7m-LgbsSe.jVeSEe.MFS4be-Ia7Qfc .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{color:#e8eaed;fill:#e8eaed}@media screen and (prefers-contrast:more){.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff,.nsm7Bb-HzV7m-LgbsSe.jVeSEe.MFS4be-Ia7Qfc .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{color:#000;fill:#000}}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff .Bz112c{height:18px;margin:-3px -3px -3px 2px;min-width:18px;width:18px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{border-top-left-radius:0;border-bottom-left-radius:0;border-top-right-radius:3px;border-bottom-right-radius:3px;margin-left:12px;margin-right:-10px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{border-radius:18px}.L5Fo6c-sM5MNb{border:0;display:block;left:0;position:relative;top:0}.L5Fo6c-bF1uUb{border-radius:4px;bottom:0;cursor:pointer;left:0;position:absolute;right:0;top:0}.L5Fo6c-bF1uUb:focus{border:none;outline:none}sentinel{}</style><style data-fela-type="RULE" type="text/css" media="(orientation: landscape) and (max-width: 903.98px)"></style><link id="googleidentityservice" type="text/css" media="all" href="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/style" rel="stylesheet"><meta http-equiv="origin-trial" content="A8o5T4MyEkRZqLA9WeG2XTFdV5tsX2Prg85xyQ+RL1btVuybB1K/EQ+7JUsPK+J32oBMTnsoF9B4A+qTlL6efgQAAABweyJvcmlnaW4iOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb206NDQzIiwiZmVhdHVyZSI6IkZlZENtQnV0dG9uTW9kZSIsImV4cGlyeSI6MTc0NDY3NTIwMCwiaXNUaGlyZFBhcnR5Ijp0cnVlfQ=="></head><body><div id="root"><div class="a b c"><a href="https://medium.com/sitemap/sitemap.xml" class="d">Sitemap</a><div class="e f g h i j k l"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><div class="m c"><div class="m n o p c" style="transform: translateY(-57px);"><div class="q r s t u v w x y j e z ab"><a class="eb ai ec bg am b ao ap aq ar as at au av t v x j e r ed ab" href="https://play.google.com/store/apps/details?id=com.medium.reader&amp;referrer=utm_source%3DmobileNavBar&amp;source=post_page---top_nav_layout_nav-----------------------------------------" rel="noopener follow">Open in app<svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="none" viewBox="0 0 10 10" class="ea"><path fill="currentColor" d="M.985 8.485a.375.375 0 1 0 .53.53zM8.75 1.25h.375A.375.375 0 0 0 8.75.875zM8.375 6.5a.375.375 0 1 0 .75 0zM3.5.875a.375.375 0 1 0 0 .75zm-1.985 8.14 7.5-7.5-.53-.53-7.5 7.5zm6.86-7.765V6.5h.75V1.25zM3.5 1.625h5.25v-.75H3.5z"></path></svg></a><div class="ac r"><p class="bg b ee ef eg eh ei ej ek el em eo eb"><span data-dd-action-name="Susi presentation tracker global_nav"><button class="bg b ee ef ep eg eh eq ei ej er es el et eu eo ev ew ex ey ez fa fb fc fd fe ff fg fh fi fj fk bn fl fm" data-testid="headerSignUpButton">Sign up</button></span></p><div class="fn m"><p class="bg b ee ef eg eh ei ej ek el em eo eb"><span data-dd-action-name="Susi presentation tracker global_nav"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="headerSignInButton" rel="noopener follow" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Funderstanding-xgboost-from-basics-to-advanced-insights-d88536d87038&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------" data-discover="true">Sign in</a></span></p></div></div></div><div class="q r s ac ae af"><div class="ac r ag"><a class="ah ai aj ak al am an ao ap aq ar as at au av ac" aria-label="Homepage" data-testid="headerMediumLogo" rel="noopener follow" href="https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="719" height="160" fill="none" aria-labelledby="wordmark-medium-desc" viewBox="0 0 719 160" class="aw ax ay"><desc id="wordmark-medium-desc">Medium Logo</desc><path fill="#242424" d="m174.104 9.734.215-.047V8.02H130.39L89.6 103.89 48.81 8.021H1.472v1.666l.212.047c8.018 1.81 12.09 4.509 12.09 14.242V137.93c0 9.734-4.087 12.433-12.106 14.243l-.212.047v1.671h32.118v-1.665l-.213-.048c-8.018-1.809-12.089-4.509-12.089-14.242V30.586l52.399 123.305h2.972l53.925-126.743V140.75c-.687 7.688-4.721 10.062-11.982 11.701l-.215.05v1.652h55.948v-1.652l-.215-.05c-7.269-1.639-11.4-4.013-12.087-11.701l-.037-116.774h.037c0-9.733 4.071-12.432 12.087-14.242m25.555 75.488c.915-20.474 8.268-35.252 20.606-35.507 3.806.063 6.998 1.312 9.479 3.714 5.272 5.118 7.751 15.812 7.368 31.793zm-.553 5.77h65.573v-.275c-.186-15.656-4.721-27.834-13.466-36.196-7.559-7.227-18.751-11.203-30.507-11.203h-.263c-6.101 0-13.584 1.48-18.909 4.16-6.061 2.807-11.407 7.003-15.855 12.511-7.161 8.874-11.499 20.866-12.554 34.343q-.05.606-.092 1.212a50 50 0 0 0-.065 1.151 85.807 85.807 0 0 0-.094 5.689c.71 30.524 17.198 54.917 46.483 54.917 25.705 0 40.675-18.791 44.407-44.013l-1.886-.664c-6.557 13.556-18.334 21.771-31.738 20.769-18.297-1.369-32.314-19.922-31.042-42.395m139.722 41.359c-2.151 5.101-6.639 7.908-12.653 7.908s-11.513-4.129-15.418-11.63c-4.197-8.053-6.405-19.436-6.405-32.92 0-28.067 8.729-46.22 22.24-46.22 5.657 0 10.111 2.807 12.236 7.704zm43.499 20.008c-8.019-1.897-12.089-4.722-12.089-14.951V1.309l-48.716 14.353v1.757l.299-.024c6.72-.543 11.278.386 13.925 2.83 2.072 1.915 3.082 4.853 3.082 8.987v18.66c-4.803-3.067-10.516-4.56-17.448-4.56-14.059 0-26.909 5.92-36.176 16.672-9.66 11.205-14.767 26.518-14.767 44.278-.003 31.72 15.612 53.039 38.851 53.039 13.595 0 24.533-7.449 29.54-20.013v16.865h43.711v-1.746zM424.1 19.819c0-9.904-7.468-17.374-17.375-17.374-9.859 0-17.573 7.632-17.573 17.374s7.721 17.374 17.573 17.374c9.907 0 17.375-7.47 17.375-17.374m11.499 132.546c-8.019-1.897-12.089-4.722-12.089-14.951h-.035V43.635l-43.714 12.551v1.705l.263.024c9.458.842 12.047 4.1 12.047 15.152v81.086h43.751v-1.746zm112.013 0c-8.018-1.897-12.089-4.722-12.089-14.951V43.635l-41.621 12.137v1.71l.246.026c7.733.813 9.967 4.257 9.967 15.36v59.279c-2.578 5.102-7.415 8.131-13.274 8.336-9.503 0-14.736-6.419-14.736-18.073V43.638l-43.714 12.55v1.703l.262.024c9.459.84 12.05 4.097 12.05 15.152v50.17a56.3 56.3 0 0 0 .91 10.444l.787 3.423c3.701 13.262 13.398 20.197 28.59 20.197 12.868 0 24.147-7.966 29.115-20.43v17.311h43.714v-1.747zm169.818 1.788v-1.749l-.213-.05c-8.7-2.006-12.089-5.789-12.089-13.49v-63.79c0-19.89-11.171-31.761-29.883-31.761-13.64 0-25.141 7.882-29.569 20.16-3.517-13.01-13.639-20.16-28.606-20.16-13.146 0-23.449 6.938-27.869 18.657V43.643L545.487 55.68v1.715l.263.024c9.345.829 12.047 4.181 12.047 14.95v81.784h40.787v-1.746l-.215-.053c-6.941-1.631-9.181-4.606-9.181-12.239V66.998c1.836-4.289 5.537-9.37 12.853-9.37 9.086 0 13.692 6.296 13.692 18.697v77.828h40.797v-1.746l-.215-.053c-6.94-1.631-9.18-4.606-9.18-12.239V75.066a42 42 0 0 0-.578-7.26c1.947-4.661 5.86-10.177 13.475-10.177 9.214 0 13.691 6.114 13.691 18.696v77.828z"></path></svg></a><div class="az i"><div class="ac ak ba bb bc r bd be"><div class="bn" aria-describedby="searchResults" aria-labelledby="searchResults" aria-haspopup="listbox" role="listbox"></div><div class="bo bp ac"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ak bf bg bh ab bi bj bk bl bm" placeholder="Search" value=""></div></div></div><div class="i l x fp fq"><span data-dd-action-name="Susi presentation tracker new_post_topnav"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="headerWriteButton" rel="noopener follow" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------" data-discover="true"><div class="bg b bh ab eb fr fs ac r ft fu fv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" d="M14 4a.5.5 0 0 0 0-1zm7 6a.5.5 0 0 0-1 0zm-7-7H4v1h10zM3 4v16h1V4zm1 17h16v-1H4zm17-1V10h-1v10zm-1 1a1 1 0 0 0 1-1h-1zM3 20a1 1 0 0 0 1 1v-1zM4 3a1 1 0 0 0-1 1h1z"></path><path stroke="currentColor" d="m17.5 4.5-8.458 8.458a.25.25 0 0 0-.06.098l-.824 2.47a.25.25 0 0 0 .316.316l2.47-.823a.25.25 0 0 0 .098-.06L19.5 6.5m-2-2 2.323-2.323a.25.25 0 0 1 .354 0l1.646 1.646a.25.25 0 0 1 0 .354L19.5 6.5m-2-2 2 2"></path></svg>Write</div></a></span></div><div class="l k j e"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="headerSearchButton" rel="noopener follow" href="https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------" data-discover="true"><div class="bg b bh ab eb fr fs ac r ft fu fv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Search</span></div></a></div><div class="ge i l k"><div class="ac r"><p class="bg b ee ef eg eh ei ej ek el em eo eb"><span data-dd-action-name="Susi presentation tracker global_nav"><button class="bg b ee ef ep eg eh eq ei ej er es el et eu eo ev ew ex ey ez fa fb fc fd fe ff fg fh fi fj fk bn fl fm" data-testid="headerSignUpButton">Sign up</button></span></p><div class="fn m"><p class="bg b ee ef eg eh ei ej ek el em eo eb"><span data-dd-action-name="Susi presentation tracker global_nav"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="headerSignInButton" rel="noopener follow" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Funderstanding-xgboost-from-basics-to-advanced-insights-d88536d87038&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------" data-discover="true">Sign in</a></span></p></div></div></div><div class="m"><div><div class="bn" role="tooltip" aria-describedby="1" aria-labelledby="1"><div tabindex="-1" class="bf"><button class="ak gf ao ac r aq fr gg gh gi" aria-label="user options menu" data-testid="headerUserIcon"><div class="m fr"><img alt="" class="m fk by bz ca de" width="32" height="32" loading="lazy" role="presentation" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_dmbNkD5D-u45r44go_cf0g.png"><div class="gj by m bz ca fw o ak gk"></div></div></button></div></div></div></div></div></div><div class="ac"><div class="cb i l k j cc" style="width: 0px;"></div><div class="cd bi ce cf cg ch" style="width: calc(100% + 0px);"><div class="m"><div data-focus-guard="true" tabindex="-1" style="width: 1px; height: 0px; padding: 0px; overflow: hidden; position: fixed; top: 1px; left: 1px;"></div><div data-focus-lock-disabled="disabled"><div class="sk" role="dialog" aria-modal="true" tabindex="-1"><div class="wm wn bi ed wo wp wq aq wr hd ws" aria-hidden="true" role="presentation"></div><div class="wt wo wu wv ww wm ed fk wx wy wz ln xa xb xc xd xe xf xg xh xi xj ac cv xk" aria-hidden="true"><div class="xl gy"></div></div></div></div><div data-focus-guard="true" tabindex="-1" style="width: 1px; height: 0px; padding: 0px; overflow: hidden; position: fixed; top: 1px; left: 1px;"></div><div class="gl gm gn go gp m"><div class="ac ci"><div class="cp bi gq gr gs gt"></div></div><article><div class="m"><div class="m"><span class="m"></span><section><div><div class="fw gz xm hb hc hd"></div><div class="he hf hg hh hi"><div class="ac ci"><div class="cp bi gq gr gs gt"><div><h1 id="77c6" class="pw-post-title hj hk hl bg hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie if ig ih ii ij ik il bl" data-testid="storyTitle" data-selectable-paragraph="">Understanding XGBoost: From Basics to Advanced Insights</h1><div><div class="speechify-ignore ac cw"><div class="speechify-ignore bi m"><div class="ac im in io ip iq ir is it iu iv iw"><div class="ac r iw"><div class="ac ix"><div><div class="bn" aria-describedby="3" aria-labelledby="3" role="tooltip"><div tabindex="-1" class="bf"><a rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---byline--d88536d87038---------------------------------------" data-discover="true"><div class="m iy iz by ja jb"><div class="m fr"><img alt="Enes Güler" class="m fk by bz ca de" width="32" height="32" loading="lazy" data-testid="authorPhoto" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_nC_mhaCkoHWhFhomi3ErNw.png"><div class="jc by m bz ca fw o jd gk"></div></div></div></a></div></div></div></div><span class="bg b bh ab bl"><div class="je ac r"><div class="ac r jf"><div class="ac r"><div><div class="bn" aria-describedby="4" aria-labelledby="4" role="tooltip"><div tabindex="-1" class="bf"><span class="bg b bh ab bl"><a class="ah ai aj fo al am an ao ap aq ar as at jg" data-testid="authorName" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---byline--d88536d87038---------------------------------------" data-discover="true">Enes Güler</a></span></div></div></div></div><div class="jh bn"></div><button class="yg zq aq ac ci r zr zs zt" style="border: 1px solid rgb(36, 36, 36);"><span class="bg b bh ab bl bi"><span class="bn zu">Follow</span></span></button></div></div></span></div><div class="ac r ji"><span class="bg b bh ab eb"><div class="ac ag"><span data-testid="storyReadTime">17 min read</span><div class="jj jk m" aria-hidden="true"><span class="m" aria-hidden="true"><span class="bg b bh ab eb">·</span></span></div><span data-testid="storyPublishDate">Sep 27, 2025</span></div></span></div></div><div class="ac cw jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka"><div class="i l x fp fq r"><div class="kq m"><div class="ac r kr ks"><div class="pw-multi-vote-icon fr kt ku kv kw"><span data-dd-action-name="Susi presentation tracker clap_footer"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="headerClapButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fd88536d87038&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Funderstanding-xgboost-from-basics-to-advanced-insights-d88536d87038&amp;user=Enes+G%C3%BCler&amp;userId=b6a26fecee8e&amp;source=---header_actions--d88536d87038---------------------clap_footer------------------" data-discover="true"><div><div class="bn" aria-describedby="5" aria-labelledby="5" role="tooltip"><div tabindex="-1" class="bf"><div class="kx aq ky kz la lb ao lc ld le kw" role="presentation"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></div></a></span></div><div class="pw-multi-vote-count m lf lg lh li lj lk ll"><div><div class="bn" aria-describedby="69" aria-labelledby="69" role="tooltip"><div tabindex="-1" class="bf"><p class="bg b ec ab eb"><button class="ah ai aj fo al am an ao ap aq ar as at au av zv lt">3<span class="m i h g sp sq"></span></button></p></div></div></div></div></div></div><div><div class="bn" aria-describedby="6" aria-labelledby="6" role="tooltip"><div tabindex="-1" class="bf"><button class="aq kx ln lo ac r fs lp lq" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="lr"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg></button></div></div></div></div><div class="ac r kb kc kd ke kf kg kh ki kj kk kl km kn ko kp"><div class="ls l k j e"></div><div class="i l"><div><div class="bn" aria-describedby="7" aria-labelledby="7" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_footer"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="headerBookmarkButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd88536d87038&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Funderstanding-xgboost-from-basics-to-advanced-insights-d88536d87038&amp;source=---header_actions--d88536d87038---------------------bookmark_footer------------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lt" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div><div class="fk lu cu"><div class="m ag"><div class="ac ci"><div class="lv lw lx ly lz ma cp bi"><div class="ac"><span data-dd-action-name="Susi presentation tracker post_audio_button"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3Dd88536d87038&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Funderstanding-xgboost-from-basics-to-advanced-insights-d88536d87038&amp;source=---header_actions--d88536d87038---------------------post_audio_button------------------" data-discover="true"><div><div class="bn" aria-describedby="53" aria-labelledby="53" role="tooltip"><div tabindex="-1" class="bf"><button aria-label="Listen" data-testid="audioPlayButton" class="ah fs aj fo al am an mb ap aq ar fe mc md lq me mf mg mh mi t mj mk ml mm mn mo mp v mq mr ms"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"></path></svg><div class="k j e"><p class="bg b bh ab eb">Listen</p></div></button></div></div></div></a></span></div></div></div></div></div><div class="bn" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bn" aria-describedby="9" aria-labelledby="9" role="tooltip"><div tabindex="-1" class="bf"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="ah fs aj fo al am an mb ap aq ar fe mc md lq me mf mg mh mi t mj mk ml mm mn mo mp v mq mr ms"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg><div class="k j e"><p class="bg b bh ab eb">Share</p></div></button></div></div></div></div></div></div></div></div></div></div><figure class="mw mx my mz na nb mt mu paragraph-image"><div role="button" tabindex="0" class="nc nd fr ne bi nf"><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Press enter or click to view image in full size</span><div class="mt mu mv"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*y0Zpd2U2nGIPmha5XniRgw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*y0Zpd2U2nGIPmha5XniRgw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*y0Zpd2U2nGIPmha5XniRgw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*y0Zpd2U2nGIPmha5XniRgw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*y0Zpd2U2nGIPmha5XniRgw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*y0Zpd2U2nGIPmha5XniRgw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y0Zpd2U2nGIPmha5XniRgw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*y0Zpd2U2nGIPmha5XniRgw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*y0Zpd2U2nGIPmha5XniRgw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*y0Zpd2U2nGIPmha5XniRgw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*y0Zpd2U2nGIPmha5XniRgw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*y0Zpd2U2nGIPmha5XniRgw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*y0Zpd2U2nGIPmha5XniRgw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*y0Zpd2U2nGIPmha5XniRgw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bi ma ng c" width="700" height="700" loading="eager" role="presentation" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_y0Zpd2U2nGIPmha5XniRgw.png"></picture></div></div></figure><p id="a549" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl of" data-selectable-paragraph=""><span class="m og oh oi bp oj ok ol om on fr">In</span><strong class="nj hm"> the highly competitive world of machine learning, achieving state-of-the-art results often requires moving beyond basic models. For years, one algorithm has consistently stood out for its speed, performance, and robustness across diverse prediction tasks: Extreme Gradient Boosting, or XGBoost.</strong> Unlike traditional methods, XGBoost leverages a highly optimized and scalable implementation of gradient boosting, making it the undisputed champion in structured data challenges, from Kaggle competitions to enterprise-level applications. <strong class="nj hm">This comprehensive guide will take you on a deep dive, explaining the foundational concepts that make XGBoost so powerful, showing you how to implement it effectively with Python, and offering advanced insights to tune your models for peak performance.</strong></p><h2 id="9062" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">1. Historical Background of XGBoost</h2><p id="855b" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">The story of XGBoost begins in 2014. <strong class="nj hm">Tianqi Chen</strong>, then a Ph.D. student at the University of Washington, recognized the performance bottlenecks and limitations of the <strong class="nj hm">Gradient Boosting</strong> algorithms that were gaining popularity at the time. In particular, existing implementations struggled with large-scale datasets, suffered from limited flexibility, and failed to efficiently leverage the parallel processing capabilities offered by modern hardware.</p><p id="5bbb" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">Chen’s objective was to develop a boosting library that was not <strong class="nj hm">only faster</strong> and <strong class="nj hm">more scalable</strong> but also <strong class="nj hm">more robust against overfitting</strong>. In line with this vision, XGBoost was designed to be more than just a theoretically powerful algorithm; it was also carefully engineered with a series of optimizations. These included parallel computation, sparsity-aware structures, tree pruning, and advanced regularization techniques, all of which distinguished it from existing implementations.</p><p id="0205" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">From the very beginning, the project was released as <strong class="nj hm">open source</strong>, which enabled researchers, data scientists, and engineers to adopt it rapidly. It quickly gained traction in <strong class="nj hm">Kaggle competitions</strong>, becoming especially popular between 2015 and 2017, when a large share of winning solutions relied on XGBoost. This success earned the algorithm the reputation of being the “competition favorite.”</p><p id="f1b6" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">However, the rise of XGBoost was not limited to competitions. Over time, it found applications across a wide range of domains, including finance, healthcare, marketing, bioinformatics, and industry. Its use cases span from credit risk modeling and customer behavior prediction to disease forecasting and anomaly detection in manufacturing processes.</p><p id="43b1" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">Today, XGBoost is regarded not merely as an algorithm but as one of the foundational building blocks of <strong class="nj hm">modern machine learning</strong>. With its strong performance, it has become a preferred standard in both academic research and industrial projects.</p><h2 id="15f5" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">2. Introduction to XGBoost</h2><p id="55db" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">XGBoost (Extreme Gradient Boosting) is a powerful <strong class="nj hm">boosting algorithm</strong> that has rapidly emerged in the modern machine learning landscape, particularly gaining popularity in competitions such as Kaggle. Its core principle is to combine multiple weak learners — typically decision trees — into a strong predictive model. This approach can be viewed as an enhanced version of classical gradient boosting methods and is widely recognized for delivering high accuracy.</p><p id="9061" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">There are several reasons behind the popularity of XGBoost:</p><p id="e0f6" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Performance and Speed: </strong>Thanks to parallel computation and optimized data structures, XGBoost can handle large datasets with remarkable efficiency.</p><p id="aa08" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Regularization:</strong> By supporting both L1 and L2 regularization, it helps reduce the risk of overfitting.</p><p id="cf44" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Flexibility:</strong> It is suitable for both regression and classification tasks and can work with a variety of loss functions.</p><p id="5416" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Community and Resources:</strong> With comprehensive documentation and strong community support, XGBoost is relatively easy to learn and apply.</p><p id="afa4" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">Beyond being an enhanced version of the classical Gradient Boosting algorithm, XGBoost is equipped with a sparsity-aware approach and tree pruning techniques that allow it to handle missing values in datasets effectively. These features elevate XGBoost from being merely an academic tool to a reliable and efficient solution for real-world projects.</p><p id="4366" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">Its success in data science competitions has further demonstrated that, when combined with proper hyperparameter tuning and feature engineering, XGBoost can consistently outperform competing algorithms. For this reason, it has become a preferred choice among data scientists for both experimental research and industrial applications.</p><h2 id="3ee3" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">3. Comparison with Other Boosting Algorithms</h2><p id="4850" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">Boosting algorithms generally aim to combine multiple weak learners (typically decision trees) into a single strong and accurate predictive model. However, their implementation strategies differ significantly. Compared to AdaBoost and classical Gradient Boosting, XGBoost offers several distinct advantages:</p><h3 id="455e" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph=""><strong class="an">3.1. Difference from AdaBoost:</strong></h3><ul class=""><li id="554f" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">AdaBoost trains subsequent models by assigning higher weights to misclassified instances, making each new model more sensitive to the errors of its predecessor.</li><li id="bfc9" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">However, AdaBoost is highly sensitive to noisy data and outliers, which can weaken its generalization capability.</li><li id="b7a3" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">XGBoost, on the other hand, not only adjusts weights but also employs gradient descent–based optimization. Furthermore, through its use of L1 and L2 regularization, it is far more robust against noisy data and overfitting.</li></ul></div></div><div class="nb"><div class="ac ci"><div class="lv qo lw qp lx qq cm qr cn qs cp bi"><figure class="qu qv qw qx qy nb qz ra paragraph-image"><div role="button" tabindex="0" class="nc nd fr ne bi nf"><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Press enter or click to view image in full size</span><div class="mt mu qt"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*P_SMUMON9tlLzvah4Ej-WA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*P_SMUMON9tlLzvah4Ej-WA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*P_SMUMON9tlLzvah4Ej-WA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*P_SMUMON9tlLzvah4Ej-WA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*P_SMUMON9tlLzvah4Ej-WA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*P_SMUMON9tlLzvah4Ej-WA.png 1100w, https://miro.medium.com/v2/resize:fit:2000/format:webp/1*P_SMUMON9tlLzvah4Ej-WA.png 2000w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 1000px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*P_SMUMON9tlLzvah4Ej-WA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*P_SMUMON9tlLzvah4Ej-WA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*P_SMUMON9tlLzvah4Ej-WA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*P_SMUMON9tlLzvah4Ej-WA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*P_SMUMON9tlLzvah4Ej-WA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*P_SMUMON9tlLzvah4Ej-WA.png 1100w, https://miro.medium.com/v2/resize:fit:2000/1*P_SMUMON9tlLzvah4Ej-WA.png 2000w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 1000px"><img alt="" class="bi ma ng c" width="1000" height="715" loading="lazy" role="presentation" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_P_SMUMON9tlLzvah4Ej-WA.png"></picture></div></div></figure></div></div></div><div class="ac ci"><div class="cp bi gq gr gs gt"><h3 id="ebc8" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph=""><strong class="an">3.2. Difference from Classical Gradient Boosting:</strong></h3><ul class=""><li id="8074" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">Like XGBoost, Gradient Boosting leverages gradient information to minimize errors. However, traditional implementations are often slower and struggle with performance on large datasets.</li><li id="0382" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">XGBoost addresses these limitations by incorporating engineering optimizations such as parallel computation, sparsity-aware algorithms, and tree pruning, making it significantly faster.</li><li id="a110" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Additionally, XGBoost provides a richer set of hyperparameters (e.g., <em class="rb">learning_rate</em>, <em class="rb">max_depth</em>, <em class="rb">gamma</em>, <em class="rb">subsample</em>, <em class="rb">colsample_bytree</em>), offering users finer control over model tuning.</li></ul><h3 id="2e40" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph=""><strong class="an">3.3. General Advantages:</strong></h3><ul class=""><li id="4e3c" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Regularization:</strong> Unlike AdaBoost and classical GBM, where regularization mechanisms are limited, XGBoost integrates both L1 (Lasso) and L2 (Ridge) regularization, offering stronger control over overfitting.</li><li id="d212" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Handling Missing Values:</strong> XGBoost can automatically learn the optimal direction for missing values, a feature not available in AdaBoost or classical GBM.</li><li id="5540" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Scalability:</strong> It efficiently handles very large datasets and supports execution on both CPUs and GPUs.</li></ul><p id="bad9" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">In summary:</strong> AdaBoost represents a simpler and more fundamental boosting approach; classical Gradient Boosting is powerful but remains limited in terms of speed and flexibility. XGBoost, by contrast, is a modern boosting method that integrates <strong class="nj hm">both theoretical and engineering advancements</strong>, offering speed, scalability, and strong generalization performance together.</p><h2 id="2b58" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">4. Fundamental Concepts of XGBoost</h2><p id="6330" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">To understand XGBoost, it is essential to first grasp the fundamental principles underlying boosting algorithms. These concepts serve as the building blocks that explain why XGBoost is so powerful and widely adopted.</p><h3 id="e146" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">4.1. What is Boosting?</h3><p id="c27b" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">Boosting is a method of combining multiple weak learners — typically shallow decision trees — into a single, strong predictive model. Each successive model attempts to correct the errors of its predecessors, allowing the ensemble to improve incrementally.</p><h3 id="e43c" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">4.2. From Weak Learners to Strong Learners</h3><p id="3a07" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">An individual small decision tree (e.g., a depth-1 “decision stump”) is generally too simple to capture the complexity of real-world data. However, systematically combining hundreds of such small trees produces a model capable of making highly accurate predictions. This principle lies at the heart of boosting.</p><h3 id="6a82" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">4.3. The Gradient Boosting Principle</h3><p id="55fa" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">Classical boosting methods assign higher weights to misclassified instances. Gradient Boosting generalizes this idea by leveraging the concept of gradient descent. Each new tree is trained to fit the gradients of the loss function, meaning the model learns the “slope of the error” from previous iterations and updates itself to minimize those errors. This approach makes the learning process more systematic and efficient.</p><h3 id="5da6" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">4.4. Loss Function (Objective Function)</h3><figure class="qu qv qw qx qy nb mt mu paragraph-image"><div role="button" tabindex="0" class="nc nd fr ne bi nf"><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Press enter or click to view image in full size</span><div class="mt mu rc"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*q7eUGSNs0Q0JEAb1HNXKbA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*q7eUGSNs0Q0JEAb1HNXKbA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*q7eUGSNs0Q0JEAb1HNXKbA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*q7eUGSNs0Q0JEAb1HNXKbA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*q7eUGSNs0Q0JEAb1HNXKbA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*q7eUGSNs0Q0JEAb1HNXKbA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q7eUGSNs0Q0JEAb1HNXKbA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*q7eUGSNs0Q0JEAb1HNXKbA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*q7eUGSNs0Q0JEAb1HNXKbA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*q7eUGSNs0Q0JEAb1HNXKbA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*q7eUGSNs0Q0JEAb1HNXKbA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*q7eUGSNs0Q0JEAb1HNXKbA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*q7eUGSNs0Q0JEAb1HNXKbA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*q7eUGSNs0Q0JEAb1HNXKbA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bi ma ng c" width="700" height="420" loading="lazy" role="presentation" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_q7eUGSNs0Q0JEAb1HNXKbA.png"></picture></div></div></figure><p id="fb17" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">The loss function is a metric that measures the difference between the model’s predictions and the true values. XGBoost supports different loss functions tailored to various problem types:</p><ul class=""><li id="b66c" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Regression:</strong> Mean Squared Error (MSE) or Root Mean Squared Error (RMSE)</li><li id="7f78" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Binary Classification:</strong> Logistic Loss (<em class="rb">binary:logistic</em>)</li><li id="c204" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Multiclass Classification:</strong> Softmax Loss (<em class="rb">multi:softmax</em>)</li><li id="0203" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Custom Tasks:</strong> Users can define their own custom loss functions</li></ul><p id="08f2" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">Selecting the appropriate loss function directly impacts model performance, as the entire learning process revolves around minimizing this function.</p><h3 id="fe55" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">4.5. Key Innovations of XGBoost</h3><p id="2723" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">Beyond the general principles of boosting, XGBoost introduces several important innovations:</p><ul class=""><li id="ed68" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Regularization:</strong> Incorporates both L1 (Lasso) and L2 (Ridge) penalties, helping to prevent overfitting.</li><li id="653d" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Parallelization:</strong> Optimizes tree construction to efficiently leverage multi-core processors.</li><li id="999d" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Sparsity-Aware Approach:</strong> Automatically directs missing values to the optimal branches.</li><li id="bfed" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Tree Pruning:</strong> Removes unnecessary branches to produce more compact and generalizable trees.</li></ul><h2 id="7fe3" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">6. Strengths and Limitations of XGBoost</h2><p id="2350" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">Like any algorithm, XGBoost has its strengths and limitations. Understanding these aspects is crucial for determining the contexts in which it is most suitable.</p><h3 id="ce94" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">6.1. Strengths</h3><p id="a019" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">High Performance and Accuracy: </strong>XGBoost has frequently secured top positions in data science competitions such as Kaggle. Its fast training times and high predictive accuracy make it a preferred choice in both academic research and industrial applications.</p><p id="a864" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Robustness Against Overfitting: </strong>By incorporating both L1 (Lasso) and L2 (Ridge) regularization, XGBoost protects the model from unnecessary complexity and enhances its generalization capability.</p><p id="d3f8" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Effective Handling of Missing Values: </strong>The algorithm can automatically direct missing values to the appropriate branches, reducing the need for extensive data preprocessing.</p><p id="02db" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Scalability and Speed:</strong></p><ul class=""><li id="e5d4" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Supports parallelization on multi-core processors</li><li id="42b3" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Offers GPU acceleration</li><li id="8940" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Maintains efficiency even on very large datasets</li></ul><p id="89cd" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Flexibility:</strong></p><ul class=""><li id="b8f9" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Provides support for a wide range of loss functions across different problem types, including regression, classification, and ranking</li><li id="75df" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Allows users to define custom loss functions or evaluation metrics</li></ul><h3 id="6647" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">6.2. Limitations</h3><p id="a1e9" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Hyperparameter Complexity: </strong>XGBoost involves a large number of parameters. Proper tuning often requires expertise, experience, and extensive trial and error.</p><p id="5710" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Training Time: </strong>Although optimizations make XGBoost relatively fast, training on very large datasets with millions of rows can still be time-consuming. Improperly tuned parameters may further extend this process.</p><p id="74dd" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Not Suitable for Unstructured Data: </strong>XGBoost excels on tabular (structured) data. However, for unstructured data such as images, audio, or text, deep learning methods (e.g., CNNs, RNNs, Transformers) are generally more appropriate.</p><p id="a329" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Interpretability Challenges: </strong>A single decision tree is easy to visualize and understand, but XGBoost models — comprising hundreds of trees — often behave like a “black box.” Therefore, additional tools such as SHAP or LIME are typically required to achieve interpretability.</p><h3 id="644c" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">6.3. When to Use XGBoost</h3><ul class=""><li id="4885" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">When high accuracy is desired on tabular (structured) datasets</li><li id="da62" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">For medium to large-sized datasets</li><li id="f94f" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">When minimizing the risk of overfitting is important</li><li id="504b" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">When a strong baseline or final model is needed in competitive settings</li></ul><p id="6ab5" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">Conversely, for very simple datasets or situations where interpretability is critical, simpler methods such as Logistic Regression, Decision Trees, or Random Forests may be more suitable.</p><h2 id="45a2" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">7. Essential Hyperparameters of XGBoost</h2><p id="3498" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">The success of XGBoost largely stems from its ability to optimize model performance through careful hyperparameter tuning. Given the large number of parameters available, it is important for beginners to focus on the most critical ones. Below are the key hyperparameters and their functions:</p><p id="40e1" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">n_estimators (Number of Trees):</strong></p><ul class=""><li id="7bed" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Determines how many trees will be used in the model.</li><li id="2279" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Too few trees can lead to underfitting; too many can cause overfitting.</li><li id="0546" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Often tuned in conjunction with <em class="rb">learning_rate</em>; lower <em class="rb">learning_rate</em> typically requires more trees.</li></ul><p id="eff4" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">max_depth (Tree Depth):</strong></p><ul class=""><li id="3cc9" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Sets the maximum depth of each tree.</li><li id="21ce" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Deeper trees capture more patterns but increase the risk of overfitting.</li><li id="4472" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">A typical starting range is between 3 and 6.</li></ul><p id="9d06" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">learning_rate / eta (Learning Rate):</strong></p><ul class=""><li id="3e81" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Scales the contribution of each tree.</li><li id="f9d6" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Small values → slower but more stable learning</li><li id="b867" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Large values → faster but riskier learning</li><li id="7a47" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Typically optimized alongside <em class="rb">n_estimators</em>.</li></ul><p id="8a5a" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">subsample (Sampling Ratio):</strong></p><ul class=""><li id="8286" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Specifies the fraction of training data used to build each tree.</li><li id="136c" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">1.0 → use all data</li><li id="dd14" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">&lt;1.0 → random subsample → reduces overfitting</li></ul><p id="dffa" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">colsample_bytree, colsample_bylevel, colsample_bynode (Feature Subsampling):</strong></p><ul class=""><li id="66aa" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Controls which features are considered at each tree, level, or node.</li><li id="9fbe" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Randomly selecting subsets of features improves generalization.</li></ul><p id="8f3c" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">gamma (Minimum Split Loss):</strong></p><ul class=""><li id="78fe" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Minimum reduction in loss required to make a split.</li><li id="15da" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Higher <em class="rb">gamma</em> → more conservative splits → reduces overfitting</li></ul><p id="f236" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">min_child_weight:</strong></p><ul class=""><li id="f5a0" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Minimum sum of instance weight needed in a leaf.</li><li id="2cb5" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Higher values → fewer splits → simpler trees → reduces overfitting</li></ul><p id="90c3" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">Regularization: reg_alpha and reg_lambda:</strong></p><ul class=""><li id="0b61" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph=""><em class="rb">reg_alpha</em> → L1 penalty</li><li id="0564" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><em class="rb">reg_lambda</em> → L2 penalty</li><li id="bfd4" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Controls model complexity and mitigates overfitting</li></ul><p id="d6ab" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">scale_pos_weight:</strong></p><ul class=""><li id="61bb" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Adjusts the balance between positive and negative classes in imbalanced datasets</li><li id="301e" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Particularly useful for binary classification</li></ul><figure class="qu qv qw qx qy nb mt mu paragraph-image"><div role="button" tabindex="0" class="nc nd fr ne bi nf"><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Press enter or click to view image in full size</span><div class="mt mu rc"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*M5gLsNRBllZCETA-4VnoXg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*M5gLsNRBllZCETA-4VnoXg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*M5gLsNRBllZCETA-4VnoXg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*M5gLsNRBllZCETA-4VnoXg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*M5gLsNRBllZCETA-4VnoXg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*M5gLsNRBllZCETA-4VnoXg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M5gLsNRBllZCETA-4VnoXg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*M5gLsNRBllZCETA-4VnoXg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*M5gLsNRBllZCETA-4VnoXg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*M5gLsNRBllZCETA-4VnoXg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*M5gLsNRBllZCETA-4VnoXg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*M5gLsNRBllZCETA-4VnoXg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*M5gLsNRBllZCETA-4VnoXg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*M5gLsNRBllZCETA-4VnoXg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bi ma ng c" width="700" height="420" loading="lazy" role="presentation" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_M5gLsNRBllZCETA-4VnoXg.png"></picture></div></div></figure><p id="a188" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">These fundamental hyperparameters significantly influence XGBoost model performance. In practice, iterative tuning of these parameters allows optimization of speed, accuracy, and generalization simultaneously.</p><h2 id="1cf9" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">8. Advanced Capabilities of XGBoost</h2><p id="82f1" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">After mastering the core hyperparameters, it is important to understand the advanced features that enhance XGBoost’s performance and flexibility. This section covers intermediate-level topics that are critical for optimizing the model and applying it effectively in more complex scenarios.</p><h3 id="598e" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">8.1. Booster Types</h3><p id="d2bb" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">XGBoost provides three types of boosters tailored for different use cases:</p><div class="ut uu uv uw ac r cv"><div class="ux uy uz va vb m fm"><h2 class="vc b vd ve vf vg vh">Get Enes Güler’s stories in&nbsp;your&nbsp;inbox</h2></div><div class="cs m fm"><p class="bg b bh ab eb">Join Medium for free to get updates from&nbsp;this&nbsp;writer.</p></div><div class="vl su vm vn st vo ac"><span class="bg b bh ab bl"><div class="vp ac cv"><div class="ac vp fj fi bq vq vr de ln vs vt vu vv vw vx vy"><input class="vz al aj an wa wb gd lb bm wc bi" placeholder="Enter your email" type="text" value=""></div></div></span><div class="i l tk cb"><div class="vi vj vk"><button class="bg b bh ab wd rz we wf wg wh wi fc fd wj wk wl fh fi fj fk bn fl fm">Subscribe</button></div></div><div class="bi k j e"><button class="bg b bh ab wd rz we wf wg wh wi fc fd wj wk wl fh bi fi fj fk bn fl fm">Subscribe</button></div></div><div class="rx m"><div id="g-recaptcha"></div></div></div><p id="756b" class="pw-post-body-paragraph nh ni hl nj b nk nm nn no nq nr ns nu nv nw ny nz oa oc od uw oe he bl" data-selectable-paragraph=""><strong class="nj hm">gbtree:</strong></p><ul class=""><li id="3cfe" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Default option.</li><li id="156c" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Uses decision trees and is suitable for both classification and regression tasks.</li></ul><p id="8faa" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">gblinear:</strong></p><ul class=""><li id="26c5" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Uses linear models (e.g., linear regression, logistic regression).</li><li id="189e" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Particularly useful for very large and sparse datasets.</li></ul><p id="d31f" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">dart (Dropouts meet Multiple Additive Regression Trees):</strong></p><ul class=""><li id="99d2" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Randomly drops some trees to prevent overfitting.</li><li id="f954" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Increases ensemble diversity and improves generalization performance.</li></ul><h3 id="163b" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">8.2. Early Stopping and Learning Rate Strategies</h3><figure class="qu qv qw qx qy nb mt mu paragraph-image"><div role="button" tabindex="0" class="nc nd fr ne bi nf"><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Press enter or click to view image in full size</span><div class="mt mu rd"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Mxx2CZQZ4ocGXzrekWcj-Q.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bi ma ng c" width="700" height="350" loading="lazy" role="presentation" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_Mxx2CZQZ4ocGXzrekWcj-Q.png"></picture></div></div></figure><ul class=""><li id="baec" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Early Stopping:</strong></li><li id="8f78" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Stops training if the model does not show improvement on the validation set for a specified number of iterations.</li><li id="7be3" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Reduces training time and mitigates the risk of overfitting.</li><li id="bc07" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Learning Rate with n_estimators Combination:</strong></li><li id="3c19" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Low learning_rate → requires more trees</li><li id="b093" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">High learning_rate → faster learning but riskier</li></ul><h3 id="e89a" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph=""><strong class="an">8.3. Subsampling Strategies</strong></h3><ul class=""><li id="60ab" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph=""><em class="rb">subsample</em> → subset of training instances</li><li id="a77f" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><em class="rb">colsample_bytree / colsample_bylevel / colsample_bynode</em> → subset of features</li><li id="0c76" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Using random subsets reduces correlation among trees and enhances generalization.</li></ul><h3 id="bcb9" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph=""><strong class="an">8.4. Choice of Evaluation Metrics</strong></h3><p id="c530" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">XGBoost supports a variety of evaluation metrics depending on the problem type:</p><ul class=""><li id="a79a" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Classification → <em class="rb">accuracy</em>, <em class="rb">AUC</em>, <em class="rb">logloss</em></li><li id="dc06" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Regression → <em class="rb">RMSE</em>, <em class="rb">MAE</em></li></ul><p id="2a95" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">Selecting the appropriate metric is crucial to ensure the model is optimized for the intended objective.</p><h3 id="be7a" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph=""><strong class="an">8.5. Tree Method and Hardware Optimizations</strong></h3><figure class="qu qv qw qx qy nb mt mu paragraph-image"><div role="button" tabindex="0" class="nc nd fr ne bi nf"><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Press enter or click to view image in full size</span><div class="mt mu rc"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Jj6Lysyr3GeQjacWsopcZw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Jj6Lysyr3GeQjacWsopcZw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Jj6Lysyr3GeQjacWsopcZw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Jj6Lysyr3GeQjacWsopcZw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Jj6Lysyr3GeQjacWsopcZw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Jj6Lysyr3GeQjacWsopcZw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jj6Lysyr3GeQjacWsopcZw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*Jj6Lysyr3GeQjacWsopcZw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Jj6Lysyr3GeQjacWsopcZw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Jj6Lysyr3GeQjacWsopcZw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Jj6Lysyr3GeQjacWsopcZw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Jj6Lysyr3GeQjacWsopcZw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Jj6Lysyr3GeQjacWsopcZw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Jj6Lysyr3GeQjacWsopcZw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bi ma ng c" width="700" height="420" loading="lazy" role="presentation" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_Jj6Lysyr3GeQjacWsopcZw.png"></picture></div></div></figure><p id="4fa4" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">The <em class="rb">tree_method</em> parameter determines how trees are constructed:</p><ul class=""><li id="496f" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph=""><em class="rb">exact</em> → classical method, ideal for small datasets</li><li id="0493" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><em class="rb">hist</em> → histogram-based, faster for large datasets</li><li id="697b" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><em class="rb">gpu_hist</em> → GPU-accelerated, ideal for very large datasets and parallel training</li></ul><h3 id="5f74" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph=""><strong class="an">8.6. Model Interpretability</strong></h3><ul class=""><li id="63be" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">XGBoost models, comprising hundreds of trees, are often considered “black-box.”</li><li id="fa98" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Tools such as SHAP or LIME can be used to explain tree decisions.</li><li id="640d" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><em class="rb">Feature importance</em> (e.g., via <em class="rb">plot_importance</em>) can visualize which features contribute most to the model.</li></ul><p id="a065" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">This section highlights XGBoost’s flexibility and optimization capabilities beyond basic hyperparameters. These insights allow the model to be applied effectively to complex datasets or competitive environments.</p><h2 id="6c26" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">9. Handling Missing Values and Sparsity in XGBoost</h2><p id="34de" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">XGBoost naturally supports working with missing and sparse data, making the algorithm highly practical for real-world datasets.</p><h3 id="5290" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph=""><strong class="an">9.1. Managing Missing Values</strong></h3><ul class=""><li id="91ab" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">Missing values in datasets pose challenges for most machine learning algorithms.</li><li id="c89d" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">XGBoost automatically determines the optimal branch for a missing value while training the tree.</li><li id="a583" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">This significantly reduces the need for imputation during preprocessing.</li></ul><h3 id="f2b1" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph=""><strong class="an">9.2. Sparsity-Aware Optimizations</strong></h3><ul class=""><li id="0b70" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">XGBoost efficiently handles sparse data matrices.</li><li id="f828" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Empty cells resulting from one-hot encoding, categorical variables, or missing values are effectively utilized during training.</li><li id="1738" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">The algorithm learns default directions for missing values and applies them during tree construction.</li><li id="6b98" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">This approach reduces memory usage and increases computational efficiency.</li></ul><h3 id="e3d2" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">9.3. Strengths<strong class="an">:</strong></h3><ul class=""><li id="0ddb" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">Minimizes the need for additional data cleaning on large datasets.</li><li id="126d" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Ensures reliable predictions even in the presence of missing or sparse values.</li><li id="2da7" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Reduces the risk of overfitting, as missing values are handled according to the model’s structure rather than being imputed randomly.</li></ul><h2 id="0171" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">10. Custom Objective Functions and Evaluation Metrics in XGBoost</h2><p id="e809" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">One of XGBoost’s most powerful features is the ability for users to define their own <strong class="nj hm">objective function</strong> and <strong class="nj hm">evaluation metric</strong>. This allows the algorithm to be adapted beyond standard regression or classification tasks to specialized scenarios.</p><h3 id="b702" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">10.1. Custom Objective Function</h3><ul class=""><li id="4647" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">XGBoost enables users to define their own loss functions.</li><li id="27b2" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Particularly useful when standard loss functions (e.g., RMSE, log-loss) are insufficient or when the problem requires a specific error measure.</li><li id="efbe" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Custom objective functions are defined as Python functions that return both the gradient and the Hessian (second-order derivative).</li></ul><pre class="qu qv qw qx qy re rf rg bq rh bc bl"><span id="1d2d" class="ri op hl rf b bh rj rk m rl rm" data-selectable-paragraph=""><span class="hljs-keyword">import</span> xgboost <span class="hljs-keyword">as</span> xgb<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># Custom loss: squared error</span><br><span class="hljs-keyword">def</span> <span class="hljs-title.function">custom_rmse</span>(<span class="hljs-params">preds, dtrain</span>):<br>    labels = dtrain.get_label()<br>    grad = preds - labels          <span class="hljs-comment"># gradient</span><br>    hess = np.ones(<span class="hljs-built_in">len</span>(labels))    <span class="hljs-comment"># hessian</span><br>    <span class="hljs-keyword">return</span> grad, hess<br><br>model = xgb.XGBRegressor(objective=custom_rmse, n_estimators=<span class="hljs-number">100</span>)<br>model.fit(X_train, y_train)</span></pre><ul class=""><li id="12c4" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">grad:</strong> The first derivative of the loss function, indicating the direction in which the model should be updated.</li><li id="97f1" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">hess:</strong> The second derivative, which stabilizes learning rates and updates.</li></ul><h3 id="9383" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">10.2. Custom Evaluation Function</h3><ul class=""><li id="6c65" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">XGBoost can utilize a user-defined metric instead of standard metrics during training.</li><li id="fc43" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">This metric evaluates the model’s performance on the validation set and can be used for mechanisms such as early stopping.</li></ul><pre class="qu qv qw qx qy re rf rg bq rh bc bl"><span id="293d" class="ri op hl rf b bh rj rk m rl rm" data-selectable-paragraph="">def <span class="hljs-built_in">custom_eval</span>(preds, dtrain):<br>    labels = dtrain.<span class="hljs-built_in">get_label</span>()<br>    error = np.<span class="hljs-built_in">mean</span>(np.<span class="hljs-built_in">abs</span>(preds - labels))  # MAE<br>    return <span class="hljs-string">'mae'</span>, error<br><br>model.<span class="hljs-built_in">fit</span>(<br>    X_train, y_train,<br>    eval_set=[(X_test, y_test)],<br>    eval_metric=custom_eval<br>)</span></pre><ul class=""><li id="8ab6" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Must return the format <code class="de rn ro rp rf b">'metric_name', value</code>.</li><li id="88cd" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Enables tracking of performance according to custom criteria beyond standard metrics.</li></ul><h3 id="cd26" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">10.3. Strengths<strong class="an">:</strong></h3><ul class=""><li id="4fa9" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">Allows XGBoost to be adapted for specialized problems.</li><li id="a088" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Applicable in diverse domains (e.g., financial risk modeling, ranking problems, imbalanced datasets).</li><li id="d1bc" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Provides control over the training process according to specific needs.</li></ul><h2 id="adf4" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">11. Model Interpretability in XGBoost Using SHAP and LIME</h2><p id="13cf" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">Due to XGBoost being composed of hundreds of decision trees, it is often regarded as a “black-box” model. In advanced projects, it is critical to explain the model’s decisions and understand which features influence predictions. Tools such as <strong class="nj hm">SHAP</strong> and <strong class="nj hm">LIME</strong> play a central role in this regard.</p><h3 id="032c" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">11.1. SHAP (SHapley Additive exPlanations)</h3><figure class="qu qv qw qx qy nb mt mu paragraph-image"><div role="button" tabindex="0" class="nc nd fr ne bi nf"><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Press enter or click to view image in full size</span><div class="mt mu rq"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*BpzVNC1bwzFmPSNxd5lMjA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*BpzVNC1bwzFmPSNxd5lMjA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*BpzVNC1bwzFmPSNxd5lMjA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*BpzVNC1bwzFmPSNxd5lMjA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*BpzVNC1bwzFmPSNxd5lMjA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*BpzVNC1bwzFmPSNxd5lMjA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BpzVNC1bwzFmPSNxd5lMjA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*BpzVNC1bwzFmPSNxd5lMjA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*BpzVNC1bwzFmPSNxd5lMjA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*BpzVNC1bwzFmPSNxd5lMjA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*BpzVNC1bwzFmPSNxd5lMjA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*BpzVNC1bwzFmPSNxd5lMjA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*BpzVNC1bwzFmPSNxd5lMjA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*BpzVNC1bwzFmPSNxd5lMjA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bi ma ng c" width="700" height="435" loading="lazy" role="presentation" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_BpzVNC1bwzFmPSNxd5lMjA.png"></picture></div></div></figure><ul class=""><li id="a4fa" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">SHAP calculates the contribution of each feature to a prediction based on game theory.</li><li id="871c" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Provides both <strong class="nj hm">global</strong> (overall importance across the dataset) and <strong class="nj hm">local</strong> (for individual observations) explanations.</li><li id="b20c" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Integrates seamlessly with XGBoost.</li></ul><pre class="qu qv qw qx qy re rf rg bq rh bc bl"><span id="486e" class="ri op hl rf b bh rj rk m rl rm" data-selectable-paragraph="">import shap<br><br><span class="hljs-comment"># Calculate SHAP values</span><br>explainer = shap.Explainer(model)<br>shap_values = explainer(X_test)<br><br><span class="hljs-comment"># Global feature importance</span><br>shap.summary_plot(shap_values, X_test)<br><br><span class="hljs-comment"># Local explanation for a single example</span><br>shap.force_plot(explainer.expected_value, shap_values[0,:], X_test[0,:])</span></pre><ul class=""><li id="879b" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">summary_plot</strong> → Visualizes the overall effect of all features.</li><li id="2c27" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">force_plot</strong> → Shows how each feature contributes to a single prediction.</li></ul><h3 id="2b4c" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">11.2. LIME (Local Interpretable Model-agnostic Explanations)</h3><figure class="qu qv qw qx qy nb mt mu paragraph-image"><div role="button" tabindex="0" class="nc nd fr ne bi nf"><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Press enter or click to view image in full size</span><div class="mt mu rq"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*p4kFd_BcPmKf-3-cNkGLew.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*p4kFd_BcPmKf-3-cNkGLew.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*p4kFd_BcPmKf-3-cNkGLew.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*p4kFd_BcPmKf-3-cNkGLew.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*p4kFd_BcPmKf-3-cNkGLew.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*p4kFd_BcPmKf-3-cNkGLew.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p4kFd_BcPmKf-3-cNkGLew.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*p4kFd_BcPmKf-3-cNkGLew.png 640w, https://miro.medium.com/v2/resize:fit:720/1*p4kFd_BcPmKf-3-cNkGLew.png 720w, https://miro.medium.com/v2/resize:fit:750/1*p4kFd_BcPmKf-3-cNkGLew.png 750w, https://miro.medium.com/v2/resize:fit:786/1*p4kFd_BcPmKf-3-cNkGLew.png 786w, https://miro.medium.com/v2/resize:fit:828/1*p4kFd_BcPmKf-3-cNkGLew.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*p4kFd_BcPmKf-3-cNkGLew.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*p4kFd_BcPmKf-3-cNkGLew.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bi ma ng c" width="700" height="370" loading="lazy" role="presentation" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_p4kFd_BcPmKf-3-cNkGLew.png"></picture></div></div></figure><ul class=""><li id="cf17" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">LIME approximates the model’s local behavior by fitting a linear model around selected instances.</li><li id="374f" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">While not as theoretically grounded as SHAP, it provides fast and flexible interpretability.</li><li id="2846" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Can be applied to any model, including XGBoost.</li></ul><pre class="qu qv qw qx qy re rf rg bq rh bc bl"><span id="606b" class="ri op hl rf b bh rj rk m rl rm" data-selectable-paragraph=""><span class="hljs-keyword">from</span> lime <span class="hljs-keyword">import</span> lime_tabular<br><br>explainer = lime_tabular.LimeTabularExplainer(<br>    X_train, mode=<span class="hljs-string">'classification'</span>, feature_names=feature_names<br>)<br><br><span class="hljs-comment"># Explanation for a single example</span><br>exp = explainer.explain_instance(X_test[<span class="hljs-number">0</span>], model.predict_proba)<br>exp.show_in_notebook(show_table=<span class="hljs-literal">True</span>)</span></pre><h3 id="838f" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">11.3. Strengths<strong class="an">:</strong></h3><ul class=""><li id="1015" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">Provides transparency by visualizing the model’s decision process.</li><li id="97ce" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Identifies important features, supporting business and data analysis.</li><li id="3e8c" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Plays a critical role in regulated industries (e.g., finance, healthcare) where explainability is required.</li></ul><h2 id="0019" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">12. Ensemble Techniques with XGBoost: Stacking and Blending</h2><p id="01bc" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">While XGBoost is a powerful standalone model, combining it with other algorithms through ensemble techniques can further enhance predictive performance. These methods are particularly popular in complex datasets and competitive environments.</p><h3 id="6f0f" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">12.1. Stacking (Layered Ensemble)</h3><ul class=""><li id="833b" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">Predictions from different models are used as input features for a learner in the next layer.</li><li id="81df" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">XGBoost often serves as a <strong class="nj hm">meta-learner</strong> or as a strong base model in the first layer.</li></ul><pre class="qu qv qw qx qy re rf rg bq rh bc bl"><span id="1cff" class="ri op hl rf b bh rj rk m rl rm" data-selectable-paragraph=""><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> StackingClassifier<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC<br><br>estimators = [<br>    (<span class="hljs-string">'xgb'</span>, xgb.XGBClassifier(n_estimators=<span class="hljs-number">100</span>, random_state=<span class="hljs-number">42</span>)),<br>    (<span class="hljs-string">'svc'</span>, SVC(probability=<span class="hljs-literal">True</span>))<br>]<br><br>stacking_model = StackingClassifier(<br>    estimators=estimators,<br>    final_estimator=LogisticRegression()<br>)<br><br>stacking_model.fit(X_train, y_train)</span></pre><ul class=""><li id="9f66" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">First layer: Predictions from XGBoost and SVM</li><li id="7051" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Second layer: Logistic Regression combines these predictions to make the final decision</li></ul><h3 id="da70" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">12.2. Blending</h3><ul class=""><li id="0a5e" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">Similar to stacking, but usually relies on a <strong class="nj hm">validation set</strong> for weighted predictions.</li><li id="8dcc" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Faster than stacking and typically preferred for smaller datasets.</li><li id="af21" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">XGBoost can function as either a base model or a meta-learner in blending frameworks.</li></ul><h3 id="adf6" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">13.3. Strengths<strong class="an">:</strong></h3><ul class=""><li id="9368" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">Combines the strengths of different algorithms to achieve higher accuracy.</li><li id="ae54" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Reduces the risk of overfitting when model diversity is increased.</li><li id="890e" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Considered a strong strategy in competitive machine learning environments.</li></ul><h2 id="d063" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">14. Distributed Training and GPU Optimization in XGBoost</h2><p id="9a30" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">XGBoost excels in scalability and speed, particularly when working with large datasets. Distributed training and GPU support are critical features for processing millions of rows efficiently.</p><h3 id="2eab" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">14.1. Distributed Training</h3><ul class=""><li id="f424" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">XGBoost can partition data across multiple machines and train in parallel.</li><li id="5e35" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Dramatically reduces training time for large datasets.</li><li id="13f0" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Integrates with distributed frameworks such as Hadoop or Spark.</li></ul><pre class="qu qv qw qx qy re rf rg bq rh bc bl"><span id="e345" class="ri op hl rf b bh rj rk m rl rm" data-selectable-paragraph=""><span class="hljs-keyword">import</span> dask.dataframe <span class="hljs-keyword">as</span> dd<br><span class="hljs-keyword">from</span> dask_ml.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">import</span> xgboost <span class="hljs-keyword">as</span> xgb<br><br><span class="hljs-comment"># Dask DataFrame</span><br>X = dd.read_csv(<span class="hljs-string">'large_dataset.csv'</span>)<br>y = X.pop(<span class="hljs-string">'target'</span>)<br><br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.2</span>)<br><br><span class="hljs-comment"># Dask XGBoost</span><br>dask_model = xgb.dask.DaskXGBClassifier(<br>    n_estimators=<span class="hljs-number">500</span>,<br>    max_depth=<span class="hljs-number">6</span>,<br>    learning_rate=<span class="hljs-number">0.1</span>,<br>    objective=<span class="hljs-string">'binary:logistic'</span><br>)<br><br>dask_model.fit(X_train, y_train)</span></pre><ul class=""><li id="c3c8" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">During distributed training, XGBoost optimizes data parallelism and workload balancing.</li></ul><h3 id="a924" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">14.2. GPU Utilization</h3><ul class=""><li id="205b" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">GPU computation, particularly with the <strong class="nj hm">gpu_hist</strong> method, accelerates training on large datasets.</li><li id="b4d6" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Supports training on a single GPU or multi-GPU environments.</li></ul><pre class="qu qv qw qx qy re rf rg bq rh bc bl"><span id="0a9b" class="ri op hl rf b bh rj rk m rl rm" data-selectable-paragraph="">gpu_model = xgb.XGBClassifier(<br>    tree_method=<span class="hljs-string">'gpu_hist'</span>,<br>    n_estimators=1000,<br>    max_depth=6,<br>    learning_rate=0.05<br>)<br><br>gpu_model.fit(X_train, y_train)</span></pre><ul class=""><li id="8e7a" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">GPU usage can provide <strong class="nj hm">10–50× faster training</strong> compared to CPU.</li><li id="1180" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">This is one of XGBoost’s most significant performance advantages for large datasets and deep trees.</li></ul><h3 id="a0b7" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">14.3. Strengths<strong class="an">:</strong></h3><ul class=""><li id="be2f" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph="">Enhances capacity to handle large datasets.</li><li id="9fea" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Significantly reduces training time.</li><li id="12a0" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Makes XGBoost scalable for real-world industrial applications through distributed or GPU-accelerated training.</li></ul><h2 id="7926" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">15. Conclusion and Practical Recommendations</h2><p id="82ea" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">XGBoost stands out in the data science landscape due to its high performance, flexibility, and scalability. However, its strength does not automatically make it the best choice in every scenario. This section discusses key considerations when using XGBoost, appropriate use cases, and alternative algorithms.</p><h3 id="3c4c" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">15.1. Critical Considerations for Using XGBoost</h3><ul class=""><li id="771c" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Hyperparameter tuning:</strong> Without properly tuned hyperparameters, the model can underfit or overfit.</li><li id="668b" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Feature engineering:</strong> While XGBoost optimizes for missing and sparse values, quality feature engineering remains critical for structured datasets.</li><li id="69cd" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Model interpretability:</strong> Due to its complex structure, tools such as SHAP or LIME are important to understand decision-making.</li><li id="60a5" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Resource management:</strong> For large datasets, training time should be optimized using GPU acceleration or distributed training strategies.</li></ul><h3 id="ca62" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">15.2. Recommended Applications</h3><ul class=""><li id="ea71" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Structured (tabular) datasets:</strong> Particularly strong in finance, healthcare, sales, and marketing.</li><li id="0d60" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Medium to large datasets:</strong> Efficient training due to parallelization and GPU support.</li><li id="7eb8" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">High accuracy requirements:</strong> Ideal for competitive environments or critical business applications.</li><li id="6863" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Missing or sparse data:</strong> Sparsity-aware optimizations ensure reliable predictions.</li></ul><h3 id="cdf3" class="pr op hl bg oq ps pt ef ou pu pv eh oy ns pw px py nw pz qa qb oa qc qd qe qf bl" data-selectable-paragraph="">15.3. Alternative Algorithms and Comparative Analysis</h3><ul class=""><li id="3667" class="nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Random Forest:</strong> Similar performance with fewer parameters, but slower and more prone to overfitting.</li><li id="9ae5" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Gradient Boosting (scikit-learn):</strong> Less optimized and less parallelized compared to XGBoost.</li><li id="588d" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">LightGBM and CatBoost:</strong> Modern boosting alternatives; LightGBM excels with very large datasets, CatBoost performs well with categorical features.</li><li id="4b84" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph=""><strong class="nj hm">Logistic Regression or Decision Tree:</strong> Preferred for simple or small datasets; highly interpretable but potentially lower performance.</li></ul><blockquote class="rr rs rt"><p id="994a" class="nh ni rb nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">“XGBoost combines the principles of gradient boosting with advanced engineering optimizations, making it one of the most powerful and versatile tools for structured data analysis in both academic research and industry applications.” — Chen &amp; Guestrin, 2016</p></blockquote><h2 id="2c21" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">From Theory to Application: Unboxing XGBoost in Practice</h2><p id="93ad" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">We have thoroughly explored the theoretical depth, optimization mechanisms, and strategies for controlling overfitting inherent in XGBoost. For any data scientist, the final step is conquering the model’s most challenging aspect: <strong class="nj hm">interpretability</strong>.</p><p id="1adf" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">To that end, we have prepared a <strong class="nj hm">comprehensive and hands-on Notebook</strong> demonstrating all the advanced concepts discussed in this article. This includes <strong class="nj hm">Hyperparameter Optimization</strong>, <strong class="nj hm">Feature Importance Metrics</strong>, and crucially, how to explain individual predictions using <strong class="nj hm">SHAP (SHapley Additive exPlanations)</strong> values.</p><p id="e7bd" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">Using this interactive environment, you can practice:</p><ul class=""><li id="b2cc" class="nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe qg qh qi bl" data-selectable-paragraph="">Training and comparing XGBoost models with different hyperparameter sets.</li><li id="164b" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Identifying the optimal parameter combination for peak performance and stability.</li><li id="87b3" class="nh ni hl nj b nk qj nm nn no qk nq nr ns ql nu nv nw qm ny nz oa qn oc od oe qg qh qi bl" data-selectable-paragraph="">Interpreting the model’s global and local predictions using <strong class="nj hm">SHAP visualizations</strong>.</li></ul><p id="9d15" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">Convert theoretical knowledge into practical skill and lift the veil on the XGBoost black box by starting here:</p><p id="4f03" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><a class="ah ru" href="https://www.kaggle.com/code/enesml/xgboost-optimization-and-shap-analysis" rel="noopener ugc nofollow" target="_blank">Kaggle Notebook</a></p><h2 id="a9d2" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">References</h2><p id="4eff" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">Chen, T., &amp; Guestrin, C. (2016). <strong class="nj hm">“XGBoost: A Scalable Tree Boosting System.”</strong> <em class="rb">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</em></p><p id="33e8" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">XGBoost Official Documentation.</strong> (Detailed parameters, features, and best practices for the library.) <a class="ah ru" href="https://xgboost.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank">XGBoost</a></p><p id="c6aa" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). <strong class="nj hm">Deep Learning.</strong> <em class="rb">MIT Press.</em></p><h2 id="a10d" class="oo op hl bg oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl bl" data-selectable-paragraph="">Continue Your Supervised Learning Journey!</h2><p id="6079" class="pw-post-body-paragraph nh ni hl nj b nk pm nm nn no pn nq nr ns po nu nv nw pp ny nz oa pq oc od oe he bl" data-selectable-paragraph="">If you’ve mastered the complexity of XGBoost, it’s beneficial to reinforce the fundamental concepts that underpin supervised learning. Dive deeper into the foundational models with the guides below:</p><p id="2086" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">1. The Foundation: Linear Regression</strong></p><p id="16bd" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">Before tackling complex models, understanding the elegance of simplicity is key. Explore my detailed guide on <strong class="nj hm">Linear Regression: Understanding the Simple Yet Powerful Model</strong> to solidify your grasp on statistical modeling and model interpretability.</p><p id="2109" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><a class="ah ru" rel="noopener" href="https://medium.com/@ml.enesguler/linear-regression-temel-kavramlardan-i%CC%87leri-seviye-uygulamalara-7c89c95091b3" data-discover="true">Linear Regression</a></p><p id="e615" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><strong class="nj hm">2. The Instance-Based Approach: K-Nearest Neighbors (KNN)</strong></p><p id="b8fa" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph="">Moving beyond tree-based models, discover the power of non-parametric, instance-based learning. My guide, <strong class="nj hm">K-Nearest Neighbors: How the Simplest Algorithm Tackles Complex Classification</strong>, provides practical insights into distance metrics and lazy learning.</p><p id="51cb" class="pw-post-body-paragraph nh ni hl nj b nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe he bl" data-selectable-paragraph=""><a class="ah ru" rel="noopener" href="https://medium.com/@ml.enesguler/k-nearest-neighbors-k-nn-s%C4%B1f%C4%B1rdan-senior-seviyeye-kapsaml%C4%B1-rehber-876e27d8c8e8" data-discover="true">KNN</a></p></div></div></div></div></section></div></div></article></div><div class="ac ci"><div class="cp bi gq gr gs gt"><div class="rv rw ac ji"><div class="rx ac"><a class="ry ak ao aq" rel="noopener follow" href="https://medium.com/tag/xgboost?source=post_page-----d88536d87038---------------------------------------" data-discover="true"><div class="rz fr de sa gv sb sc bg b bh ab bl gc">Xgboost</div></a></div><div class="rx ac"><a class="ry ak ao aq" rel="noopener follow" href="https://medium.com/tag/data-science?source=post_page-----d88536d87038---------------------------------------" data-discover="true"><div class="rz fr de sa gv sb sc bg b bh ab bl gc">Data Science</div></a></div><div class="rx ac"><a class="ry ak ao aq" rel="noopener follow" href="https://medium.com/tag/ai?source=post_page-----d88536d87038---------------------------------------" data-discover="true"><div class="rz fr de sa gv sb sc bg b bh ab bl gc">AI</div></a></div><div class="rx ac"><a class="ry ak ao aq" rel="noopener follow" href="https://medium.com/tag/supervised-learning?source=post_page-----d88536d87038---------------------------------------" data-discover="true"><div class="rz fr de sa gv sb sc bg b bh ab bl gc">Supervised Learning</div></a></div><div class="rx ac"><a class="ry ak ao aq" rel="noopener follow" href="https://medium.com/tag/machine-learning?source=post_page-----d88536d87038---------------------------------------" data-discover="true"><div class="rz fr de sa gv sb sc bg b bh ab bl gc">Machine Learning</div></a></div></div></div></div><div class="m"></div><footer class="sd se sf sg sh ac r si sj c"><div class="m ag"><div class="ac ci"><div class="cp bi gq gr gs gt"><div class="ac cw sk"><div class="ac r kr"><div class="sl m"><span class="m sm sn so f e"><div class="ac r kr ks"><div class="pw-multi-vote-icon fr kt ku kv kw"><span data-dd-action-name="Susi presentation tracker clap_footer"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="footerClapButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fd88536d87038&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Funderstanding-xgboost-from-basics-to-advanced-insights-d88536d87038&amp;user=Enes+G%C3%BCler&amp;userId=b6a26fecee8e&amp;source=---footer_actions--d88536d87038---------------------clap_footer------------------" data-discover="true"><div><div class="bn" aria-describedby="10" aria-labelledby="10" role="tooltip"><div tabindex="-1" class="bf"><div class="kx aq ky kz la lb ao lc ld le kw" role="presentation"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></div></a></span></div><div class="pw-multi-vote-count m lf lg lh li lj lk ll"><div><div class="bn" aria-describedby="71" aria-labelledby="71" role="tooltip"><div tabindex="-1" class="bf"><p class="bg b ec ab eb"><button class="ah ai aj fo al am an ao ap aq ar as at au av zv lt">3<span class="m i h g sp sq"></span></button></p></div></div></div></div></div></span><span class="m i h g sp sq"><div class="ac r kr ks"><div class="pw-multi-vote-icon fr kt ku kv kw"><span data-dd-action-name="Susi presentation tracker clap_footer"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="footerClapButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fd88536d87038&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Funderstanding-xgboost-from-basics-to-advanced-insights-d88536d87038&amp;user=Enes+G%C3%BCler&amp;userId=b6a26fecee8e&amp;source=---footer_actions--d88536d87038---------------------clap_footer------------------" data-discover="true"><div><div class="bn" aria-describedby="11" aria-labelledby="11" role="tooltip"><div tabindex="-1" class="bf"><div class="kx aq ky kz la lb ao lc ld le kw" role="presentation"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></div></a></span></div><div class="pw-multi-vote-count m lf lg lh li lj lk ll"><div><div class="bn" aria-describedby="73" aria-labelledby="73" role="tooltip"><div tabindex="-1" class="bf"><p class="bg b ec ab eb"><button class="ah ai aj fo al am an ao ap aq ar as at au av zv lt">3</button></p></div></div></div></div></div></span></div><div class="az ac"><div><div class="bn" aria-describedby="12" aria-labelledby="12" role="tooltip"><div tabindex="-1" class="bf"><button class="aq kx ln lo ac r fs lp lq" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="lr"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg></button></div></div></div></div></div><div class="ac r"><div class="sr m cb"><div><div class="bn" aria-describedby="13" aria-labelledby="13" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_footer"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="footerBookmarkButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd88536d87038&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Funderstanding-xgboost-from-basics-to-advanced-insights-d88536d87038&amp;source=---footer_actions--d88536d87038---------------------bookmark_footer------------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lt" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div><div class="sr m cb"><div class="bn" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bn" aria-describedby="14" aria-labelledby="14" role="tooltip"><div tabindex="-1" class="bf"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="ah fs aj fo al am an mb ap aq ar fe mc md lq me"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div></footer><div class="ss m"><div class="ac ci"><div class="cp bi gq gr gs gt"><div class="ac iv it ir st su"><div class="sv sw sx sy sz ta tb tc td te ac cw"><div class="i l"><a tabindex="0" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---post_author_info--d88536d87038---------------------------------------" data-discover="true"><div class="m fr"><img alt="Enes Güler" class="m fk by tf tg de" width="48" height="48" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_nC_mhaCkoHWhFhomi3ErNw(1).png"><div class="gj by m tf tg fw o ak th"></div></div></a></div><div class="k j e"><a tabindex="0" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---post_author_info--d88536d87038---------------------------------------" data-discover="true"><div class="m fr"><img alt="Enes Güler" class="m fk by ti tj de" width="64" height="64" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_nC_mhaCkoHWhFhomi3ErNw(2).png"><div class="gj by m ti tj fw o ak th"></div></div></a></div><div class="k j e tk cb"><div class="ac"><button class="yg zq aq ac ci r zw kq zx" style="border: 1px solid rgb(36, 36, 36);"><span class="bg b bh ab bl bi"><span class="bn zu">Follow</span></span></button></div></div></div><div class="ac cv cd"><div class="tl tm tn qp qo m"><a class="ah ai aj al am an ao ap aq ar as at au av ac r" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---post_author_info--d88536d87038---------------------------------------" data-discover="true"><h2 class="pw-author-name bg tp tq tr ts tt tu tv ns px py nw qa qb oa qd qe bl"><span class="he to">Written by Enes Güler</span></h2></a><div class="rx ac ix"><div class="m cb"><span class="pw-follower-count bg b bh ab eb"><a class="ah ai aj fo al am an ao ap aq ar as at jg" rel="noopener follow" href="https://medium.com/@ml.enesguler/followers?source=post_page---post_author_info--d88536d87038---------------------------------------" data-discover="true">1 follower</a></span></div><div class="bg b bh ab eb ac tw"><span class="tx m" aria-hidden="true"><span class="bg b bh ab eb">·</span></span><a class="ah ai aj fo al am an ao ap aq ar as at jg" rel="noopener follow" href="https://medium.com/@ml.enesguler/following?source=post_page---post_author_info--d88536d87038---------------------------------------" data-discover="true">1 following</a></div></div><div class="ty m"><p class="bg b bh ab bl"><span class="he">MLOps &amp; Backend Engineer. Focused on Distributed Systems &amp; Automation. 🛠️ Stack: AWS, Kubernetes, Docker, Python.</span></p></div></div></div><div class="i l"><div class="ac"><button class="yg zq aq ac ci r zw kq zx" style="border: 1px solid rgb(36, 36, 36);"><span class="bg b bh ab bl bi"><span class="bn zu">Follow</span></span></button></div></div></div></div></div></div><div class="tz m"><div class="ua bi s ss"></div><div class="ac ci"><div class="cp bi gq gr gs gt"><div class="ac r cw"><h2 class="bg tp or ot ou ov ox oy oz pb pc pd pf pg ph pj pk bl">No responses yet</h2><div class="ac ub"><div><div class="bn" aria-describedby="15" aria-labelledby="15" role="tooltip"><div tabindex="-1" class="bf"><a class="uc ud" href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--d88536d87038---------------------------------------" rel="noopener follow" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" aria-label="Shield with a checkmark" viewBox="0 0 25 25"><path fill-rule="evenodd" d="M11.987 5.036a.754.754 0 0 1 .914-.01c.972.721 1.767 1.218 2.6 1.543.828.322 1.719.485 2.887.505a.755.755 0 0 1 .741.757c-.018 3.623-.43 6.256-1.449 8.21-1.034 1.984-2.662 3.209-4.966 4.083a.75.75 0 0 1-.537-.003c-2.243-.874-3.858-2.095-4.897-4.074-1.024-1.951-1.457-4.583-1.476-8.216a.755.755 0 0 1 .741-.757c1.195-.02 2.1-.182 2.923-.503.827-.322 1.6-.815 2.519-1.535m.468.903c-.897.69-1.717 1.21-2.623 1.564-.898.35-1.856.527-3.026.565.037 3.45.469 5.817 1.36 7.515.884 1.684 2.25 2.762 4.284 3.571 2.092-.81 3.465-1.89 4.344-3.575.886-1.698 1.299-4.065 1.334-7.512-1.149-.039-2.091-.217-2.99-.567-.906-.353-1.745-.873-2.683-1.561m-.009 9.155a2.672 2.672 0 1 0 0-5.344 2.672 2.672 0 0 0 0 5.344m0 1a3.672 3.672 0 1 0 0-7.344 3.672 3.672 0 0 0 0 7.344m-1.813-3.777.525-.526.916.917 1.623-1.625.526.526-2.149 2.152z" clip-rule="evenodd"></path></svg></a></div></div></div></div></div><div class="ue uf ug uh ui m"><div><div class="bg b bh ab bl"><div class="xn"><div class="xv m"><div class="xw ac r"><div class="m fr"><img alt="" class="m fk by bz ca de" width="32" height="32" loading="lazy" role="presentation" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_dmbNkD5D-u45r44go_cf0g.png"><div class="gj by m bz ca fw o ak th"></div></div><div class="bo ac cu cv ci"><p class="bg b bh ab eb">Write a response</p></div></div><div class="de bq ac cv xo xp"><div class="ac cv fr"><span data-dd-action-name="Susi presentation tracker respond_sidebar"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Funderstanding-xgboost-from-basics-to-advanced-insights-d88536d87038&amp;source=---post_responses--d88536d87038---------------------respond_sidebar------------------" data-discover="true"><div class="vq m"><p class="bg b bh ab eb">What are your thoughts?</p></div></a></span><div class="cw xq eb ac xr wr xs"><span class="bg b bh ab eb"><div class="ac"><div><div class="bn" aria-describedby="28" aria-labelledby="28" role="tooltip"><div tabindex="-1" class="bf"><span role="button" aria-label="Bold (⌘B)" class="xx xy xz ya bq lu ci yb yc yd" tabindex="0"><svg width="21" height="21"><path fill-rule="evenodd" d="M10.308 17.993h-5.92l.11-.894.783-.12c.56-.11.79-.224.79-.448V5.37c0-.225-.113-.336-.902-.448H4.5l-.114-.894h6.255c4.02 0 5.58 1.23 5.58 3.13 0 1.896-1.78 3.125-3.79 3.463v.11c2.69.34 4.25 1.56 4.25 3.57 0 2.35-2.01 3.69-6.37 3.69l.02.01h-.02zm-.335-12.96H8.967V10.5h1.23c1.788 0 2.79-1.23 2.79-2.683 0-1.685-1.004-2.803-3.006-2.803v.02zm-.223 6.36h-.783v5.588l1.225.23h.22c1.67 0 3.01-1.004 3.01-2.792 0-2.122-1.566-3.016-3.69-3.016h.018z"></path></svg></span></div></div></div><div><div class="bn" aria-describedby="29" aria-labelledby="29" role="tooltip"><div tabindex="-1" class="bf"><span role="button" aria-label="Italic (⌘I)" class="xx xy xz ya bq lu ci yb yc yd" tabindex="0"><svg width="21" height="21"><path fill-rule="evenodd" d="M9.847 18.04c-.533 0-2.027-.64-1.92-.853l2.027-7.68-.64-.214-1.387 1.494-.427-.427c.534-1.173 1.707-2.667 2.774-2.667.533 0 2.24.534 2.133.854l-2.133 7.786.533.214 1.6-1.067.427.427c-.64 1.066-1.92 2.133-2.987 2.133m2.347-11.733c-.96 0-1.387-.64-1.387-1.387 0-1.067.747-1.92 1.493-1.92.854 0 1.387.64 1.387 1.493-.107 1.067-.747 1.814-1.493 1.814"></path></svg></span></div></div></div></div></span><div class="xt tk ac xr wr xs"><div class="xu"><button class="bg b ec ab bl ye yf yg yh lt lp wi fc fd fe yi yj yk fh fi fj fk bn fl fm" data-testid="CancelResponseButton">Cancel</button></div><button class="bg b ec ab wd ye we wf wg wh wi fc fd wj wk wl fh fi fj fk bn fl fm" disabled="" data-testid="ResponseRespondButton">Respond</button></div></div></div></div></div></div></div></div></div></div></div></div><div class="uj uk ul um un m bx"><div class="ac ci"><div class="cp bi gq gr gs gt"><div class="zy zz dt du dv ty m"><h2 class="bg tp or ot ou ov ox oy oz pb pc pd pf pg ph pj pk bl">More from Enes Güler</h2></div><div class="aba ac kr ji abb abc abd abe abf abg abh abi abj abk abl abm abn abo abp"><div class="abq abr abs qo abt abu abv qp abw abx aby abz zj aca acb acc zk acd ace acf acg"><div class="ach aci acj ack acl ed m"><article class="ed" data-testid="post-preview"><div class="ed sh m"><div class="bi ed"><div class="ed m"><div class="fr ed acm acn aco acp acq acr acs act acu acv acw acx acy" role="link" data-href="https://medium.com/@ml.enesguler/k-means-clustering-from-fundamentals-to-advanced-applications-in-data-science-9803b7b6779d" tabindex="0"><div class="acz"><div aria-label="K-Means Clustering: From Fundamentals to Advanced Applications in Data Science"><div class="adb adc add ade cc"><img alt="K-Means Clustering: From Fundamentals to Advanced Applications in Data Science" class="bi adf adg adh bx" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_KbT1WM1Lcv_sM7HieLzKFQ.webp"></div></div></div><div class="ada ac ci cv"><div class="ac cv xl bi adi adj adk adl"><div class="adm adn ado adp adq ac r"><div class="ry m"><div class="m"><div><div class="m" aria-describedby="92" aria-labelledby="92" role="tooltip"><div tabindex="-1" class="bf"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---author_recirc--d88536d87038----0---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><div class="m fr"><img alt="Enes Güler" class="m fk by adr ads de" width="20" height="20" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_nC_mhaCkoHWhFhomi3ErNw(3).png"><div class="gj by m adr ads fw o ak gk"></div></div></a></div></div></div></div></div><div><div class="m" aria-describedby="93" aria-labelledby="93" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---author_recirc--d88536d87038----0---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">Enes Güler</p></a></div></div></div></div><div class="aea m aeb aec aed aee aef he"><div class="aeg aeh aei aej aek ael aem aen"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/@ml.enesguler/k-means-clustering-from-fundamentals-to-advanced-applications-in-data-science-9803b7b6779d?source=post_page---author_recirc--d88536d87038----0---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><div title="K-Means Clustering: From Fundamentals to Advanced Applications in Data Science"><h2 class="bg hm or ot aeo aep ou ov ox aeq aer oy ns px aes aet py nw qa aeu aev qb oa qd aew aex qe ga adu adv adx adz bl">K-Means Clustering: From Fundamentals to Advanced Applications in Data Science</h2></div><div class="aey m"><h3 class="bg b aez ab ga afa adu adv afb adx adz eb">In a world drowning in data, the ability to segment, categorize, and discover hidden patterns is not just an advantage — it’s a necessity…</h3></div></a></div></div><span class="bg b ec ab eb"><div class="tf ac cw ag"><div class="ac r afe"><span>Oct 25, 2025</span><div class=""><div class="fr afc do ac r"><div class="fw wr afd ac r afe"><div class="fn do dq m de"></div></div><a class="fw ln afd ac r afe" tabindex="-1" rel="noopener follow" href="https://medium.com/@ml.enesguler/k-means-clustering-from-fundamentals-to-advanced-applications-in-data-science-9803b7b6779d?source=post_page---author_recirc--d88536d87038----0---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><div><div class="ac" aria-describedby="192" aria-labelledby="192" role="tooltip"><div tabindex="-1" class="bf"><div class="ac r afz"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>1</span></div></div></div></div></a></div></div></div><div class="ac r aff afg"><div class=""><div><div class="bn" aria-describedby="94" aria-labelledby="94" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_preview"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9803b7b6779d&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Fk-means-clustering-from-fundamentals-to-advanced-applications-in-data-science-9803b7b6779d&amp;source=---author_recirc--d88536d87038----0-----------------bookmark_preview----603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lt afh" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="ua bi uo lr"></div></div></div></div></div></div></div></div></article></div></div><div class="abq abr abs qo abt abu abv qp abw abx aby abz zj aca acb acc zk acd ace acf acg"><div class="ach aci acj ack acl ed m"><article class="ed" data-testid="post-preview"><div class="ed sh m"><div class="bi ed"><div class="ed m"><div class="fr ed acm acn aco acp acq acr acs act acu acv acw acx acy" role="link" data-href="https://medium.com/@ml.enesguler/understanding-principal-component-analysis-pca-b1d8f5aaf766" tabindex="0"><div class="acz"><div aria-label="Understanding Principal Component Analysis (PCA)"><div class="adb adc add ade cc"><img alt="Understanding Principal Component Analysis (PCA)" class="bi adf adg adh bx" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_o7J9PvfXEgAH1_6TKAgehQ.webp"></div></div></div><div class="ada ac ci cv"><div class="ac cv xl bi adi adj adk adl"><div class="adm adn ado adp adq ac r"><div class="ry m"><div class="m"><div><div class="m" aria-describedby="95" aria-labelledby="95" role="tooltip"><div tabindex="-1" class="bf"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---author_recirc--d88536d87038----1---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><div class="m fr"><img alt="Enes Güler" class="m fk by adr ads de" width="20" height="20" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_nC_mhaCkoHWhFhomi3ErNw(3).png"><div class="gj by m adr ads fw o ak gk"></div></div></a></div></div></div></div></div><div><div class="m" aria-describedby="96" aria-labelledby="96" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---author_recirc--d88536d87038----1---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">Enes Güler</p></a></div></div></div></div><div class="aea m aeb aec aed aee aef he"><div class="aeg aeh aei aej aek ael aem aen"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/@ml.enesguler/understanding-principal-component-analysis-pca-b1d8f5aaf766?source=post_page---author_recirc--d88536d87038----1---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><div title=""><h2 class="bg hm or ot aeo aep ou ov ox aeq aer oy ns px aes aet py nw qa aeu aev qb oa qd aew aex qe ga adu adv adx adz bl">Understanding Principal Component Analysis (PCA)</h2></div><div class="aey m"><h3 class="bg b aez ab ga afa adu adv afb adx adz eb">From Zero to Expert PCA: All the Theory and Practical Code Examples You Need to Know</h3></div></a></div></div><span class="bg b ec ab eb"><div class="tf ac cw ag"><div class="ac r afe"><span>Oct 15, 2025</span><div class=""><div class="fr afc do ac r"><div class="fw wr afd ac r afe"><div class="fn do dq m de"></div></div><a class="fw ln afd ac r afe" tabindex="-1" rel="noopener follow" href="https://medium.com/@ml.enesguler/understanding-principal-component-analysis-pca-b1d8f5aaf766?source=post_page---author_recirc--d88536d87038----1---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><div><div class="ac" aria-describedby="193" aria-labelledby="193" role="tooltip"><div tabindex="-1" class="bf"><div class="ac r afz"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>1</span></div></div></div></div></a></div></div></div><div class="ac r aff afg"><div class=""><div><div class="bn" aria-describedby="97" aria-labelledby="97" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_preview"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb1d8f5aaf766&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Funderstanding-principal-component-analysis-pca-b1d8f5aaf766&amp;source=---author_recirc--d88536d87038----1-----------------bookmark_preview----603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lt afh" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="ua bi uo lr"></div></div></div></div></div></div></div></div></article></div></div><div class="abq abr abs qo abt abu abv qp abw abx aby abz zj aca acb acc zk acd ace acf acg"><div class="ach aci acj ack acl ed m"><article class="ed" data-testid="post-preview"><div class="ed sh m"><div class="bi ed"><div class="ed m"><div class="fr ed acm acn aco acp acq acr acs act acu acv acw acx acy" role="link" data-href="https://medium.com/@ml.enesguler/k-nearest-neighbors-k-nn-sıfırdan-senior-seviyeye-kapsamlı-rehber-876e27d8c8e8" tabindex="0"><div class="acz"><div aria-label="K-Nearest Neighbors (K-NN): Sıfırdan Senior Seviyeye Kapsamlı Rehber"><div class="adb adc add ade cc"><img alt="K-Nearest Neighbors (K-NN): Sıfırdan Senior Seviyeye Kapsamlı Rehber" class="bi adf adg adh bx" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_3-cl97wbIbG2CV04B6qgRA.webp"></div></div></div><div class="ada ac ci cv"><div class="ac cv xl bi adi adj adk adl"><div class="adm adn ado adp adq ac r"><div class="ry m"><div class="m"><div><div class="m" aria-describedby="98" aria-labelledby="98" role="tooltip"><div tabindex="-1" class="bf"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---author_recirc--d88536d87038----2---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><div class="m fr"><img alt="Enes Güler" class="m fk by adr ads de" width="20" height="20" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_nC_mhaCkoHWhFhomi3ErNw(3).png"><div class="gj by m adr ads fw o ak gk"></div></div></a></div></div></div></div></div><div><div class="m" aria-describedby="99" aria-labelledby="99" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---author_recirc--d88536d87038----2---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">Enes Güler</p></a></div></div></div></div><div class="aea m aeb aec aed aee aef he"><div class="aeg aeh aei aej aek ael aem aen"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/@ml.enesguler/k-nearest-neighbors-k-nn-s%C4%B1f%C4%B1rdan-senior-seviyeye-kapsaml%C4%B1-rehber-876e27d8c8e8?source=post_page---author_recirc--d88536d87038----2---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><div title=""><h2 class="bg hm or ot aeo aep ou ov ox aeq aer oy ns px aes aet py nw qa aeu aev qb oa qd aew aex qe ga adu adv adx adz bl">K-Nearest Neighbors (K-NN): Sıfırdan Senior Seviyeye Kapsamlı Rehber</h2></div><div class="aey m"><h3 class="bg b aez ab ga afa adu adv afb adx adz eb">Temelden ileri seviyeye K-Nearest Neighbors (K-NN) rehberi: teori, uygulama ve ipuçları</h3></div></a></div></div><span class="bg b ec ab eb"><div class="tf ac cw ag"><div class="ac r afe"><span>Aug 27, 2025</span><div class=""><div class="fr afc do ac r"><div class="fw wr afd ac r afe"><div class="fn do dq m de"></div></div><a class="fw ln afd ac r afe" tabindex="-1" rel="noopener follow" href="https://medium.com/@ml.enesguler/k-nearest-neighbors-k-nn-s%C4%B1f%C4%B1rdan-senior-seviyeye-kapsaml%C4%B1-rehber-876e27d8c8e8?source=post_page---author_recirc--d88536d87038----2---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><div><div class="ac" aria-describedby="194" aria-labelledby="194" role="tooltip"><div tabindex="-1" class="bf"><div class="ac r afz"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>1</span></div></div></div></div></a></div></div></div><div class="ac r aff afg"><div class=""><div><div class="bn" aria-describedby="100" aria-labelledby="100" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_preview"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F876e27d8c8e8&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Fk-nearest-neighbors-k-nn-s%25C4%25B1f%25C4%25B1rdan-senior-seviyeye-kapsaml%25C4%25B1-rehber-876e27d8c8e8&amp;source=---author_recirc--d88536d87038----2-----------------bookmark_preview----603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lt afh" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="ua bi uo lr"></div></div></div></div></div></div></div></div></article></div></div><div class="abq abr abs qo abt abu abv qp abw abx aby abz zj aca acb acc zk acd ace acf acg"><div class="ach aci acj ack acl ed m"><article class="ed" data-testid="post-preview"><div class="ed sh m"><div class="bi ed"><div class="ed m"><div class="fr ed acm acn aco acp acq acr acs act acu acv acw acx acy" role="link" data-href="https://medium.com/@ml.enesguler/linear-regression-temel-kavramlardan-i̇leri-seviye-uygulamalara-7c89c95091b3" tabindex="0"><div class="acz"><div aria-label="Linear Regression: Temel Kavramlardan İleri Seviye Uygulamalara"><div class="adb adc add ade cc"><img alt="Linear Regression: Temel Kavramlardan İleri Seviye Uygulamalara" class="bi adf adg adh bx" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_VGMZMeETdSzocCSQLhKSMQ.webp"></div></div></div><div class="ada ac ci cv"><div class="ac cv xl bi adi adj adk adl"><div class="adm adn ado adp adq ac r"><div class="ry m"><div class="m"><div><div class="m" aria-describedby="101" aria-labelledby="101" role="tooltip"><div tabindex="-1" class="bf"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---author_recirc--d88536d87038----3---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><div class="m fr"><img alt="Enes Güler" class="m fk by adr ads de" width="20" height="20" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_nC_mhaCkoHWhFhomi3ErNw(3).png"><div class="gj by m adr ads fw o ak gk"></div></div></a></div></div></div></div></div><div><div class="m" aria-describedby="102" aria-labelledby="102" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---author_recirc--d88536d87038----3---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">Enes Güler</p></a></div></div></div></div><div class="aea m aeb aec aed aee aef he"><div class="aeg aeh aei aej aek ael aem aen"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/@ml.enesguler/linear-regression-temel-kavramlardan-i%CC%87leri-seviye-uygulamalara-7c89c95091b3?source=post_page---author_recirc--d88536d87038----3---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><div title=""><h2 class="bg hm or ot aeo aep ou ov ox aeq aer oy ns px aes aet py nw qa aeu aev qb oa qd aew aex qe ga adu adv adx adz bl">Linear Regression: Temel Kavramlardan İleri Seviye Uygulamalara</h2></div><div class="aey m"><h3 class="bg b aez ab ga afa adu adv afb adx adz eb">Bir değişkenin diğerini nasıl etkilediğini keşfetmek ister misiniz? Lineer regresyonun gücünü görün.</h3></div></a></div></div><span class="bg b ec ab eb"><div class="tf ac cw ag"><div class="ac r afe"><span>Sep 6, 2025</span><div class=""><div class="fr afc do ac r"><div class="fw wr afd ac r afe"><div class="fn do dq m de"></div></div><a class="fw ln afd ac r afe" tabindex="-1" rel="noopener follow" href="https://medium.com/@ml.enesguler/linear-regression-temel-kavramlardan-i%CC%87leri-seviye-uygulamalara-7c89c95091b3?source=post_page---author_recirc--d88536d87038----3---------------------603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><div><div class="ac" aria-describedby="195" aria-labelledby="195" role="tooltip"><div tabindex="-1" class="bf"><div class="ac r afz"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>1</span></div></div></div></div></a></div></div></div><div class="ac r aff afg"><div class=""><div><div class="bn" aria-describedby="103" aria-labelledby="103" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_preview"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7c89c95091b3&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40ml.enesguler%2Flinear-regression-temel-kavramlardan-i%25CC%2587leri-seviye-uygulamalara-7c89c95091b3&amp;source=---author_recirc--d88536d87038----3-----------------bookmark_preview----603f8db8_2546_4c93_a3bf_c99bfefe73a2--------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lt afh" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div><div class="ua bi uo dr ds afi afj afk"></div><div class="ac su st ir it iv"><a class="bg b bh ab bl rz yf yg yh lt lp wi fc fd fe yi yj yk fh afl afm afn afo afp fi fj fk bn fl fm" rel="noopener follow" href="https://medium.com/@ml.enesguler?source=post_page---author_recirc--d88536d87038---------------------------------------" data-discover="true"><div class="m fm">See all from Enes Güler</div></a></div></div></div><div class="ua bi uo afq afr afs aft afu"></div><div class="ac ci"><div class="cp bi gq gr gs gt"><div class="afv afw m"><h2 class="bg tp or ot ou ov ox oy oz pb pc pd pf pg ph pj pk bl">Recommended from Medium</h2><div class="qu qv qw qx qy m"><div class="aba ac kr ji abb abc abd abe abf abg abh abi abj abk abl abm abn abo abp"><div class="abq abr abs qo abt abu abv qp abw abx aby abz zj aca acb acc zk acd ace acf acg"><div class="ach aci acj ack acl ed m"><article class="ed" data-testid="post-preview"><div class="ed sh m"><div class="bi ed"><div class="ed m"><div class="fr ed acm acn aco acp acq acr acs act acu acv acw acx acy" role="link" data-href="https://medium.com/nextgenllm/the-complete-guide-to-vector-similarity-euclidean-distance-cosine-similarity-dot-product-8bb60b967746" tabindex="0"><div class="acz"><div aria-label="The Complete Guide to Vector Similarity: Euclidean Distance, Cosine Similarity &amp; Dot Product…"><div class="adb adc add ade cc"><img alt="The Complete Guide to Vector Similarity: Euclidean Distance, Cosine Similarity &amp; Dot Product…" class="bi adf adg adh bx" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/0_nM0-p2e1gTZPQTyf.webp"></div></div></div><div class="ada ac ci cv"><div class="ac cv xl bi adi adj adk adl"><div class="adm adn ado adp adq ac r"><div class="ry m"><div><div class="m" aria-describedby="104" aria-labelledby="104" role="tooltip"><div tabindex="-1" class="bf"><a href="https://medium.com/nextgenllm?source=post_page---read_next_recirc--d88536d87038----0---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" rel="noopener follow"><div class="fr"><img alt="NextGenAI" class="de afx m ads adr" width="20" height="20" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_nUcolRUzhDSgRLASrTkxKQ.jpg"><div class="afx m adr ads fw o gj gk"></div></div></a></div></div></div></div><div class="to m gc"><p class="bg b ec ab eb">In</p></div><div class="m"><div><div class="m" aria-describedby="105" aria-labelledby="105" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" href="https://medium.com/nextgenllm?source=post_page---read_next_recirc--d88536d87038----0---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" rel="noopener follow"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">NextGenAI</p></a></div></div></div></div><div class="afy m"><p class="bg b ec ab eb">by</p></div><div><div class="m" aria-describedby="106" aria-labelledby="106" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" rel="noopener follow" href="https://medium.com/@premvishnoi?source=post_page---read_next_recirc--d88536d87038----0---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">Prem Vishnoi(cloudvala)</p></a></div></div></div></div><div class="aea m aeb aec aed aee aef he"><div class="aeg aeh aei aej aek ael aem aen"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/nextgenllm/the-complete-guide-to-vector-similarity-euclidean-distance-cosine-similarity-dot-product-8bb60b967746?source=post_page---read_next_recirc--d88536d87038----0---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div title="The Complete Guide to Vector Similarity: Euclidean Distance, Cosine Similarity &amp; Dot Product…"><h2 class="bg hm or ot aeo aep ou ov ox aeq aer oy ns px aes aet py nw qa aeu aev qb oa qd aew aex qe ga adu adv adx adz bl">The Complete Guide to Vector Similarity: Euclidean Distance, Cosine Similarity &amp; Dot Product…</h2></div><div class="aey m"><h3 class="bg b aez ab ga afa adu adv afb adx adz eb">Measuring similarity between embeddings is a fundamental task in machine learning (ML), natural language processing (NLP), and information…</h3></div></a></div></div><span class="bg b ec ab eb"><div class="tf ac cw ag"><div class="ac r afe"><div class="sh ac"><button class="m ak aq ao" aria-label="Member-only story"><div class=""><div><div class="bn" aria-describedby="107" aria-labelledby="107" role="tooltip"><div tabindex="-1" class="bf"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div><span>Jul 12, 2025</span><div class=""><div class="fr afc do ac r"><div class="fw wr afd ac r afe"><div class="fn do dq m de"></div></div><a class="fw ln afd ac r afe" tabindex="-1" rel="noopener follow" href="https://medium.com/nextgenllm/the-complete-guide-to-vector-similarity-euclidean-distance-cosine-similarity-dot-product-8bb60b967746?source=post_page---read_next_recirc--d88536d87038----0---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div><div class="ac" aria-describedby="196" aria-labelledby="196" role="tooltip"><div tabindex="-1" class="bf"><div class="ac r afz"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>128</span></div></div></div></div></a></div></div></div><div class="ac r aff afg"><div class=""><div><div class="bn" aria-describedby="108" aria-labelledby="108" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_preview"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8bb60b967746&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnextgenllm%2Fthe-complete-guide-to-vector-similarity-euclidean-distance-cosine-similarity-dot-product-8bb60b967746&amp;source=---read_next_recirc--d88536d87038----0-----------------bookmark_preview----137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lt afh" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="ua bi uo lr"></div></div></div></div></div></div></div></div></article></div></div><div class="abq abr abs qo abt abu abv qp abw abx aby abz zj aca acb acc zk acd ace acf acg"><div class="ach aci acj ack acl ed m"><article class="ed" data-testid="post-preview"><div class="ed sh m"><div class="bi ed"><div class="ed m"><div class="fr ed acm acn aco acp acq acr acs act acu acv acw acx acy" role="link" data-href="https://medium.com/@QuarkAndCode/time-series-feature-engineering-with-tsfresh-and-automl-62b3b6b9dab7" tabindex="0"><div class="acz"><div aria-label="Time-Series Feature Engineering with tsfresh and AutoML"><div class="adb adc add ade cc"><img alt="Time-Series Feature Engineering with tsfresh and AutoML" class="bi adf adg adh bx" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_2n5cvYGRBC9hC69atm5VmA.webp"></div></div></div><div class="ada ac ci cv"><div class="ac cv xl bi adi adj adk adl"><div class="adm adn ado adp adq ac r"><div class="ry m"><div class="m"><div><div class="m" aria-describedby="109" aria-labelledby="109" role="tooltip"><div tabindex="-1" class="bf"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@QuarkAndCode?source=post_page---read_next_recirc--d88536d87038----1---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div class="m fr"><img alt="QuarkAndCode" class="m fk by adr ads de" width="20" height="20" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_N098LoAzsqGv17g66NlrDA.jpg"><div class="gj by m adr ads fw o ak gk"></div></div></a></div></div></div></div></div><div><div class="m" aria-describedby="110" aria-labelledby="110" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" rel="noopener follow" href="https://medium.com/@QuarkAndCode?source=post_page---read_next_recirc--d88536d87038----1---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">QuarkAndCode</p></a></div></div></div></div><div class="aea m aeb aec aed aee aef he"><div class="aeg aeh aei aej aek ael aem aen"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/@QuarkAndCode/time-series-feature-engineering-with-tsfresh-and-automl-62b3b6b9dab7?source=post_page---read_next_recirc--d88536d87038----1---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div title=""><h2 class="bg hm or ot aeo aep ou ov ox aeq aer oy ns px aes aet py nw qa aeu aev qb oa qd aew aex qe ga adu adv adx adz bl">Time-Series Feature Engineering with tsfresh and AutoML</h2></div><div class="aey m"><h3 class="bg b aez ab ga afa adu adv afb adx adz eb">Explore how tsfresh and AutoML automate time-series feature engineering for multi-step forecasting, authorship attribution and AI…</h3></div></a></div></div><span class="bg b ec ab eb"><div class="tf ac cw ag"><div class="ac r afe"><div class="sh ac"><button class="m ak aq ao" aria-label="Member-only story"><div class=""><div><div class="bn" aria-describedby="111" aria-labelledby="111" role="tooltip"><div tabindex="-1" class="bf"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div><span>Dec 2, 2025</span><div class=""><div class="fr afc do ac r"><div class="fw wr afd ac r afe"><div class="fn do dq m de"></div></div><a class="fw ln afd ac r afe" tabindex="-1" rel="noopener follow" href="https://medium.com/@QuarkAndCode/time-series-feature-engineering-with-tsfresh-and-automl-62b3b6b9dab7?source=post_page---read_next_recirc--d88536d87038----1---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"></a></div></div></div><div class="ac r aff afg"><div class=""><div><div class="bn" aria-describedby="112" aria-labelledby="112" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_preview"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F62b3b6b9dab7&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40QuarkAndCode%2Ftime-series-feature-engineering-with-tsfresh-and-automl-62b3b6b9dab7&amp;source=---read_next_recirc--d88536d87038----1-----------------bookmark_preview----137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lt afh" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div></div><div class="aba ac kr ji abb abc abd abe abf abg abh abi abj abk abl abm abn abo abp"><div class="abq abr abs qo abt abu abv qp abw abx aby abz zj aca acb acc zk acd ace acf acg"><div class="ach aci acj ack acl ed m"><article class="ed" data-testid="post-preview"><div class="ed sh m"><div class="bi ed"><div class="ed m"><div class="fr ed acm acn aco acp acq acr acs act acu acv acw acx acy" role="link" data-href="https://medium.com/@maheera_amjad/word-embeddings-explained-word2vec-glove-and-beyond-4430927f3dea" tabindex="0"><div class="acz"><div aria-label="Word Embeddings Explained: Word2Vec, GloVe, and Beyond"><div class="adb adc add ade cc"><img alt="Word Embeddings Explained: Word2Vec, GloVe, and Beyond" class="bi adf adg adh bx" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_unNcHM81D3n8ETqfiXZ6vg.webp"></div></div></div><div class="ada ac ci cv"><div class="ac cv xl bi adi adj adk adl"><div class="adm adn ado adp adq ac r"><div class="ry m"><div class="m"><div><div class="m" aria-describedby="113" aria-labelledby="113" role="tooltip"><div tabindex="-1" class="bf"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@maheera_amjad?source=post_page---read_next_recirc--d88536d87038----0---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div class="m fr"><img alt="Maheera Amjad" class="m fk by adr ads de" width="20" height="20" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_--CK9cB911PX5FxmaEfVGQ.png"><div class="gj by m adr ads fw o ak gk"></div></div></a></div></div></div></div></div><div><div class="m" aria-describedby="114" aria-labelledby="114" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" rel="noopener follow" href="https://medium.com/@maheera_amjad?source=post_page---read_next_recirc--d88536d87038----0---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">Maheera Amjad</p></a></div></div></div></div><div class="aea m aeb aec aed aee aef he"><div class="aeg aeh aei aej aek ael aem aen"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/@maheera_amjad/word-embeddings-explained-word2vec-glove-and-beyond-4430927f3dea?source=post_page---read_next_recirc--d88536d87038----0---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div title=""><h2 class="bg hm or ot aeo aep ou ov ox aeq aer oy ns px aes aet py nw qa aeu aev qb oa qd aew aex qe ga adu adv adx adz bl">Word Embeddings Explained: Word2Vec, GloVe, and Beyond</h2></div><div class="aey m"><h3 class="bg b aez ab ga afa adu adv afb adx adz eb">Learn how vector math makes machines understand word relationships.</h3></div></a></div></div><span class="bg b ec ab eb"><div class="tf ac cw ag"><div class="ac r afe"><div class="sh ac"><button class="m ak aq ao" aria-label="Member-only story"><div class=""><div><div class="bn" aria-describedby="115" aria-labelledby="115" role="tooltip"><div tabindex="-1" class="bf"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div><span>Sep 29, 2025</span><div class=""><div class="fr afc do ac r"><div class="fw wr afd ac r afe"><div class="fn do dq m de"></div></div><a class="fw ln afd ac r afe" tabindex="-1" rel="noopener follow" href="https://medium.com/@maheera_amjad/word-embeddings-explained-word2vec-glove-and-beyond-4430927f3dea?source=post_page---read_next_recirc--d88536d87038----0---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div><div class="ac" aria-describedby="197" aria-labelledby="197" role="tooltip"><div tabindex="-1" class="bf"><div class="ac r afz"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>326</span></div></div></div></div></a></div></div></div><div class="ac r aff afg"><div class=""><div><div class="bn" aria-describedby="116" aria-labelledby="116" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_preview"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4430927f3dea&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40maheera_amjad%2Fword-embeddings-explained-word2vec-glove-and-beyond-4430927f3dea&amp;source=---read_next_recirc--d88536d87038----0-----------------bookmark_preview----137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lt afh" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="ua bi uo lr"></div></div></div></div></div></div></div></div></article></div></div><div class="abq abr abs qo abt abu abv qp abw abx aby abz zj aca acb acc zk acd ace acf acg"><div class="ach aci acj ack acl ed m"><article class="ed" data-testid="post-preview"><div class="ed sh m"><div class="bi ed"><div class="ed m"><div class="fr ed acm acn aco acp acq acr acs act acu acv acw acx acy" role="link" data-href="https://medium.com/python-in-plain-english/understanding-word2vec-cbow-and-skip-gram-8668d30bd7ef" tabindex="0"><div class="acz"><div aria-label="Understanding Word2Vec — CBOW and Skip-Gram"><div class="adb adc add ade cc"><img alt="Understanding Word2Vec — CBOW and Skip-Gram" class="bi adf adg adh bx" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/0_WaAGOjZRmq8bBTS5.webp"></div></div></div><div class="ada ac ci cv"><div class="ac cv xl bi adi adj adk adl"><div class="adm adn ado adp adq ac r"><div class="ry m"><div><div class="m" aria-describedby="117" aria-labelledby="117" role="tooltip"><div tabindex="-1" class="bf"><a href="https://medium.com/python-in-plain-english?source=post_page---read_next_recirc--d88536d87038----1---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" rel="noopener follow"><div class="fr"><img alt="Python in Plain English" class="de afx m ads adr" width="20" height="20" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_VA3oGfprJgj5fRsTjXp6fA@2x.png"><div class="afx m adr ads fw o gj gk"></div></div></a></div></div></div></div><div class="to m gc"><p class="bg b ec ab eb">In</p></div><div class="m"><div><div class="m" aria-describedby="118" aria-labelledby="118" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" href="https://medium.com/python-in-plain-english?source=post_page---read_next_recirc--d88536d87038----1---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" rel="noopener follow"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">Python in Plain English</p></a></div></div></div></div><div class="afy m"><p class="bg b ec ab eb">by</p></div><div><div class="m" aria-describedby="119" aria-labelledby="119" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" rel="noopener follow" href="https://medium.com/@helenedk?source=post_page---read_next_recirc--d88536d87038----1---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">Helene Kegel</p></a></div></div></div></div><div class="aea m aeb aec aed aee aef he"><div class="aeg aeh aei aej aek ael aem aen"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/python-in-plain-english/understanding-word2vec-cbow-and-skip-gram-8668d30bd7ef?source=post_page---read_next_recirc--d88536d87038----1---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div title=""><h2 class="bg hm or ot aeo aep ou ov ox aeq aer oy ns px aes aet py nw qa aeu aev qb oa qd aew aex qe ga adu adv adx adz bl">Understanding Word2Vec — CBOW and Skip-Gram</h2></div><div class="aey m"><h3 class="bg b aez ab ga afa adu adv afb adx adz eb">In this article, we will take a look at the word embedding model called Word2Vec, which is a model that learns vector representations (i.e…</h3></div></a></div></div><span class="bg b ec ab eb"><div class="tf ac cw ag"><div class="ac r afe"><div class="sh ac"><button class="m ak aq ao" aria-label="Member-only story"><div class=""><div><div class="bn" aria-describedby="120" aria-labelledby="120" role="tooltip"><div tabindex="-1" class="bf"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div><span>Aug 19, 2025</span><div class=""><div class="fr afc do ac r"><div class="fw wr afd ac r afe"><div class="fn do dq m de"></div></div><a class="fw ln afd ac r afe" tabindex="-1" rel="noopener follow" href="https://medium.com/python-in-plain-english/understanding-word2vec-cbow-and-skip-gram-8668d30bd7ef?source=post_page---read_next_recirc--d88536d87038----1---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"></a></div></div></div><div class="ac r aff afg"><div class=""><div><div class="bn" aria-describedby="121" aria-labelledby="121" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_preview"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8668d30bd7ef&amp;operation=register&amp;redirect=https%3A%2F%2Fpython.plainenglish.io%2Funderstanding-word2vec-cbow-and-skip-gram-8668d30bd7ef&amp;source=---read_next_recirc--d88536d87038----1-----------------bookmark_preview----137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lt afh" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="ua bi uo lr"></div></div></div></div></div></div></div></div></article></div></div><div class="abq abr abs qo abt abu abv qp abw abx aby abz zj aca acb acc zk acd ace acf acg"><div class="ach aci acj ack acl ed m"><article class="ed" data-testid="post-preview"><div class="ed sh m"><div class="bi ed"><div class="ed m"><div class="fr ed acm acn aco acp acq acr acs act acu acv acw acx acy" role="link" data-href="https://medium.com/@satyamcser/beyond-gradient-descent-variational-automata-for-reinforcement-learning-68d49b5531da" tabindex="0"><div class="acz"><div aria-label="Beyond Gradient Descent: Variational Automata for Reinforcement Learning"><div class="adb adc add ade cc"><img alt="Beyond Gradient Descent: Variational Automata for Reinforcement Learning" class="bi adf adg adh bx" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/0_0_JVyN8cmNR6BTge.webp"></div></div></div><div class="ada ac ci cv"><div class="ac cv xl bi adi adj adk adl"><div class="adm adn ado adp adq ac r"><div class="ry m"><div class="m"><div><div class="m" aria-describedby="122" aria-labelledby="122" role="tooltip"><div tabindex="-1" class="bf"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@satyamcser?source=post_page---read_next_recirc--d88536d87038----2---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div class="m fr"><img alt="Satyam Mishra" class="m fk by adr ads de" width="20" height="20" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_JTDk7VQ6kwhPh_4q-Fp1lQ.jpg"><div class="gj by m adr ads fw o ak gk"></div></div></a></div></div></div></div></div><div><div class="m" aria-describedby="123" aria-labelledby="123" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" rel="noopener follow" href="https://medium.com/@satyamcser?source=post_page---read_next_recirc--d88536d87038----2---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">Satyam Mishra</p></a></div></div></div></div><div class="aea m aeb aec aed aee aef he"><div class="aeg aeh aei aej aek ael aem aen"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/@satyamcser/beyond-gradient-descent-variational-automata-for-reinforcement-learning-68d49b5531da?source=post_page---read_next_recirc--d88536d87038----2---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div title="Beyond Gradient Descent: Variational Automata for Reinforcement Learning"><h2 class="bg hm or ot aeo aep ou ov ox aeq aer oy ns px aes aet py nw qa aeu aev qb oa qd aew aex qe ga adu adv adx adz bl">Beyond Gradient Descent: Variational Automata for Reinforcement Learning</h2></div><div class="aey m"><h3 class="bg b aez ab ga afa adu adv afb adx adz eb">How Structured Constraints and Information Geometry Could Redefine Policy Optimization</h3></div></a></div></div><span class="bg b ec ab eb"><div class="tf ac cw ag"><div class="ac r afe"><div class="sh ac"><button class="m ak aq ao" aria-label="Member-only story"><div class=""><div><div class="bn" aria-describedby="124" aria-labelledby="124" role="tooltip"><div tabindex="-1" class="bf"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div><span>Aug 16, 2025</span><div class=""><div class="fr afc do ac r"><div class="fw wr afd ac r afe"><div class="fn do dq m de"></div></div><a class="fw ln afd ac r afe" tabindex="-1" rel="noopener follow" href="https://medium.com/@satyamcser/beyond-gradient-descent-variational-automata-for-reinforcement-learning-68d49b5531da?source=post_page---read_next_recirc--d88536d87038----2---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div><div class="ac" aria-describedby="198" aria-labelledby="198" role="tooltip"><div tabindex="-1" class="bf"><div class="ac r afz"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>17</span></div></div></div></div></a></div></div></div><div class="ac r aff afg"><div class=""><div><div class="bn" aria-describedby="125" aria-labelledby="125" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_preview"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F68d49b5531da&amp;operation=register&amp;redirect=https%3A%2F%2Fsatyamcser.medium.com%2Fbeyond-gradient-descent-variational-automata-for-reinforcement-learning-68d49b5531da&amp;source=---read_next_recirc--d88536d87038----2-----------------bookmark_preview----137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lt afh" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span><div class="k j e"><div class="ua bi uo lr"></div></div></div></div></div></div></div></div></article></div></div><div class="abq abr abs qo abt abu abv qp abw abx aby abz zj aca acb acc zk acd ace acf acg"><div class="ach aci acj ack acl ed m"><article class="ed" data-testid="post-preview"><div class="ed sh m"><div class="bi ed"><div class="ed m"><div class="fr ed acm acn aco acp acq acr acs act acu acv acw acx acy" role="link" data-href="https://medium.com/data-science-collective/vector-error-correction-model-a9ed374390f5" tabindex="0"><div class="acz"><div aria-label="Vector Error Correction Model"><div class="adb adc add ade cc"><img alt="Vector Error Correction Model" class="bi adf adg adh bx" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/0_pBwY6jN89juRRETL.webp"></div></div></div><div class="ada ac ci cv"><div class="ac cv xl bi adi adj adk adl"><div class="adm adn ado adp adq ac r"><div class="ry m"><div><div class="m" aria-describedby="126" aria-labelledby="126" role="tooltip"><div tabindex="-1" class="bf"><a href="https://medium.com/data-science-collective?source=post_page---read_next_recirc--d88536d87038----3---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" rel="noopener follow"><div class="fr"><img alt="Data Science Collective" class="de afx m ads adr" width="20" height="20" loading="lazy" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1_0nV0Q-FBHj94Kggq00pG2Q.jpg"><div class="afx m adr ads fw o gj gk"></div></div></a></div></div></div></div><div class="to m gc"><p class="bg b ec ab eb">In</p></div><div class="m"><div><div class="m" aria-describedby="127" aria-labelledby="127" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" href="https://medium.com/data-science-collective?source=post_page---read_next_recirc--d88536d87038----3---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" rel="noopener follow"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">Data Science Collective</p></a></div></div></div></div><div class="afy m"><p class="bg b ec ab eb">by</p></div><div><div class="m" aria-describedby="128" aria-labelledby="128" role="tooltip"><div tabindex="-1" class="bf"><a class="ah ai aj fo al am an ao ap aq ar as at jg ac r" rel="noopener follow" href="https://medium.com/@egorhowell?source=post_page---read_next_recirc--d88536d87038----3---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><p class="bg b ec ab ga adt adu adv adw adx ady adz bl">Egor Howell</p></a></div></div></div></div><div class="aea m aeb aec aed aee aef he"><div class="aeg aeh aei aej aek ael aem aen"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/data-science-collective/vector-error-correction-model-a9ed374390f5?source=post_page---read_next_recirc--d88536d87038----3---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div title=""><h2 class="bg hm or ot aeo aep ou ov ox aeq aer oy ns px aes aet py nw qa aeu aev qb oa qd aew aex qe ga adu adv adx adz bl">Vector Error Correction Model</h2></div><div class="aey m"><h3 class="bg b aez ab ga afa adu adv afb adx adz eb">One of the more nuanced time series models</h3></div></a></div></div><span class="bg b ec ab eb"><div class="tf ac cw ag"><div class="ac r afe"><div class="sh ac"><button class="m ak aq ao" aria-label="Member-only story"><div class=""><div><div class="bn" aria-describedby="129" aria-labelledby="129" role="tooltip"><div tabindex="-1" class="bf"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 64 64"><path fill="#FFC017" d="m39.637 40.831-5.771 15.871a1.99 1.99 0 0 1-3.732 0l-5.771-15.87a2.02 2.02 0 0 0-1.194-1.195L7.298 33.866a1.99 1.99 0 0 1 0-3.732l15.87-5.771a2.02 2.02 0 0 0 1.195-1.194l5.771-15.871a1.99 1.99 0 0 1 3.732 0l5.771 15.87a2.02 2.02 0 0 0 1.194 1.195l15.871 5.771a1.99 1.99 0 0 1 0 3.732l-15.87 5.771a2.02 2.02 0 0 0-1.195 1.194"></path></svg></div></div></div></div></button></div>3d ago<div class=""><div class="fr afc do ac r"><div class="fw wr afd ac r afe"><div class="fn do dq m de"></div></div><a class="fw ln afd ac r afe" tabindex="-1" rel="noopener follow" href="https://medium.com/data-science-collective/vector-error-correction-model-a9ed374390f5?source=post_page---read_next_recirc--d88536d87038----3---------------------137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><div><div class="ac" aria-describedby="199" aria-labelledby="199" role="tooltip"><div tabindex="-1" class="bf"><div class="ac r afz"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" aria-labelledby="clap-filled-static-desc" viewBox="0 0 16 16"><desc id="clap-filled-static-desc">A clap icon</desc><path fill="#6B6B6B" fill-rule="evenodd" d="m3.672 10.167 2.138 2.14h-.002c1.726 1.722 4.337 2.436 5.96.81 1.472-1.45 1.806-3.68.76-5.388l-1.815-3.484c-.353-.524-.849-1.22-1.337-.958-.49.261 0 1.56 0 1.56l.78 1.932L6.43 2.866c-.837-.958-1.467-1.108-1.928-.647-.33.33-.266.856.477 1.598.501.503 1.888 1.957 1.888 1.957.17.174.083.485-.093.655a.56.56 0 0 1-.34.163.43.43 0 0 1-.317-.135s-2.4-2.469-2.803-2.87c-.344-.346-.803-.54-1.194-.15-.408.406-.273 1.065.11 1.447.345.346 2.31 2.297 2.685 2.67l.062.06c.17.175.269.628.093.8-.193.188-.453.33-.678.273a.9.9 0 0 1-.446-.273S2.501 6.84 1.892 6.23c-.407-.406-.899-.333-1.229 0-.525.524.263 1.28 1.73 2.691.384.368.814.781 1.279 1.246m8.472-7.219c.372-.29.95-.28 1.303.244V3.19l1.563 3.006.036.074c.885 1.87.346 4.093-.512 5.159l-.035.044c-.211.264-.344.43-.74.61 1.382-1.855.963-3.478-.248-5.456L11.943 3.88l-.002-.037c-.017-.3-.039-.71.203-.895" clip-rule="evenodd"></path></svg><span>46</span></div></div></div></div></a></div></div></div><div class="ac r aff afg"><div class=""><div><div class="bn" aria-describedby="130" aria-labelledby="130" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_preview"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa9ed374390f5&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fdata-science-collective%2Fvector-error-correction-model-a9ed374390f5&amp;source=---read_next_recirc--d88536d87038----3-----------------bookmark_preview----137227c8_0ca5_46f0_b320_bb3c256a6e3a--------------" data-discover="true"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lt afh" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div><div class="ua bi uo dr ds afi afj afk"></div><a class="bg b bh ab bl rz yf yg yh lt lp wi fc fd fe yi yj yk fh afl afm afn afo afp fi fj fk bn fl fm" rel="noopener follow" href="https://medium.com/?source=post_page---read_next_recirc--d88536d87038---------------------------------------" data-discover="true"><div class="m fm">See more recommendations</div></a></div></div></div><div class="i l k"><div class="ua bi uo up"></div><div class="ac ci"><div class="cp bi gq gr gs gt"><div class="uq ac kr ji"><div class="ur us m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://help.medium.com/hc/en-us?source=post_page-----d88536d87038---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Help</p></a></div><div class="ur us m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://status.medium.com/?source=post_page-----d88536d87038---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Status</p></a></div><div class="ur us m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/about?autoplay=1&amp;source=post_page-----d88536d87038---------------------------------------" data-discover="true"><p class="bg b ec ab eb">About</p></a></div><div class="ur us m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" rel="noopener follow" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----d88536d87038---------------------------------------" data-discover="true"><p class="bg b ec ab eb">Careers</p></a></div><div class="ur us m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="mailto:pressinquiries@medium.com" rel="noopener follow"><p class="bg b ec ab eb">Press</p></a></div><div class="ur us m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://blog.medium.com/?source=post_page-----d88536d87038---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Blog</p></a></div><div class="ur us m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----d88536d87038---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Privacy</p></a></div><div class="ur us m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----d88536d87038---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Rules</p></a></div><div class="ur us m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----d88536d87038---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Terms</p></a></div><div class="ur m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://speechify.com/medium?source=post_page-----d88536d87038---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Text to speech</p></a></div></div></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20260106-214857-49e54cb9c2"</script><script>window.__GRAPHQL_URI__ = "https://medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-d88536d87038","user-b6a26fecee8e"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[],"pubFeaturingPostPageLabelEnabled":false,"shouldFollowPostQueryEnabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"DEFAULT","explicit":false},"viewerIsBot":false},"debug":{"requestId":"25726277-0dc7-4e23-bd8e-0f0755349938","requestTag":"","hybridDevServices":[],"originalSpanCarrier":{"traceparent":"00-b24f1fe817cf29fb3525d4438f08ad02-e3b08a526a6eb8cb-01"}},"multiVote":{"clapsPerPost":{}},"navigation":{"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fmedium.com\u002F@ml.enesguler\u002Funderstanding-xgboost-from-basics-to-advanced-insights-d88536d87038","host":"medium.com","hostname":"medium.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"partnerProgram":{"selectedCountryCode":null},"staticRouterContext":{"route":{"name":"ShowPostUnderUser"},"statusCode":200},"toastQueue":[],"currentToast":null,"queryString":"","currentHash":""},"config":{"nodeEnv":"production","version":"main-20260106-214857-49e54cb9c2","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","iosAppId":"828256236","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20260106-214857-49e54cb9c2","commit":"49e54cb9c27279d4695fd32f5eb00496c5e969d3"}},"datacenter":"us"},"googleAdsCode":"AW-17106321204","googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"7*V1_7XP4snlmqrc_0Njontw.png","height":110,"width":500},"postLogo":{"imageId":"167cff2a3d17ac1e64d0762539978f2d54c0058886e8b3c8a03a725a83012ec0","height":630,"width":1200},"postPreviewImage":{"imageId":"bc1f8416df0cad099e43cda2872716e5864f18a73bda2a7547ea082aca9b5632","height":630,"width":1200}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyV2":"e8a5e126-792b-4ee6-8fba-d574c1b02fc5","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyV2":"3815d7d6-b8ca-4224-9b8c-182f9047866e","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyOneYearFree":"e6c0637a-2bad-4171-ab4f-3c268633d83c","monthly25PercentOffFirstYear":"235ecc62-0cdb-49ae-9378-726cd21c504b","monthly20PercentOffFirstYear":"ba518864-9c13-4a99-91ca-411bf0cac756","monthly15PercentOffFirstYear":"594c029b-9f89-43d5-88f8-8173af4e070e","monthly10PercentOffFirstYear":"c6c7bc9a-40f2-4b51-8126-e28511d5bdb0","monthlyForStudents":"629ebe51-da7d-41fd-8293-34cd2f2030a8","yearlyOneYearFree":"78ba7be9-0d9f-4ece-aa3e-b54b826f2bf1","yearly25PercentOffFirstYear":"2dbb010d-bb8f-4eeb-ad5c-a08509f42d34","yearly20PercentOffFirstYear":"47565488-435b-47f8-bf93-40d5fbe0ebc8","yearly15PercentOffFirstYear":"8259809b-0881-47d9-acf7-6c001c7f720f","yearly10PercentOffFirstYear":"9dd694fb-96e1-472c-8d9e-3c868d5c1506","yearlyForStudents":"e29345ef-ab1c-4234-95c5-70e50fe6bc23","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"collectionByDomainOrSlug({\"domainOrSlug\":\"medium.com\"})":null,"postResult({\"id\":\"d88536d87038\"})":{"__ref":"Post:d88536d87038"}},"LinkedAccounts:b6a26fecee8e":{"__typename":"LinkedAccounts","mastodon":null,"id":"b6a26fecee8e"},"NewsletterV3:f9970ca046a2":{"__typename":"NewsletterV3","id":"f9970ca046a2","type":"NEWSLETTER_TYPE_AUTHOR","slug":"b6a26fecee8e","name":"b6a26fecee8e","collection":null,"user":{"__ref":"User:b6a26fecee8e"}},"User:b6a26fecee8e":{"__typename":"User","id":"b6a26fecee8e","name":"Enes Güler","username":"ml.enesguler","newsletterV3":{"__ref":"NewsletterV3:f9970ca046a2"},"linkedAccounts":{"__ref":"LinkedAccounts:b6a26fecee8e"},"isSuspended":false,"imageId":"1*nC_mhaCkoHWhFhomi3ErNw.png","customDomainState":null,"hasSubdomain":false,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":1,"followingCount":1,"collectionFollowingCount":0},"bio":"MLOps & Backend Engineer. Focused on Distributed Systems & Automation. 🛠️ Stack: AWS, Kubernetes, Docker, Python.","membership":null,"allowNotes":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:b6a26fecee8e-viewerId:lo_dc62f1b31c7a"},"twitterScreenName":""},"Paragraph:a1d2c55f4d9a_0":{"__typename":"Paragraph","id":"a1d2c55f4d9a_0","name":"77c6","type":"H3","href":null,"layout":null,"metadata":null,"text":"Understanding XGBoost: From Basics to Advanced Insights","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*y0Zpd2U2nGIPmha5XniRgw.png":{"__typename":"ImageMetadata","id":"1*y0Zpd2U2nGIPmha5XniRgw.png","originalHeight":1024,"originalWidth":1024,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a1d2c55f4d9a_1":{"__typename":"Paragraph","id":"a1d2c55f4d9a_1","name":"f3a5","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*y0Zpd2U2nGIPmha5XniRgw.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_2":{"__typename":"Paragraph","id":"a1d2c55f4d9a_2","name":"a549","type":"P","href":null,"layout":null,"metadata":null,"text":"In the highly competitive world of machine learning, achieving state-of-the-art results often requires moving beyond basic models. For years, one algorithm has consistently stood out for its speed, performance, and robustness across diverse prediction tasks: Extreme Gradient Boosting, or XGBoost. Unlike traditional methods, XGBoost leverages a highly optimized and scalable implementation of gradient boosting, making it the undisputed champion in structured data challenges, from Kaggle competitions to enterprise-level applications. This comprehensive guide will take you on a deep dive, explaining the foundational concepts that make XGBoost so powerful, showing you how to implement it effectively with Python, and offering advanced insights to tune your models for peak performance.","hasDropCap":true,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":297,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":537,"end":789,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_3":{"__typename":"Paragraph","id":"a1d2c55f4d9a_3","name":"9062","type":"H3","href":null,"layout":null,"metadata":null,"text":"1. Historical Background of XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_4":{"__typename":"Paragraph","id":"a1d2c55f4d9a_4","name":"855b","type":"P","href":null,"layout":null,"metadata":null,"text":"The story of XGBoost begins in 2014. Tianqi Chen, then a Ph.D. student at the University of Washington, recognized the performance bottlenecks and limitations of the Gradient Boosting algorithms that were gaining popularity at the time. In particular, existing implementations struggled with large-scale datasets, suffered from limited flexibility, and failed to efficiently leverage the parallel processing capabilities offered by modern hardware.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":37,"end":48,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":166,"end":183,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_5":{"__typename":"Paragraph","id":"a1d2c55f4d9a_5","name":"5bbb","type":"P","href":null,"layout":null,"metadata":null,"text":"Chen’s objective was to develop a boosting library that was not only faster and more scalable but also more robust against overfitting. In line with this vision, XGBoost was designed to be more than just a theoretically powerful algorithm; it was also carefully engineered with a series of optimizations. These included parallel computation, sparsity-aware structures, tree pruning, and advanced regularization techniques, all of which distinguished it from existing implementations.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":64,"end":75,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":80,"end":93,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":103,"end":134,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_6":{"__typename":"Paragraph","id":"a1d2c55f4d9a_6","name":"0205","type":"P","href":null,"layout":null,"metadata":null,"text":"From the very beginning, the project was released as open source, which enabled researchers, data scientists, and engineers to adopt it rapidly. It quickly gained traction in Kaggle competitions, becoming especially popular between 2015 and 2017, when a large share of winning solutions relied on XGBoost. This success earned the algorithm the reputation of being the “competition favorite.”","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":53,"end":64,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":175,"end":194,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_7":{"__typename":"Paragraph","id":"a1d2c55f4d9a_7","name":"f1b6","type":"P","href":null,"layout":null,"metadata":null,"text":"However, the rise of XGBoost was not limited to competitions. Over time, it found applications across a wide range of domains, including finance, healthcare, marketing, bioinformatics, and industry. Its use cases span from credit risk modeling and customer behavior prediction to disease forecasting and anomaly detection in manufacturing processes.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_8":{"__typename":"Paragraph","id":"a1d2c55f4d9a_8","name":"43b1","type":"P","href":null,"layout":null,"metadata":null,"text":"Today, XGBoost is regarded not merely as an algorithm but as one of the foundational building blocks of modern machine learning. With its strong performance, it has become a preferred standard in both academic research and industrial projects.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":104,"end":127,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_9":{"__typename":"Paragraph","id":"a1d2c55f4d9a_9","name":"15f5","type":"H3","href":null,"layout":null,"metadata":null,"text":"2. Introduction to XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_10":{"__typename":"Paragraph","id":"a1d2c55f4d9a_10","name":"55db","type":"P","href":null,"layout":null,"metadata":null,"text":"XGBoost (Extreme Gradient Boosting) is a powerful boosting algorithm that has rapidly emerged in the modern machine learning landscape, particularly gaining popularity in competitions such as Kaggle. Its core principle is to combine multiple weak learners — typically decision trees — into a strong predictive model. This approach can be viewed as an enhanced version of classical gradient boosting methods and is widely recognized for delivering high accuracy.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":50,"end":68,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_11":{"__typename":"Paragraph","id":"a1d2c55f4d9a_11","name":"9061","type":"P","href":null,"layout":null,"metadata":null,"text":"There are several reasons behind the popularity of XGBoost:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_12":{"__typename":"Paragraph","id":"a1d2c55f4d9a_12","name":"e0f6","type":"P","href":null,"layout":null,"metadata":null,"text":"Performance and Speed: Thanks to parallel computation and optimized data structures, XGBoost can handle large datasets with remarkable efficiency.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_13":{"__typename":"Paragraph","id":"a1d2c55f4d9a_13","name":"aa08","type":"P","href":null,"layout":null,"metadata":null,"text":"Regularization: By supporting both L1 and L2 regularization, it helps reduce the risk of overfitting.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_14":{"__typename":"Paragraph","id":"a1d2c55f4d9a_14","name":"cf44","type":"P","href":null,"layout":null,"metadata":null,"text":"Flexibility: It is suitable for both regression and classification tasks and can work with a variety of loss functions.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_15":{"__typename":"Paragraph","id":"a1d2c55f4d9a_15","name":"5416","type":"P","href":null,"layout":null,"metadata":null,"text":"Community and Resources: With comprehensive documentation and strong community support, XGBoost is relatively easy to learn and apply.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_16":{"__typename":"Paragraph","id":"a1d2c55f4d9a_16","name":"afa4","type":"P","href":null,"layout":null,"metadata":null,"text":"Beyond being an enhanced version of the classical Gradient Boosting algorithm, XGBoost is equipped with a sparsity-aware approach and tree pruning techniques that allow it to handle missing values in datasets effectively. These features elevate XGBoost from being merely an academic tool to a reliable and efficient solution for real-world projects.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_17":{"__typename":"Paragraph","id":"a1d2c55f4d9a_17","name":"4366","type":"P","href":null,"layout":null,"metadata":null,"text":"Its success in data science competitions has further demonstrated that, when combined with proper hyperparameter tuning and feature engineering, XGBoost can consistently outperform competing algorithms. For this reason, it has become a preferred choice among data scientists for both experimental research and industrial applications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_18":{"__typename":"Paragraph","id":"a1d2c55f4d9a_18","name":"3ee3","type":"H3","href":null,"layout":null,"metadata":null,"text":"3. Comparison with Other Boosting Algorithms","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_19":{"__typename":"Paragraph","id":"a1d2c55f4d9a_19","name":"4850","type":"P","href":null,"layout":null,"metadata":null,"text":"Boosting algorithms generally aim to combine multiple weak learners (typically decision trees) into a single strong and accurate predictive model. However, their implementation strategies differ significantly. Compared to AdaBoost and classical Gradient Boosting, XGBoost offers several distinct advantages:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_20":{"__typename":"Paragraph","id":"a1d2c55f4d9a_20","name":"455e","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.1. Difference from AdaBoost:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":30,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_21":{"__typename":"Paragraph","id":"a1d2c55f4d9a_21","name":"554f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"AdaBoost trains subsequent models by assigning higher weights to misclassified instances, making each new model more sensitive to the errors of its predecessor.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_22":{"__typename":"Paragraph","id":"a1d2c55f4d9a_22","name":"bfc9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"However, AdaBoost is highly sensitive to noisy data and outliers, which can weaken its generalization capability.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_23":{"__typename":"Paragraph","id":"a1d2c55f4d9a_23","name":"b7a3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"XGBoost, on the other hand, not only adjusts weights but also employs gradient descent–based optimization. Furthermore, through its use of L1 and L2 regularization, it is far more robust against noisy data and overfitting.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*P_SMUMON9tlLzvah4Ej-WA.png":{"__typename":"ImageMetadata","id":"1*P_SMUMON9tlLzvah4Ej-WA.png","originalHeight":3000,"originalWidth":4200,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a1d2c55f4d9a_24":{"__typename":"Paragraph","id":"a1d2c55f4d9a_24","name":"f0a6","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"__ref":"ImageMetadata:1*P_SMUMON9tlLzvah4Ej-WA.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_25":{"__typename":"Paragraph","id":"a1d2c55f4d9a_25","name":"ebc8","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.2. Difference from Classical Gradient Boosting:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":49,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_26":{"__typename":"Paragraph","id":"a1d2c55f4d9a_26","name":"8074","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Like XGBoost, Gradient Boosting leverages gradient information to minimize errors. However, traditional implementations are often slower and struggle with performance on large datasets.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_27":{"__typename":"Paragraph","id":"a1d2c55f4d9a_27","name":"0382","type":"ULI","href":null,"layout":null,"metadata":null,"text":"XGBoost addresses these limitations by incorporating engineering optimizations such as parallel computation, sparsity-aware algorithms, and tree pruning, making it significantly faster.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_28":{"__typename":"Paragraph","id":"a1d2c55f4d9a_28","name":"a110","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Additionally, XGBoost provides a richer set of hyperparameters (e.g., learning_rate, max_depth, gamma, subsample, colsample_bytree), offering users finer control over model tuning.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":70,"end":83,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":85,"end":94,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":96,"end":101,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":103,"end":112,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":114,"end":130,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_29":{"__typename":"Paragraph","id":"a1d2c55f4d9a_29","name":"2e40","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.3. General Advantages:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_30":{"__typename":"Paragraph","id":"a1d2c55f4d9a_30","name":"4e3c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Regularization: Unlike AdaBoost and classical GBM, where regularization mechanisms are limited, XGBoost integrates both L1 (Lasso) and L2 (Ridge) regularization, offering stronger control over overfitting.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_31":{"__typename":"Paragraph","id":"a1d2c55f4d9a_31","name":"d212","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Handling Missing Values: XGBoost can automatically learn the optimal direction for missing values, a feature not available in AdaBoost or classical GBM.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_32":{"__typename":"Paragraph","id":"a1d2c55f4d9a_32","name":"5540","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Scalability: It efficiently handles very large datasets and supports execution on both CPUs and GPUs.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_33":{"__typename":"Paragraph","id":"a1d2c55f4d9a_33","name":"bad9","type":"P","href":null,"layout":null,"metadata":null,"text":"In summary: AdaBoost represents a simpler and more fundamental boosting approach; classical Gradient Boosting is powerful but remains limited in terms of speed and flexibility. XGBoost, by contrast, is a modern boosting method that integrates both theoretical and engineering advancements, offering speed, scalability, and strong generalization performance together.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":11,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":243,"end":288,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_34":{"__typename":"Paragraph","id":"a1d2c55f4d9a_34","name":"2b58","type":"H3","href":null,"layout":null,"metadata":null,"text":"4. Fundamental Concepts of XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_35":{"__typename":"Paragraph","id":"a1d2c55f4d9a_35","name":"6330","type":"P","href":null,"layout":null,"metadata":null,"text":"To understand XGBoost, it is essential to first grasp the fundamental principles underlying boosting algorithms. These concepts serve as the building blocks that explain why XGBoost is so powerful and widely adopted.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_36":{"__typename":"Paragraph","id":"a1d2c55f4d9a_36","name":"e146","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.1. What is Boosting?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_37":{"__typename":"Paragraph","id":"a1d2c55f4d9a_37","name":"c27b","type":"P","href":null,"layout":null,"metadata":null,"text":"Boosting is a method of combining multiple weak learners — typically shallow decision trees — into a single, strong predictive model. Each successive model attempts to correct the errors of its predecessors, allowing the ensemble to improve incrementally.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_38":{"__typename":"Paragraph","id":"a1d2c55f4d9a_38","name":"e43c","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.2. From Weak Learners to Strong Learners","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_39":{"__typename":"Paragraph","id":"a1d2c55f4d9a_39","name":"3a07","type":"P","href":null,"layout":null,"metadata":null,"text":"An individual small decision tree (e.g., a depth-1 “decision stump”) is generally too simple to capture the complexity of real-world data. However, systematically combining hundreds of such small trees produces a model capable of making highly accurate predictions. This principle lies at the heart of boosting.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_40":{"__typename":"Paragraph","id":"a1d2c55f4d9a_40","name":"6a82","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.3. The Gradient Boosting Principle","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_41":{"__typename":"Paragraph","id":"a1d2c55f4d9a_41","name":"55fa","type":"P","href":null,"layout":null,"metadata":null,"text":"Classical boosting methods assign higher weights to misclassified instances. Gradient Boosting generalizes this idea by leveraging the concept of gradient descent. Each new tree is trained to fit the gradients of the loss function, meaning the model learns the “slope of the error” from previous iterations and updates itself to minimize those errors. This approach makes the learning process more systematic and efficient.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_42":{"__typename":"Paragraph","id":"a1d2c55f4d9a_42","name":"5da6","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.4. Loss Function (Objective Function)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*q7eUGSNs0Q0JEAb1HNXKbA.png":{"__typename":"ImageMetadata","id":"1*q7eUGSNs0Q0JEAb1HNXKbA.png","originalHeight":1800,"originalWidth":3000,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a1d2c55f4d9a_43":{"__typename":"Paragraph","id":"a1d2c55f4d9a_43","name":"19fb","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*q7eUGSNs0Q0JEAb1HNXKbA.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_44":{"__typename":"Paragraph","id":"a1d2c55f4d9a_44","name":"fb17","type":"P","href":null,"layout":null,"metadata":null,"text":"The loss function is a metric that measures the difference between the model’s predictions and the true values. XGBoost supports different loss functions tailored to various problem types:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_45":{"__typename":"Paragraph","id":"a1d2c55f4d9a_45","name":"b66c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Regression: Mean Squared Error (MSE) or Root Mean Squared Error (RMSE)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":11,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_46":{"__typename":"Paragraph","id":"a1d2c55f4d9a_46","name":"7f78","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Binary Classification: Logistic Loss (binary:logistic)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":38,"end":53,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_47":{"__typename":"Paragraph","id":"a1d2c55f4d9a_47","name":"c204","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Multiclass Classification: Softmax Loss (multi:softmax)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":26,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":41,"end":54,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_48":{"__typename":"Paragraph","id":"a1d2c55f4d9a_48","name":"0203","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Custom Tasks: Users can define their own custom loss functions","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_49":{"__typename":"Paragraph","id":"a1d2c55f4d9a_49","name":"08f2","type":"P","href":null,"layout":null,"metadata":null,"text":"Selecting the appropriate loss function directly impacts model performance, as the entire learning process revolves around minimizing this function.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_50":{"__typename":"Paragraph","id":"a1d2c55f4d9a_50","name":"fe55","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.5. Key Innovations of XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_51":{"__typename":"Paragraph","id":"a1d2c55f4d9a_51","name":"2723","type":"P","href":null,"layout":null,"metadata":null,"text":"Beyond the general principles of boosting, XGBoost introduces several important innovations:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_52":{"__typename":"Paragraph","id":"a1d2c55f4d9a_52","name":"ed68","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Regularization: Incorporates both L1 (Lasso) and L2 (Ridge) penalties, helping to prevent overfitting.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_53":{"__typename":"Paragraph","id":"a1d2c55f4d9a_53","name":"653d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Parallelization: Optimizes tree construction to efficiently leverage multi-core processors.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_54":{"__typename":"Paragraph","id":"a1d2c55f4d9a_54","name":"999d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Sparsity-Aware Approach: Automatically directs missing values to the optimal branches.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_55":{"__typename":"Paragraph","id":"a1d2c55f4d9a_55","name":"bfed","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Tree Pruning: Removes unnecessary branches to produce more compact and generalizable trees.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_56":{"__typename":"Paragraph","id":"a1d2c55f4d9a_56","name":"7fe3","type":"H3","href":null,"layout":null,"metadata":null,"text":"6. Strengths and Limitations of XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_57":{"__typename":"Paragraph","id":"a1d2c55f4d9a_57","name":"2350","type":"P","href":null,"layout":null,"metadata":null,"text":"Like any algorithm, XGBoost has its strengths and limitations. Understanding these aspects is crucial for determining the contexts in which it is most suitable.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_58":{"__typename":"Paragraph","id":"a1d2c55f4d9a_58","name":"ce94","type":"H4","href":null,"layout":null,"metadata":null,"text":"6.1. Strengths","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_59":{"__typename":"Paragraph","id":"a1d2c55f4d9a_59","name":"a019","type":"P","href":null,"layout":null,"metadata":null,"text":"High Performance and Accuracy: XGBoost has frequently secured top positions in data science competitions such as Kaggle. Its fast training times and high predictive accuracy make it a preferred choice in both academic research and industrial applications.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_60":{"__typename":"Paragraph","id":"a1d2c55f4d9a_60","name":"a864","type":"P","href":null,"layout":null,"metadata":null,"text":"Robustness Against Overfitting: By incorporating both L1 (Lasso) and L2 (Ridge) regularization, XGBoost protects the model from unnecessary complexity and enhances its generalization capability.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":32,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_61":{"__typename":"Paragraph","id":"a1d2c55f4d9a_61","name":"d3f8","type":"P","href":null,"layout":null,"metadata":null,"text":"Effective Handling of Missing Values: The algorithm can automatically direct missing values to the appropriate branches, reducing the need for extensive data preprocessing.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":38,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_62":{"__typename":"Paragraph","id":"a1d2c55f4d9a_62","name":"02db","type":"P","href":null,"layout":null,"metadata":null,"text":"Scalability and Speed:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_63":{"__typename":"Paragraph","id":"a1d2c55f4d9a_63","name":"e5d4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Supports parallelization on multi-core processors","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_64":{"__typename":"Paragraph","id":"a1d2c55f4d9a_64","name":"42b3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Offers GPU acceleration","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_65":{"__typename":"Paragraph","id":"a1d2c55f4d9a_65","name":"8940","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Maintains efficiency even on very large datasets","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_66":{"__typename":"Paragraph","id":"a1d2c55f4d9a_66","name":"89cd","type":"P","href":null,"layout":null,"metadata":null,"text":"Flexibility:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_67":{"__typename":"Paragraph","id":"a1d2c55f4d9a_67","name":"b8f9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Provides support for a wide range of loss functions across different problem types, including regression, classification, and ranking","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_68":{"__typename":"Paragraph","id":"a1d2c55f4d9a_68","name":"75df","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Allows users to define custom loss functions or evaluation metrics","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_69":{"__typename":"Paragraph","id":"a1d2c55f4d9a_69","name":"6647","type":"H4","href":null,"layout":null,"metadata":null,"text":"6.2. Limitations","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_70":{"__typename":"Paragraph","id":"a1d2c55f4d9a_70","name":"a1e9","type":"P","href":null,"layout":null,"metadata":null,"text":"Hyperparameter Complexity: XGBoost involves a large number of parameters. Proper tuning often requires expertise, experience, and extensive trial and error.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":27,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_71":{"__typename":"Paragraph","id":"a1d2c55f4d9a_71","name":"5710","type":"P","href":null,"layout":null,"metadata":null,"text":"Training Time: Although optimizations make XGBoost relatively fast, training on very large datasets with millions of rows can still be time-consuming. Improperly tuned parameters may further extend this process.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_72":{"__typename":"Paragraph","id":"a1d2c55f4d9a_72","name":"74dd","type":"P","href":null,"layout":null,"metadata":null,"text":"Not Suitable for Unstructured Data: XGBoost excels on tabular (structured) data. However, for unstructured data such as images, audio, or text, deep learning methods (e.g., CNNs, RNNs, Transformers) are generally more appropriate.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":36,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_73":{"__typename":"Paragraph","id":"a1d2c55f4d9a_73","name":"a329","type":"P","href":null,"layout":null,"metadata":null,"text":"Interpretability Challenges: A single decision tree is easy to visualize and understand, but XGBoost models — comprising hundreds of trees — often behave like a “black box.” Therefore, additional tools such as SHAP or LIME are typically required to achieve interpretability.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":29,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_74":{"__typename":"Paragraph","id":"a1d2c55f4d9a_74","name":"644c","type":"H4","href":null,"layout":null,"metadata":null,"text":"6.3. When to Use XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_75":{"__typename":"Paragraph","id":"a1d2c55f4d9a_75","name":"4885","type":"ULI","href":null,"layout":null,"metadata":null,"text":"When high accuracy is desired on tabular (structured) datasets","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_76":{"__typename":"Paragraph","id":"a1d2c55f4d9a_76","name":"da62","type":"ULI","href":null,"layout":null,"metadata":null,"text":"For medium to large-sized datasets","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_77":{"__typename":"Paragraph","id":"a1d2c55f4d9a_77","name":"f94f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"When minimizing the risk of overfitting is important","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_78":{"__typename":"Paragraph","id":"a1d2c55f4d9a_78","name":"504b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"When a strong baseline or final model is needed in competitive settings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_79":{"__typename":"Paragraph","id":"a1d2c55f4d9a_79","name":"6ab5","type":"P","href":null,"layout":null,"metadata":null,"text":"Conversely, for very simple datasets or situations where interpretability is critical, simpler methods such as Logistic Regression, Decision Trees, or Random Forests may be more suitable.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_80":{"__typename":"Paragraph","id":"a1d2c55f4d9a_80","name":"45a2","type":"H3","href":null,"layout":null,"metadata":null,"text":"7. Essential Hyperparameters of XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_81":{"__typename":"Paragraph","id":"a1d2c55f4d9a_81","name":"3498","type":"P","href":null,"layout":null,"metadata":null,"text":"The success of XGBoost largely stems from its ability to optimize model performance through careful hyperparameter tuning. Given the large number of parameters available, it is important for beginners to focus on the most critical ones. Below are the key hyperparameters and their functions:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_82":{"__typename":"Paragraph","id":"a1d2c55f4d9a_82","name":"40e1","type":"P","href":null,"layout":null,"metadata":null,"text":"n_estimators (Number of Trees):","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_83":{"__typename":"Paragraph","id":"a1d2c55f4d9a_83","name":"7bed","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Determines how many trees will be used in the model.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_84":{"__typename":"Paragraph","id":"a1d2c55f4d9a_84","name":"2279","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Too few trees can lead to underfitting; too many can cause overfitting.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_85":{"__typename":"Paragraph","id":"a1d2c55f4d9a_85","name":"0546","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Often tuned in conjunction with learning_rate; lower learning_rate typically requires more trees.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":32,"end":45,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":53,"end":66,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_86":{"__typename":"Paragraph","id":"a1d2c55f4d9a_86","name":"eff4","type":"P","href":null,"layout":null,"metadata":null,"text":"max_depth (Tree Depth):","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_87":{"__typename":"Paragraph","id":"a1d2c55f4d9a_87","name":"3cc9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Sets the maximum depth of each tree.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_88":{"__typename":"Paragraph","id":"a1d2c55f4d9a_88","name":"21ce","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Deeper trees capture more patterns but increase the risk of overfitting.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_89":{"__typename":"Paragraph","id":"a1d2c55f4d9a_89","name":"4472","type":"ULI","href":null,"layout":null,"metadata":null,"text":"A typical starting range is between 3 and 6.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_90":{"__typename":"Paragraph","id":"a1d2c55f4d9a_90","name":"9d06","type":"P","href":null,"layout":null,"metadata":null,"text":"learning_rate \u002F eta (Learning Rate):","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":36,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_91":{"__typename":"Paragraph","id":"a1d2c55f4d9a_91","name":"3e81","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Scales the contribution of each tree.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_92":{"__typename":"Paragraph","id":"a1d2c55f4d9a_92","name":"f9d6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Small values → slower but more stable learning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_93":{"__typename":"Paragraph","id":"a1d2c55f4d9a_93","name":"b867","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Large values → faster but riskier learning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_94":{"__typename":"Paragraph","id":"a1d2c55f4d9a_94","name":"7a47","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Typically optimized alongside n_estimators.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":30,"end":42,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_95":{"__typename":"Paragraph","id":"a1d2c55f4d9a_95","name":"8a5a","type":"P","href":null,"layout":null,"metadata":null,"text":"subsample (Sampling Ratio):","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":27,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_96":{"__typename":"Paragraph","id":"a1d2c55f4d9a_96","name":"8286","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Specifies the fraction of training data used to build each tree.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_97":{"__typename":"Paragraph","id":"a1d2c55f4d9a_97","name":"136c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"1.0 → use all data","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_98":{"__typename":"Paragraph","id":"a1d2c55f4d9a_98","name":"dd14","type":"ULI","href":null,"layout":null,"metadata":null,"text":"\u003C1.0 → random subsample → reduces overfitting","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_99":{"__typename":"Paragraph","id":"a1d2c55f4d9a_99","name":"dffa","type":"P","href":null,"layout":null,"metadata":null,"text":"colsample_bytree, colsample_bylevel, colsample_bynode (Feature Subsampling):","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":76,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_100":{"__typename":"Paragraph","id":"a1d2c55f4d9a_100","name":"66aa","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Controls which features are considered at each tree, level, or node.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_101":{"__typename":"Paragraph","id":"a1d2c55f4d9a_101","name":"9fbe","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Randomly selecting subsets of features improves generalization.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_102":{"__typename":"Paragraph","id":"a1d2c55f4d9a_102","name":"8f3c","type":"P","href":null,"layout":null,"metadata":null,"text":"gamma (Minimum Split Loss):","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":27,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_103":{"__typename":"Paragraph","id":"a1d2c55f4d9a_103","name":"78fe","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Minimum reduction in loss required to make a split.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_104":{"__typename":"Paragraph","id":"a1d2c55f4d9a_104","name":"15da","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Higher gamma → more conservative splits → reduces overfitting","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":7,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_105":{"__typename":"Paragraph","id":"a1d2c55f4d9a_105","name":"f236","type":"P","href":null,"layout":null,"metadata":null,"text":"min_child_weight:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_106":{"__typename":"Paragraph","id":"a1d2c55f4d9a_106","name":"f5a0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Minimum sum of instance weight needed in a leaf.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_107":{"__typename":"Paragraph","id":"a1d2c55f4d9a_107","name":"2cb5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Higher values → fewer splits → simpler trees → reduces overfitting","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_108":{"__typename":"Paragraph","id":"a1d2c55f4d9a_108","name":"90c3","type":"P","href":null,"layout":null,"metadata":null,"text":"Regularization: reg_alpha and reg_lambda:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":41,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_109":{"__typename":"Paragraph","id":"a1d2c55f4d9a_109","name":"0b61","type":"ULI","href":null,"layout":null,"metadata":null,"text":"reg_alpha → L1 penalty","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_110":{"__typename":"Paragraph","id":"a1d2c55f4d9a_110","name":"0564","type":"ULI","href":null,"layout":null,"metadata":null,"text":"reg_lambda → L2 penalty","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_111":{"__typename":"Paragraph","id":"a1d2c55f4d9a_111","name":"bfd4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Controls model complexity and mitigates overfitting","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_112":{"__typename":"Paragraph","id":"a1d2c55f4d9a_112","name":"d6ab","type":"P","href":null,"layout":null,"metadata":null,"text":"scale_pos_weight:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_113":{"__typename":"Paragraph","id":"a1d2c55f4d9a_113","name":"61bb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Adjusts the balance between positive and negative classes in imbalanced datasets","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_114":{"__typename":"Paragraph","id":"a1d2c55f4d9a_114","name":"301e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Particularly useful for binary classification","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*M5gLsNRBllZCETA-4VnoXg.png":{"__typename":"ImageMetadata","id":"1*M5gLsNRBllZCETA-4VnoXg.png","originalHeight":1800,"originalWidth":3000,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a1d2c55f4d9a_115":{"__typename":"Paragraph","id":"a1d2c55f4d9a_115","name":"ab38","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*M5gLsNRBllZCETA-4VnoXg.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_116":{"__typename":"Paragraph","id":"a1d2c55f4d9a_116","name":"a188","type":"P","href":null,"layout":null,"metadata":null,"text":"These fundamental hyperparameters significantly influence XGBoost model performance. In practice, iterative tuning of these parameters allows optimization of speed, accuracy, and generalization simultaneously.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_117":{"__typename":"Paragraph","id":"a1d2c55f4d9a_117","name":"1cf9","type":"H3","href":null,"layout":null,"metadata":null,"text":"8. Advanced Capabilities of XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_118":{"__typename":"Paragraph","id":"a1d2c55f4d9a_118","name":"82f1","type":"P","href":null,"layout":null,"metadata":null,"text":"After mastering the core hyperparameters, it is important to understand the advanced features that enhance XGBoost’s performance and flexibility. This section covers intermediate-level topics that are critical for optimizing the model and applying it effectively in more complex scenarios.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_119":{"__typename":"Paragraph","id":"a1d2c55f4d9a_119","name":"598e","type":"H4","href":null,"layout":null,"metadata":null,"text":"8.1. Booster Types","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_120":{"__typename":"Paragraph","id":"a1d2c55f4d9a_120","name":"d2bb","type":"P","href":null,"layout":null,"metadata":null,"text":"XGBoost provides three types of boosters tailored for different use cases:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_121":{"__typename":"Paragraph","id":"a1d2c55f4d9a_121","name":"756b","type":"P","href":null,"layout":null,"metadata":null,"text":"gbtree:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_122":{"__typename":"Paragraph","id":"a1d2c55f4d9a_122","name":"3cfe","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Default option.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_123":{"__typename":"Paragraph","id":"a1d2c55f4d9a_123","name":"156c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Uses decision trees and is suitable for both classification and regression tasks.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_124":{"__typename":"Paragraph","id":"a1d2c55f4d9a_124","name":"8faa","type":"P","href":null,"layout":null,"metadata":null,"text":"gblinear:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_125":{"__typename":"Paragraph","id":"a1d2c55f4d9a_125","name":"26c5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Uses linear models (e.g., linear regression, logistic regression).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_126":{"__typename":"Paragraph","id":"a1d2c55f4d9a_126","name":"189e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Particularly useful for very large and sparse datasets.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_127":{"__typename":"Paragraph","id":"a1d2c55f4d9a_127","name":"d31f","type":"P","href":null,"layout":null,"metadata":null,"text":"dart (Dropouts meet Multiple Additive Regression Trees):","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":56,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_128":{"__typename":"Paragraph","id":"a1d2c55f4d9a_128","name":"99d2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Randomly drops some trees to prevent overfitting.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_129":{"__typename":"Paragraph","id":"a1d2c55f4d9a_129","name":"f954","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Increases ensemble diversity and improves generalization performance.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_130":{"__typename":"Paragraph","id":"a1d2c55f4d9a_130","name":"163b","type":"H4","href":null,"layout":null,"metadata":null,"text":"8.2. Early Stopping and Learning Rate Strategies","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*Mxx2CZQZ4ocGXzrekWcj-Q.png":{"__typename":"ImageMetadata","id":"1*Mxx2CZQZ4ocGXzrekWcj-Q.png","originalHeight":1800,"originalWidth":3600,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a1d2c55f4d9a_131":{"__typename":"Paragraph","id":"a1d2c55f4d9a_131","name":"4796","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*Mxx2CZQZ4ocGXzrekWcj-Q.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_132":{"__typename":"Paragraph","id":"a1d2c55f4d9a_132","name":"baec","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Early Stopping:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_133":{"__typename":"Paragraph","id":"a1d2c55f4d9a_133","name":"8f78","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Stops training if the model does not show improvement on the validation set for a specified number of iterations.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_134":{"__typename":"Paragraph","id":"a1d2c55f4d9a_134","name":"7be3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Reduces training time and mitigates the risk of overfitting.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_135":{"__typename":"Paragraph","id":"a1d2c55f4d9a_135","name":"bc07","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Learning Rate with n_estimators Combination:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":44,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_136":{"__typename":"Paragraph","id":"a1d2c55f4d9a_136","name":"3c19","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Low learning_rate → requires more trees","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_137":{"__typename":"Paragraph","id":"a1d2c55f4d9a_137","name":"b093","type":"ULI","href":null,"layout":null,"metadata":null,"text":"High learning_rate → faster learning but riskier","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_138":{"__typename":"Paragraph","id":"a1d2c55f4d9a_138","name":"e89a","type":"H4","href":null,"layout":null,"metadata":null,"text":"8.3. Subsampling Strategies","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":27,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_139":{"__typename":"Paragraph","id":"a1d2c55f4d9a_139","name":"60ab","type":"ULI","href":null,"layout":null,"metadata":null,"text":"subsample → subset of training instances","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_140":{"__typename":"Paragraph","id":"a1d2c55f4d9a_140","name":"a77f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"colsample_bytree \u002F colsample_bylevel \u002F colsample_bynode → subset of features","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":55,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_141":{"__typename":"Paragraph","id":"a1d2c55f4d9a_141","name":"0c76","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Using random subsets reduces correlation among trees and enhances generalization.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_142":{"__typename":"Paragraph","id":"a1d2c55f4d9a_142","name":"bcb9","type":"H4","href":null,"layout":null,"metadata":null,"text":"8.4. Choice of Evaluation Metrics","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":33,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_143":{"__typename":"Paragraph","id":"a1d2c55f4d9a_143","name":"c530","type":"P","href":null,"layout":null,"metadata":null,"text":"XGBoost supports a variety of evaluation metrics depending on the problem type:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_144":{"__typename":"Paragraph","id":"a1d2c55f4d9a_144","name":"a79a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Classification → accuracy, AUC, logloss","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":17,"end":25,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":27,"end":30,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":32,"end":39,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_145":{"__typename":"Paragraph","id":"a1d2c55f4d9a_145","name":"dc06","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Regression → RMSE, MAE","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":13,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":19,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_146":{"__typename":"Paragraph","id":"a1d2c55f4d9a_146","name":"2a95","type":"P","href":null,"layout":null,"metadata":null,"text":"Selecting the appropriate metric is crucial to ensure the model is optimized for the intended objective.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_147":{"__typename":"Paragraph","id":"a1d2c55f4d9a_147","name":"be7a","type":"H4","href":null,"layout":null,"metadata":null,"text":"8.5. Tree Method and Hardware Optimizations","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":43,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*Jj6Lysyr3GeQjacWsopcZw.png":{"__typename":"ImageMetadata","id":"1*Jj6Lysyr3GeQjacWsopcZw.png","originalHeight":1800,"originalWidth":3000,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a1d2c55f4d9a_148":{"__typename":"Paragraph","id":"a1d2c55f4d9a_148","name":"721a","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*Jj6Lysyr3GeQjacWsopcZw.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_149":{"__typename":"Paragraph","id":"a1d2c55f4d9a_149","name":"4fa4","type":"P","href":null,"layout":null,"metadata":null,"text":"The tree_method parameter determines how trees are constructed:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":4,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_150":{"__typename":"Paragraph","id":"a1d2c55f4d9a_150","name":"496f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"exact → classical method, ideal for small datasets","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_151":{"__typename":"Paragraph","id":"a1d2c55f4d9a_151","name":"0493","type":"ULI","href":null,"layout":null,"metadata":null,"text":"hist → histogram-based, faster for large datasets","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":4,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_152":{"__typename":"Paragraph","id":"a1d2c55f4d9a_152","name":"697b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"gpu_hist → GPU-accelerated, ideal for very large datasets and parallel training","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":8,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_153":{"__typename":"Paragraph","id":"a1d2c55f4d9a_153","name":"5f74","type":"H4","href":null,"layout":null,"metadata":null,"text":"8.6. Model Interpretability","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":27,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_154":{"__typename":"Paragraph","id":"a1d2c55f4d9a_154","name":"63be","type":"ULI","href":null,"layout":null,"metadata":null,"text":"XGBoost models, comprising hundreds of trees, are often considered “black-box.”","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_155":{"__typename":"Paragraph","id":"a1d2c55f4d9a_155","name":"fa98","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Tools such as SHAP or LIME can be used to explain tree decisions.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_156":{"__typename":"Paragraph","id":"a1d2c55f4d9a_156","name":"640d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Feature importance (e.g., via plot_importance) can visualize which features contribute most to the model.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":18,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":30,"end":45,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_157":{"__typename":"Paragraph","id":"a1d2c55f4d9a_157","name":"a065","type":"P","href":null,"layout":null,"metadata":null,"text":"This section highlights XGBoost’s flexibility and optimization capabilities beyond basic hyperparameters. These insights allow the model to be applied effectively to complex datasets or competitive environments.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_158":{"__typename":"Paragraph","id":"a1d2c55f4d9a_158","name":"6c26","type":"H3","href":null,"layout":null,"metadata":null,"text":"9. Handling Missing Values and Sparsity in XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_159":{"__typename":"Paragraph","id":"a1d2c55f4d9a_159","name":"34de","type":"P","href":null,"layout":null,"metadata":null,"text":"XGBoost naturally supports working with missing and sparse data, making the algorithm highly practical for real-world datasets.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_160":{"__typename":"Paragraph","id":"a1d2c55f4d9a_160","name":"5290","type":"H4","href":null,"layout":null,"metadata":null,"text":"9.1. Managing Missing Values","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":28,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_161":{"__typename":"Paragraph","id":"a1d2c55f4d9a_161","name":"91ab","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Missing values in datasets pose challenges for most machine learning algorithms.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_162":{"__typename":"Paragraph","id":"a1d2c55f4d9a_162","name":"c89d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"XGBoost automatically determines the optimal branch for a missing value while training the tree.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_163":{"__typename":"Paragraph","id":"a1d2c55f4d9a_163","name":"a583","type":"ULI","href":null,"layout":null,"metadata":null,"text":"This significantly reduces the need for imputation during preprocessing.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_164":{"__typename":"Paragraph","id":"a1d2c55f4d9a_164","name":"f2b1","type":"H4","href":null,"layout":null,"metadata":null,"text":"9.2. Sparsity-Aware Optimizations","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":33,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_165":{"__typename":"Paragraph","id":"a1d2c55f4d9a_165","name":"0b70","type":"ULI","href":null,"layout":null,"metadata":null,"text":"XGBoost efficiently handles sparse data matrices.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_166":{"__typename":"Paragraph","id":"a1d2c55f4d9a_166","name":"f828","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Empty cells resulting from one-hot encoding, categorical variables, or missing values are effectively utilized during training.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_167":{"__typename":"Paragraph","id":"a1d2c55f4d9a_167","name":"1738","type":"ULI","href":null,"layout":null,"metadata":null,"text":"The algorithm learns default directions for missing values and applies them during tree construction.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_168":{"__typename":"Paragraph","id":"a1d2c55f4d9a_168","name":"6b98","type":"ULI","href":null,"layout":null,"metadata":null,"text":"This approach reduces memory usage and increases computational efficiency.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_169":{"__typename":"Paragraph","id":"a1d2c55f4d9a_169","name":"e3d2","type":"H4","href":null,"layout":null,"metadata":null,"text":"9.3. Strengths:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":14,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_170":{"__typename":"Paragraph","id":"a1d2c55f4d9a_170","name":"0ddb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Minimizes the need for additional data cleaning on large datasets.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_171":{"__typename":"Paragraph","id":"a1d2c55f4d9a_171","name":"126d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Ensures reliable predictions even in the presence of missing or sparse values.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_172":{"__typename":"Paragraph","id":"a1d2c55f4d9a_172","name":"2da7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Reduces the risk of overfitting, as missing values are handled according to the model’s structure rather than being imputed randomly.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_173":{"__typename":"Paragraph","id":"a1d2c55f4d9a_173","name":"0171","type":"H3","href":null,"layout":null,"metadata":null,"text":"10. Custom Objective Functions and Evaluation Metrics in XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_174":{"__typename":"Paragraph","id":"a1d2c55f4d9a_174","name":"e809","type":"P","href":null,"layout":null,"metadata":null,"text":"One of XGBoost’s most powerful features is the ability for users to define their own objective function and evaluation metric. This allows the algorithm to be adapted beyond standard regression or classification tasks to specialized scenarios.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":85,"end":103,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":108,"end":125,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_175":{"__typename":"Paragraph","id":"a1d2c55f4d9a_175","name":"b702","type":"H4","href":null,"layout":null,"metadata":null,"text":"10.1. Custom Objective Function","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_176":{"__typename":"Paragraph","id":"a1d2c55f4d9a_176","name":"4647","type":"ULI","href":null,"layout":null,"metadata":null,"text":"XGBoost enables users to define their own loss functions.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_177":{"__typename":"Paragraph","id":"a1d2c55f4d9a_177","name":"27b2","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Particularly useful when standard loss functions (e.g., RMSE, log-loss) are insufficient or when the problem requires a specific error measure.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_178":{"__typename":"Paragraph","id":"a1d2c55f4d9a_178","name":"efbe","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Custom objective functions are defined as Python functions that return both the gradient and the Hessian (second-order derivative).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_179":{"__typename":"Paragraph","id":"a1d2c55f4d9a_179","name":"1d2d","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import xgboost as xgb\nimport numpy as np\n\n# Custom loss: squared error\ndef custom_rmse(preds, dtrain):\n    labels = dtrain.get_label()\n    grad = preds - labels          # gradient\n    hess = np.ones(len(labels))    # hessian\n    return grad, hess\n\nmodel = xgb.XGBRegressor(objective=custom_rmse, n_estimators=100)\nmodel.fit(X_train, y_train)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_180":{"__typename":"Paragraph","id":"a1d2c55f4d9a_180","name":"12c4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"grad: The first derivative of the loss function, indicating the direction in which the model should be updated.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_181":{"__typename":"Paragraph","id":"a1d2c55f4d9a_181","name":"97f1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"hess: The second derivative, which stabilizes learning rates and updates.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_182":{"__typename":"Paragraph","id":"a1d2c55f4d9a_182","name":"9383","type":"H4","href":null,"layout":null,"metadata":null,"text":"10.2. Custom Evaluation Function","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_183":{"__typename":"Paragraph","id":"a1d2c55f4d9a_183","name":"6c65","type":"ULI","href":null,"layout":null,"metadata":null,"text":"XGBoost can utilize a user-defined metric instead of standard metrics during training.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_184":{"__typename":"Paragraph","id":"a1d2c55f4d9a_184","name":"fc43","type":"ULI","href":null,"layout":null,"metadata":null,"text":"This metric evaluates the model’s performance on the validation set and can be used for mechanisms such as early stopping.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_185":{"__typename":"Paragraph","id":"a1d2c55f4d9a_185","name":"293d","type":"PRE","href":null,"layout":null,"metadata":null,"text":"def custom_eval(preds, dtrain):\n    labels = dtrain.get_label()\n    error = np.mean(np.abs(preds - labels))  # MAE\n    return 'mae', error\n\nmodel.fit(\n    X_train, y_train,\n    eval_set=[(X_test, y_test)],\n    eval_metric=custom_eval\n)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"scss"},"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_186":{"__typename":"Paragraph","id":"a1d2c55f4d9a_186","name":"8ab6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Must return the format 'metric_name', value.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":23,"end":43,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_187":{"__typename":"Paragraph","id":"a1d2c55f4d9a_187","name":"88cd","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Enables tracking of performance according to custom criteria beyond standard metrics.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_188":{"__typename":"Paragraph","id":"a1d2c55f4d9a_188","name":"cd26","type":"H4","href":null,"layout":null,"metadata":null,"text":"10.3. Strengths:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":15,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_189":{"__typename":"Paragraph","id":"a1d2c55f4d9a_189","name":"4fa9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Allows XGBoost to be adapted for specialized problems.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_190":{"__typename":"Paragraph","id":"a1d2c55f4d9a_190","name":"a088","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Applicable in diverse domains (e.g., financial risk modeling, ranking problems, imbalanced datasets).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_191":{"__typename":"Paragraph","id":"a1d2c55f4d9a_191","name":"d1bc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Provides control over the training process according to specific needs.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_192":{"__typename":"Paragraph","id":"a1d2c55f4d9a_192","name":"adf4","type":"H3","href":null,"layout":null,"metadata":null,"text":"11. Model Interpretability in XGBoost Using SHAP and LIME","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_193":{"__typename":"Paragraph","id":"a1d2c55f4d9a_193","name":"13cf","type":"P","href":null,"layout":null,"metadata":null,"text":"Due to XGBoost being composed of hundreds of decision trees, it is often regarded as a “black-box” model. In advanced projects, it is critical to explain the model’s decisions and understand which features influence predictions. Tools such as SHAP and LIME play a central role in this regard.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":243,"end":247,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":252,"end":256,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_194":{"__typename":"Paragraph","id":"a1d2c55f4d9a_194","name":"032c","type":"H4","href":null,"layout":null,"metadata":null,"text":"11.1. SHAP (SHapley Additive exPlanations)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*BpzVNC1bwzFmPSNxd5lMjA.png":{"__typename":"ImageMetadata","id":"1*BpzVNC1bwzFmPSNxd5lMjA.png","originalHeight":528,"originalWidth":850,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a1d2c55f4d9a_195":{"__typename":"Paragraph","id":"a1d2c55f4d9a_195","name":"e972","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*BpzVNC1bwzFmPSNxd5lMjA.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_196":{"__typename":"Paragraph","id":"a1d2c55f4d9a_196","name":"a4fa","type":"ULI","href":null,"layout":null,"metadata":null,"text":"SHAP calculates the contribution of each feature to a prediction based on game theory.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_197":{"__typename":"Paragraph","id":"a1d2c55f4d9a_197","name":"871c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Provides both global (overall importance across the dataset) and local (for individual observations) explanations.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":14,"end":20,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":65,"end":70,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_198":{"__typename":"Paragraph","id":"a1d2c55f4d9a_198","name":"b20c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Integrates seamlessly with XGBoost.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_199":{"__typename":"Paragraph","id":"a1d2c55f4d9a_199","name":"486e","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import shap\n\n# Calculate SHAP values\nexplainer = shap.Explainer(model)\nshap_values = explainer(X_test)\n\n# Global feature importance\nshap.summary_plot(shap_values, X_test)\n\n# Local explanation for a single example\nshap.force_plot(explainer.expected_value, shap_values[0,:], X_test[0,:])","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"makefile"},"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_200":{"__typename":"Paragraph","id":"a1d2c55f4d9a_200","name":"879b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"summary_plot → Visualizes the overall effect of all features.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_201":{"__typename":"Paragraph","id":"a1d2c55f4d9a_201","name":"2c27","type":"ULI","href":null,"layout":null,"metadata":null,"text":"force_plot → Shows how each feature contributes to a single prediction.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_202":{"__typename":"Paragraph","id":"a1d2c55f4d9a_202","name":"2b4c","type":"H4","href":null,"layout":null,"metadata":null,"text":"11.2. LIME (Local Interpretable Model-agnostic Explanations)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*p4kFd_BcPmKf-3-cNkGLew.png":{"__typename":"ImageMetadata","id":"1*p4kFd_BcPmKf-3-cNkGLew.png","originalHeight":449,"originalWidth":850,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:a1d2c55f4d9a_203":{"__typename":"Paragraph","id":"a1d2c55f4d9a_203","name":"01a3","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*p4kFd_BcPmKf-3-cNkGLew.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_204":{"__typename":"Paragraph","id":"a1d2c55f4d9a_204","name":"cf17","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LIME approximates the model’s local behavior by fitting a linear model around selected instances.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_205":{"__typename":"Paragraph","id":"a1d2c55f4d9a_205","name":"374f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"While not as theoretically grounded as SHAP, it provides fast and flexible interpretability.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_206":{"__typename":"Paragraph","id":"a1d2c55f4d9a_206","name":"2846","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Can be applied to any model, including XGBoost.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_207":{"__typename":"Paragraph","id":"a1d2c55f4d9a_207","name":"606b","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from lime import lime_tabular\n\nexplainer = lime_tabular.LimeTabularExplainer(\n    X_train, mode='classification', feature_names=feature_names\n)\n\n# Explanation for a single example\nexp = explainer.explain_instance(X_test[0], model.predict_proba)\nexp.show_in_notebook(show_table=True)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_208":{"__typename":"Paragraph","id":"a1d2c55f4d9a_208","name":"838f","type":"H4","href":null,"layout":null,"metadata":null,"text":"11.3. Strengths:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":15,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_209":{"__typename":"Paragraph","id":"a1d2c55f4d9a_209","name":"1015","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Provides transparency by visualizing the model’s decision process.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_210":{"__typename":"Paragraph","id":"a1d2c55f4d9a_210","name":"97ce","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Identifies important features, supporting business and data analysis.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_211":{"__typename":"Paragraph","id":"a1d2c55f4d9a_211","name":"3e8c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Plays a critical role in regulated industries (e.g., finance, healthcare) where explainability is required.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_212":{"__typename":"Paragraph","id":"a1d2c55f4d9a_212","name":"0019","type":"H3","href":null,"layout":null,"metadata":null,"text":"12. Ensemble Techniques with XGBoost: Stacking and Blending","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_213":{"__typename":"Paragraph","id":"a1d2c55f4d9a_213","name":"01bc","type":"P","href":null,"layout":null,"metadata":null,"text":"While XGBoost is a powerful standalone model, combining it with other algorithms through ensemble techniques can further enhance predictive performance. These methods are particularly popular in complex datasets and competitive environments.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_214":{"__typename":"Paragraph","id":"a1d2c55f4d9a_214","name":"6f0f","type":"H4","href":null,"layout":null,"metadata":null,"text":"12.1. Stacking (Layered Ensemble)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_215":{"__typename":"Paragraph","id":"a1d2c55f4d9a_215","name":"833b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Predictions from different models are used as input features for a learner in the next layer.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_216":{"__typename":"Paragraph","id":"a1d2c55f4d9a_216","name":"81df","type":"ULI","href":null,"layout":null,"metadata":null,"text":"XGBoost often serves as a meta-learner or as a strong base model in the first layer.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":26,"end":38,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_217":{"__typename":"Paragraph","id":"a1d2c55f4d9a_217","name":"1cff","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nestimators = [\n    ('xgb', xgb.XGBClassifier(n_estimators=100, random_state=42)),\n    ('svc', SVC(probability=True))\n]\n\nstacking_model = StackingClassifier(\n    estimators=estimators,\n    final_estimator=LogisticRegression()\n)\n\nstacking_model.fit(X_train, y_train)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_218":{"__typename":"Paragraph","id":"a1d2c55f4d9a_218","name":"9f66","type":"ULI","href":null,"layout":null,"metadata":null,"text":"First layer: Predictions from XGBoost and SVM","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_219":{"__typename":"Paragraph","id":"a1d2c55f4d9a_219","name":"7051","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Second layer: Logistic Regression combines these predictions to make the final decision","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_220":{"__typename":"Paragraph","id":"a1d2c55f4d9a_220","name":"da70","type":"H4","href":null,"layout":null,"metadata":null,"text":"12.2. Blending","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_221":{"__typename":"Paragraph","id":"a1d2c55f4d9a_221","name":"0a5e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Similar to stacking, but usually relies on a validation set for weighted predictions.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":45,"end":59,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_222":{"__typename":"Paragraph","id":"a1d2c55f4d9a_222","name":"8dcc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Faster than stacking and typically preferred for smaller datasets.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_223":{"__typename":"Paragraph","id":"a1d2c55f4d9a_223","name":"af21","type":"ULI","href":null,"layout":null,"metadata":null,"text":"XGBoost can function as either a base model or a meta-learner in blending frameworks.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_224":{"__typename":"Paragraph","id":"a1d2c55f4d9a_224","name":"adf6","type":"H4","href":null,"layout":null,"metadata":null,"text":"13.3. Strengths:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":15,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_225":{"__typename":"Paragraph","id":"a1d2c55f4d9a_225","name":"9368","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Combines the strengths of different algorithms to achieve higher accuracy.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_226":{"__typename":"Paragraph","id":"a1d2c55f4d9a_226","name":"ae54","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Reduces the risk of overfitting when model diversity is increased.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_227":{"__typename":"Paragraph","id":"a1d2c55f4d9a_227","name":"890e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Considered a strong strategy in competitive machine learning environments.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_228":{"__typename":"Paragraph","id":"a1d2c55f4d9a_228","name":"d063","type":"H3","href":null,"layout":null,"metadata":null,"text":"14. Distributed Training and GPU Optimization in XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_229":{"__typename":"Paragraph","id":"a1d2c55f4d9a_229","name":"9a30","type":"P","href":null,"layout":null,"metadata":null,"text":"XGBoost excels in scalability and speed, particularly when working with large datasets. Distributed training and GPU support are critical features for processing millions of rows efficiently.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_230":{"__typename":"Paragraph","id":"a1d2c55f4d9a_230","name":"2eab","type":"H4","href":null,"layout":null,"metadata":null,"text":"14.1. Distributed Training","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_231":{"__typename":"Paragraph","id":"a1d2c55f4d9a_231","name":"f424","type":"ULI","href":null,"layout":null,"metadata":null,"text":"XGBoost can partition data across multiple machines and train in parallel.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_232":{"__typename":"Paragraph","id":"a1d2c55f4d9a_232","name":"5e35","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Dramatically reduces training time for large datasets.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_233":{"__typename":"Paragraph","id":"a1d2c55f4d9a_233","name":"13f0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Integrates with distributed frameworks such as Hadoop or Spark.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_234":{"__typename":"Paragraph","id":"a1d2c55f4d9a_234","name":"e345","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import dask.dataframe as dd\nfrom dask_ml.model_selection import train_test_split\nimport xgboost as xgb\n\n# Dask DataFrame\nX = dd.read_csv('large_dataset.csv')\ny = X.pop('target')\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Dask XGBoost\ndask_model = xgb.dask.DaskXGBClassifier(\n    n_estimators=500,\n    max_depth=6,\n    learning_rate=0.1,\n    objective='binary:logistic'\n)\n\ndask_model.fit(X_train, y_train)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_235":{"__typename":"Paragraph","id":"a1d2c55f4d9a_235","name":"c3c8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"During distributed training, XGBoost optimizes data parallelism and workload balancing.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_236":{"__typename":"Paragraph","id":"a1d2c55f4d9a_236","name":"a924","type":"H4","href":null,"layout":null,"metadata":null,"text":"14.2. GPU Utilization","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_237":{"__typename":"Paragraph","id":"a1d2c55f4d9a_237","name":"205b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GPU computation, particularly with the gpu_hist method, accelerates training on large datasets.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":39,"end":47,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_238":{"__typename":"Paragraph","id":"a1d2c55f4d9a_238","name":"b4d6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Supports training on a single GPU or multi-GPU environments.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_239":{"__typename":"Paragraph","id":"a1d2c55f4d9a_239","name":"0a9b","type":"PRE","href":null,"layout":null,"metadata":null,"text":"gpu_model = xgb.XGBClassifier(\n    tree_method='gpu_hist',\n    n_estimators=1000,\n    max_depth=6,\n    learning_rate=0.05\n)\n\ngpu_model.fit(X_train, y_train)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"bash"},"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_240":{"__typename":"Paragraph","id":"a1d2c55f4d9a_240","name":"8e7a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GPU usage can provide 10–50× faster training compared to CPU.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":22,"end":44,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_241":{"__typename":"Paragraph","id":"a1d2c55f4d9a_241","name":"1180","type":"ULI","href":null,"layout":null,"metadata":null,"text":"This is one of XGBoost’s most significant performance advantages for large datasets and deep trees.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_242":{"__typename":"Paragraph","id":"a1d2c55f4d9a_242","name":"a0b7","type":"H4","href":null,"layout":null,"metadata":null,"text":"14.3. Strengths:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":15,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_243":{"__typename":"Paragraph","id":"a1d2c55f4d9a_243","name":"be2f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Enhances capacity to handle large datasets.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_244":{"__typename":"Paragraph","id":"a1d2c55f4d9a_244","name":"9fea","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Significantly reduces training time.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_245":{"__typename":"Paragraph","id":"a1d2c55f4d9a_245","name":"12a0","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Makes XGBoost scalable for real-world industrial applications through distributed or GPU-accelerated training.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_246":{"__typename":"Paragraph","id":"a1d2c55f4d9a_246","name":"7926","type":"H3","href":null,"layout":null,"metadata":null,"text":"15. Conclusion and Practical Recommendations","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_247":{"__typename":"Paragraph","id":"a1d2c55f4d9a_247","name":"82ea","type":"P","href":null,"layout":null,"metadata":null,"text":"XGBoost stands out in the data science landscape due to its high performance, flexibility, and scalability. However, its strength does not automatically make it the best choice in every scenario. This section discusses key considerations when using XGBoost, appropriate use cases, and alternative algorithms.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_248":{"__typename":"Paragraph","id":"a1d2c55f4d9a_248","name":"3c4c","type":"H4","href":null,"layout":null,"metadata":null,"text":"15.1. Critical Considerations for Using XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_249":{"__typename":"Paragraph","id":"a1d2c55f4d9a_249","name":"771c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Hyperparameter tuning: Without properly tuned hyperparameters, the model can underfit or overfit.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_250":{"__typename":"Paragraph","id":"a1d2c55f4d9a_250","name":"668b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Feature engineering: While XGBoost optimizes for missing and sparse values, quality feature engineering remains critical for structured datasets.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":20,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_251":{"__typename":"Paragraph","id":"a1d2c55f4d9a_251","name":"69cd","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Model interpretability: Due to its complex structure, tools such as SHAP or LIME are important to understand decision-making.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_252":{"__typename":"Paragraph","id":"a1d2c55f4d9a_252","name":"60a5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Resource management: For large datasets, training time should be optimized using GPU acceleration or distributed training strategies.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":20,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_253":{"__typename":"Paragraph","id":"a1d2c55f4d9a_253","name":"ca62","type":"H4","href":null,"layout":null,"metadata":null,"text":"15.2. Recommended Applications","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_254":{"__typename":"Paragraph","id":"a1d2c55f4d9a_254","name":"ea71","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Structured (tabular) datasets: Particularly strong in finance, healthcare, sales, and marketing.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":30,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_255":{"__typename":"Paragraph","id":"a1d2c55f4d9a_255","name":"0d60","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Medium to large datasets: Efficient training due to parallelization and GPU support.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":25,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_256":{"__typename":"Paragraph","id":"a1d2c55f4d9a_256","name":"7eb8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"High accuracy requirements: Ideal for competitive environments or critical business applications.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":27,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_257":{"__typename":"Paragraph","id":"a1d2c55f4d9a_257","name":"6863","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Missing or sparse data: Sparsity-aware optimizations ensure reliable predictions.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_258":{"__typename":"Paragraph","id":"a1d2c55f4d9a_258","name":"cdf3","type":"H4","href":null,"layout":null,"metadata":null,"text":"15.3. Alternative Algorithms and Comparative Analysis","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_259":{"__typename":"Paragraph","id":"a1d2c55f4d9a_259","name":"3667","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Random Forest: Similar performance with fewer parameters, but slower and more prone to overfitting.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":14,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_260":{"__typename":"Paragraph","id":"a1d2c55f4d9a_260","name":"9ae5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Gradient Boosting (scikit-learn): Less optimized and less parallelized compared to XGBoost.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":33,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_261":{"__typename":"Paragraph","id":"a1d2c55f4d9a_261","name":"588d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LightGBM and CatBoost: Modern boosting alternatives; LightGBM excels with very large datasets, CatBoost performs well with categorical features.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_262":{"__typename":"Paragraph","id":"a1d2c55f4d9a_262","name":"4b84","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Logistic Regression or Decision Tree: Preferred for simple or small datasets; highly interpretable but potentially lower performance.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":37,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_263":{"__typename":"Paragraph","id":"a1d2c55f4d9a_263","name":"994a","type":"BQ","href":null,"layout":null,"metadata":null,"text":"“XGBoost combines the principles of gradient boosting with advanced engineering optimizations, making it one of the most powerful and versatile tools for structured data analysis in both academic research and industry applications.” — Chen & Guestrin, 2016","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_264":{"__typename":"Paragraph","id":"a1d2c55f4d9a_264","name":"2c21","type":"H3","href":null,"layout":null,"metadata":null,"text":"From Theory to Application: Unboxing XGBoost in Practice","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_265":{"__typename":"Paragraph","id":"a1d2c55f4d9a_265","name":"93ad","type":"P","href":null,"layout":null,"metadata":null,"text":"We have thoroughly explored the theoretical depth, optimization mechanisms, and strategies for controlling overfitting inherent in XGBoost. For any data scientist, the final step is conquering the model’s most challenging aspect: interpretability.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":230,"end":246,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_266":{"__typename":"Paragraph","id":"a1d2c55f4d9a_266","name":"1adf","type":"P","href":null,"layout":null,"metadata":null,"text":"To that end, we have prepared a comprehensive and hands-on Notebook demonstrating all the advanced concepts discussed in this article. This includes Hyperparameter Optimization, Feature Importance Metrics, and crucially, how to explain individual predictions using SHAP (SHapley Additive exPlanations) values.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":32,"end":67,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":149,"end":176,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":178,"end":204,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":265,"end":301,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_267":{"__typename":"Paragraph","id":"a1d2c55f4d9a_267","name":"e7bd","type":"P","href":null,"layout":null,"metadata":null,"text":"Using this interactive environment, you can practice:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_268":{"__typename":"Paragraph","id":"a1d2c55f4d9a_268","name":"b2cc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Training and comparing XGBoost models with different hyperparameter sets.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_269":{"__typename":"Paragraph","id":"a1d2c55f4d9a_269","name":"164b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Identifying the optimal parameter combination for peak performance and stability.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_270":{"__typename":"Paragraph","id":"a1d2c55f4d9a_270","name":"87b3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Interpreting the model’s global and local predictions using SHAP visualizations.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":60,"end":79,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_271":{"__typename":"Paragraph","id":"a1d2c55f4d9a_271","name":"9d15","type":"P","href":null,"layout":null,"metadata":null,"text":"Convert theoretical knowledge into practical skill and lift the veil on the XGBoost black box by starting here:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_272":{"__typename":"Paragraph","id":"a1d2c55f4d9a_272","name":"4f03","type":"P","href":null,"layout":null,"metadata":null,"text":"Kaggle Notebook","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":15,"href":"https:\u002F\u002Fwww.kaggle.com\u002Fcode\u002Fenesml\u002Fxgboost-optimization-and-shap-analysis","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_273":{"__typename":"Paragraph","id":"a1d2c55f4d9a_273","name":"a9d2","type":"H3","href":null,"layout":null,"metadata":null,"text":"References","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_274":{"__typename":"Paragraph","id":"a1d2c55f4d9a_274","name":"4eff","type":"P","href":null,"layout":null,"metadata":null,"text":"Chen, T., & Guestrin, C. (2016). “XGBoost: A Scalable Tree Boosting System.” Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":33,"end":76,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":77,"end":176,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_275":{"__typename":"Paragraph","id":"a1d2c55f4d9a_275","name":"33e8","type":"P","href":null,"layout":null,"metadata":null,"text":"XGBoost Official Documentation. (Detailed parameters, features, and best practices for the library.) XGBoost","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":101,"end":108,"href":"https:\u002F\u002Fxgboost.readthedocs.io\u002Fen\u002Fstable\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_276":{"__typename":"Paragraph","id":"a1d2c55f4d9a_276","name":"c6aa","type":"P","href":null,"layout":null,"metadata":null,"text":"Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":52,"end":66,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":67,"end":77,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_277":{"__typename":"Paragraph","id":"a1d2c55f4d9a_277","name":"a10d","type":"H3","href":null,"layout":null,"metadata":null,"text":"Continue Your Supervised Learning Journey!","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_278":{"__typename":"Paragraph","id":"a1d2c55f4d9a_278","name":"6079","type":"P","href":null,"layout":null,"metadata":null,"text":"If you’ve mastered the complexity of XGBoost, it’s beneficial to reinforce the fundamental concepts that underpin supervised learning. Dive deeper into the foundational models with the guides below:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_279":{"__typename":"Paragraph","id":"a1d2c55f4d9a_279","name":"2086","type":"P","href":null,"layout":null,"metadata":null,"text":"1. The Foundation: Linear Regression","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":36,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_280":{"__typename":"Paragraph","id":"a1d2c55f4d9a_280","name":"16bd","type":"P","href":null,"layout":null,"metadata":null,"text":"Before tackling complex models, understanding the elegance of simplicity is key. Explore my detailed guide on Linear Regression: Understanding the Simple Yet Powerful Model to solidify your grasp on statistical modeling and model interpretability.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":110,"end":172,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_281":{"__typename":"Paragraph","id":"a1d2c55f4d9a_281","name":"2109","type":"P","href":null,"layout":null,"metadata":null,"text":"Linear Regression","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":17,"href":"https:\u002F\u002Fmedium.com\u002F@ml.enesguler\u002Flinear-regression-temel-kavramlardan-i%CC%87leri-seviye-uygulamalara-7c89c95091b3","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_282":{"__typename":"Paragraph","id":"a1d2c55f4d9a_282","name":"e615","type":"P","href":null,"layout":null,"metadata":null,"text":"2. The Instance-Based Approach: K-Nearest Neighbors (KNN)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":57,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_283":{"__typename":"Paragraph","id":"a1d2c55f4d9a_283","name":"b8fa","type":"P","href":null,"layout":null,"metadata":null,"text":"Moving beyond tree-based models, discover the power of non-parametric, instance-based learning. My guide, K-Nearest Neighbors: How the Simplest Algorithm Tackles Complex Classification, provides practical insights into distance metrics and lazy learning.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":106,"end":184,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:a1d2c55f4d9a_284":{"__typename":"Paragraph","id":"a1d2c55f4d9a_284","name":"51cb","type":"P","href":null,"layout":null,"metadata":null,"text":"KNN","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":3,"href":"https:\u002F\u002Fmedium.com\u002F@ml.enesguler\u002Fk-nearest-neighbors-k-nn-s%C4%B1f%C4%B1rdan-senior-seviyeye-kapsaml%C4%B1-rehber-876e27d8c8e8","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"UserViewerEdge:userId:b6a26fecee8e-viewerId:lo_dc62f1b31c7a":{"__typename":"UserViewerEdge","id":"userId:b6a26fecee8e-viewerId:lo_dc62f1b31c7a","isMuting":false},"PostViewerEdge:postId:d88536d87038-viewerId:lo_dc62f1b31c7a":{"__typename":"PostViewerEdge","shouldIndexPostForExternalSearch":true,"id":"postId:d88536d87038-viewerId:lo_dc62f1b31c7a"},"Tag:xgboost":{"__typename":"Tag","id":"xgboost","displayTitle":"Xgboost","normalizedTagSlug":"xgboost"},"Tag:data-science":{"__typename":"Tag","id":"data-science","displayTitle":"Data Science","normalizedTagSlug":"data-science"},"Tag:ai":{"__typename":"Tag","id":"ai","displayTitle":"AI","normalizedTagSlug":"ai"},"Tag:supervised-learning":{"__typename":"Tag","id":"supervised-learning","displayTitle":"Supervised Learning","normalizedTagSlug":"supervised-learning"},"Tag:machine-learning":{"__typename":"Tag","id":"machine-learning","displayTitle":"Machine Learning","normalizedTagSlug":"machine-learning"},"Post:d88536d87038":{"__typename":"Post","id":"d88536d87038","collection":null,"content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"c565","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:a1d2c55f4d9a_0"},{"__ref":"Paragraph:a1d2c55f4d9a_1"},{"__ref":"Paragraph:a1d2c55f4d9a_2"},{"__ref":"Paragraph:a1d2c55f4d9a_3"},{"__ref":"Paragraph:a1d2c55f4d9a_4"},{"__ref":"Paragraph:a1d2c55f4d9a_5"},{"__ref":"Paragraph:a1d2c55f4d9a_6"},{"__ref":"Paragraph:a1d2c55f4d9a_7"},{"__ref":"Paragraph:a1d2c55f4d9a_8"},{"__ref":"Paragraph:a1d2c55f4d9a_9"},{"__ref":"Paragraph:a1d2c55f4d9a_10"},{"__ref":"Paragraph:a1d2c55f4d9a_11"},{"__ref":"Paragraph:a1d2c55f4d9a_12"},{"__ref":"Paragraph:a1d2c55f4d9a_13"},{"__ref":"Paragraph:a1d2c55f4d9a_14"},{"__ref":"Paragraph:a1d2c55f4d9a_15"},{"__ref":"Paragraph:a1d2c55f4d9a_16"},{"__ref":"Paragraph:a1d2c55f4d9a_17"},{"__ref":"Paragraph:a1d2c55f4d9a_18"},{"__ref":"Paragraph:a1d2c55f4d9a_19"},{"__ref":"Paragraph:a1d2c55f4d9a_20"},{"__ref":"Paragraph:a1d2c55f4d9a_21"},{"__ref":"Paragraph:a1d2c55f4d9a_22"},{"__ref":"Paragraph:a1d2c55f4d9a_23"},{"__ref":"Paragraph:a1d2c55f4d9a_24"},{"__ref":"Paragraph:a1d2c55f4d9a_25"},{"__ref":"Paragraph:a1d2c55f4d9a_26"},{"__ref":"Paragraph:a1d2c55f4d9a_27"},{"__ref":"Paragraph:a1d2c55f4d9a_28"},{"__ref":"Paragraph:a1d2c55f4d9a_29"},{"__ref":"Paragraph:a1d2c55f4d9a_30"},{"__ref":"Paragraph:a1d2c55f4d9a_31"},{"__ref":"Paragraph:a1d2c55f4d9a_32"},{"__ref":"Paragraph:a1d2c55f4d9a_33"},{"__ref":"Paragraph:a1d2c55f4d9a_34"},{"__ref":"Paragraph:a1d2c55f4d9a_35"},{"__ref":"Paragraph:a1d2c55f4d9a_36"},{"__ref":"Paragraph:a1d2c55f4d9a_37"},{"__ref":"Paragraph:a1d2c55f4d9a_38"},{"__ref":"Paragraph:a1d2c55f4d9a_39"},{"__ref":"Paragraph:a1d2c55f4d9a_40"},{"__ref":"Paragraph:a1d2c55f4d9a_41"},{"__ref":"Paragraph:a1d2c55f4d9a_42"},{"__ref":"Paragraph:a1d2c55f4d9a_43"},{"__ref":"Paragraph:a1d2c55f4d9a_44"},{"__ref":"Paragraph:a1d2c55f4d9a_45"},{"__ref":"Paragraph:a1d2c55f4d9a_46"},{"__ref":"Paragraph:a1d2c55f4d9a_47"},{"__ref":"Paragraph:a1d2c55f4d9a_48"},{"__ref":"Paragraph:a1d2c55f4d9a_49"},{"__ref":"Paragraph:a1d2c55f4d9a_50"},{"__ref":"Paragraph:a1d2c55f4d9a_51"},{"__ref":"Paragraph:a1d2c55f4d9a_52"},{"__ref":"Paragraph:a1d2c55f4d9a_53"},{"__ref":"Paragraph:a1d2c55f4d9a_54"},{"__ref":"Paragraph:a1d2c55f4d9a_55"},{"__ref":"Paragraph:a1d2c55f4d9a_56"},{"__ref":"Paragraph:a1d2c55f4d9a_57"},{"__ref":"Paragraph:a1d2c55f4d9a_58"},{"__ref":"Paragraph:a1d2c55f4d9a_59"},{"__ref":"Paragraph:a1d2c55f4d9a_60"},{"__ref":"Paragraph:a1d2c55f4d9a_61"},{"__ref":"Paragraph:a1d2c55f4d9a_62"},{"__ref":"Paragraph:a1d2c55f4d9a_63"},{"__ref":"Paragraph:a1d2c55f4d9a_64"},{"__ref":"Paragraph:a1d2c55f4d9a_65"},{"__ref":"Paragraph:a1d2c55f4d9a_66"},{"__ref":"Paragraph:a1d2c55f4d9a_67"},{"__ref":"Paragraph:a1d2c55f4d9a_68"},{"__ref":"Paragraph:a1d2c55f4d9a_69"},{"__ref":"Paragraph:a1d2c55f4d9a_70"},{"__ref":"Paragraph:a1d2c55f4d9a_71"},{"__ref":"Paragraph:a1d2c55f4d9a_72"},{"__ref":"Paragraph:a1d2c55f4d9a_73"},{"__ref":"Paragraph:a1d2c55f4d9a_74"},{"__ref":"Paragraph:a1d2c55f4d9a_75"},{"__ref":"Paragraph:a1d2c55f4d9a_76"},{"__ref":"Paragraph:a1d2c55f4d9a_77"},{"__ref":"Paragraph:a1d2c55f4d9a_78"},{"__ref":"Paragraph:a1d2c55f4d9a_79"},{"__ref":"Paragraph:a1d2c55f4d9a_80"},{"__ref":"Paragraph:a1d2c55f4d9a_81"},{"__ref":"Paragraph:a1d2c55f4d9a_82"},{"__ref":"Paragraph:a1d2c55f4d9a_83"},{"__ref":"Paragraph:a1d2c55f4d9a_84"},{"__ref":"Paragraph:a1d2c55f4d9a_85"},{"__ref":"Paragraph:a1d2c55f4d9a_86"},{"__ref":"Paragraph:a1d2c55f4d9a_87"},{"__ref":"Paragraph:a1d2c55f4d9a_88"},{"__ref":"Paragraph:a1d2c55f4d9a_89"},{"__ref":"Paragraph:a1d2c55f4d9a_90"},{"__ref":"Paragraph:a1d2c55f4d9a_91"},{"__ref":"Paragraph:a1d2c55f4d9a_92"},{"__ref":"Paragraph:a1d2c55f4d9a_93"},{"__ref":"Paragraph:a1d2c55f4d9a_94"},{"__ref":"Paragraph:a1d2c55f4d9a_95"},{"__ref":"Paragraph:a1d2c55f4d9a_96"},{"__ref":"Paragraph:a1d2c55f4d9a_97"},{"__ref":"Paragraph:a1d2c55f4d9a_98"},{"__ref":"Paragraph:a1d2c55f4d9a_99"},{"__ref":"Paragraph:a1d2c55f4d9a_100"},{"__ref":"Paragraph:a1d2c55f4d9a_101"},{"__ref":"Paragraph:a1d2c55f4d9a_102"},{"__ref":"Paragraph:a1d2c55f4d9a_103"},{"__ref":"Paragraph:a1d2c55f4d9a_104"},{"__ref":"Paragraph:a1d2c55f4d9a_105"},{"__ref":"Paragraph:a1d2c55f4d9a_106"},{"__ref":"Paragraph:a1d2c55f4d9a_107"},{"__ref":"Paragraph:a1d2c55f4d9a_108"},{"__ref":"Paragraph:a1d2c55f4d9a_109"},{"__ref":"Paragraph:a1d2c55f4d9a_110"},{"__ref":"Paragraph:a1d2c55f4d9a_111"},{"__ref":"Paragraph:a1d2c55f4d9a_112"},{"__ref":"Paragraph:a1d2c55f4d9a_113"},{"__ref":"Paragraph:a1d2c55f4d9a_114"},{"__ref":"Paragraph:a1d2c55f4d9a_115"},{"__ref":"Paragraph:a1d2c55f4d9a_116"},{"__ref":"Paragraph:a1d2c55f4d9a_117"},{"__ref":"Paragraph:a1d2c55f4d9a_118"},{"__ref":"Paragraph:a1d2c55f4d9a_119"},{"__ref":"Paragraph:a1d2c55f4d9a_120"},{"__ref":"Paragraph:a1d2c55f4d9a_121"},{"__ref":"Paragraph:a1d2c55f4d9a_122"},{"__ref":"Paragraph:a1d2c55f4d9a_123"},{"__ref":"Paragraph:a1d2c55f4d9a_124"},{"__ref":"Paragraph:a1d2c55f4d9a_125"},{"__ref":"Paragraph:a1d2c55f4d9a_126"},{"__ref":"Paragraph:a1d2c55f4d9a_127"},{"__ref":"Paragraph:a1d2c55f4d9a_128"},{"__ref":"Paragraph:a1d2c55f4d9a_129"},{"__ref":"Paragraph:a1d2c55f4d9a_130"},{"__ref":"Paragraph:a1d2c55f4d9a_131"},{"__ref":"Paragraph:a1d2c55f4d9a_132"},{"__ref":"Paragraph:a1d2c55f4d9a_133"},{"__ref":"Paragraph:a1d2c55f4d9a_134"},{"__ref":"Paragraph:a1d2c55f4d9a_135"},{"__ref":"Paragraph:a1d2c55f4d9a_136"},{"__ref":"Paragraph:a1d2c55f4d9a_137"},{"__ref":"Paragraph:a1d2c55f4d9a_138"},{"__ref":"Paragraph:a1d2c55f4d9a_139"},{"__ref":"Paragraph:a1d2c55f4d9a_140"},{"__ref":"Paragraph:a1d2c55f4d9a_141"},{"__ref":"Paragraph:a1d2c55f4d9a_142"},{"__ref":"Paragraph:a1d2c55f4d9a_143"},{"__ref":"Paragraph:a1d2c55f4d9a_144"},{"__ref":"Paragraph:a1d2c55f4d9a_145"},{"__ref":"Paragraph:a1d2c55f4d9a_146"},{"__ref":"Paragraph:a1d2c55f4d9a_147"},{"__ref":"Paragraph:a1d2c55f4d9a_148"},{"__ref":"Paragraph:a1d2c55f4d9a_149"},{"__ref":"Paragraph:a1d2c55f4d9a_150"},{"__ref":"Paragraph:a1d2c55f4d9a_151"},{"__ref":"Paragraph:a1d2c55f4d9a_152"},{"__ref":"Paragraph:a1d2c55f4d9a_153"},{"__ref":"Paragraph:a1d2c55f4d9a_154"},{"__ref":"Paragraph:a1d2c55f4d9a_155"},{"__ref":"Paragraph:a1d2c55f4d9a_156"},{"__ref":"Paragraph:a1d2c55f4d9a_157"},{"__ref":"Paragraph:a1d2c55f4d9a_158"},{"__ref":"Paragraph:a1d2c55f4d9a_159"},{"__ref":"Paragraph:a1d2c55f4d9a_160"},{"__ref":"Paragraph:a1d2c55f4d9a_161"},{"__ref":"Paragraph:a1d2c55f4d9a_162"},{"__ref":"Paragraph:a1d2c55f4d9a_163"},{"__ref":"Paragraph:a1d2c55f4d9a_164"},{"__ref":"Paragraph:a1d2c55f4d9a_165"},{"__ref":"Paragraph:a1d2c55f4d9a_166"},{"__ref":"Paragraph:a1d2c55f4d9a_167"},{"__ref":"Paragraph:a1d2c55f4d9a_168"},{"__ref":"Paragraph:a1d2c55f4d9a_169"},{"__ref":"Paragraph:a1d2c55f4d9a_170"},{"__ref":"Paragraph:a1d2c55f4d9a_171"},{"__ref":"Paragraph:a1d2c55f4d9a_172"},{"__ref":"Paragraph:a1d2c55f4d9a_173"},{"__ref":"Paragraph:a1d2c55f4d9a_174"},{"__ref":"Paragraph:a1d2c55f4d9a_175"},{"__ref":"Paragraph:a1d2c55f4d9a_176"},{"__ref":"Paragraph:a1d2c55f4d9a_177"},{"__ref":"Paragraph:a1d2c55f4d9a_178"},{"__ref":"Paragraph:a1d2c55f4d9a_179"},{"__ref":"Paragraph:a1d2c55f4d9a_180"},{"__ref":"Paragraph:a1d2c55f4d9a_181"},{"__ref":"Paragraph:a1d2c55f4d9a_182"},{"__ref":"Paragraph:a1d2c55f4d9a_183"},{"__ref":"Paragraph:a1d2c55f4d9a_184"},{"__ref":"Paragraph:a1d2c55f4d9a_185"},{"__ref":"Paragraph:a1d2c55f4d9a_186"},{"__ref":"Paragraph:a1d2c55f4d9a_187"},{"__ref":"Paragraph:a1d2c55f4d9a_188"},{"__ref":"Paragraph:a1d2c55f4d9a_189"},{"__ref":"Paragraph:a1d2c55f4d9a_190"},{"__ref":"Paragraph:a1d2c55f4d9a_191"},{"__ref":"Paragraph:a1d2c55f4d9a_192"},{"__ref":"Paragraph:a1d2c55f4d9a_193"},{"__ref":"Paragraph:a1d2c55f4d9a_194"},{"__ref":"Paragraph:a1d2c55f4d9a_195"},{"__ref":"Paragraph:a1d2c55f4d9a_196"},{"__ref":"Paragraph:a1d2c55f4d9a_197"},{"__ref":"Paragraph:a1d2c55f4d9a_198"},{"__ref":"Paragraph:a1d2c55f4d9a_199"},{"__ref":"Paragraph:a1d2c55f4d9a_200"},{"__ref":"Paragraph:a1d2c55f4d9a_201"},{"__ref":"Paragraph:a1d2c55f4d9a_202"},{"__ref":"Paragraph:a1d2c55f4d9a_203"},{"__ref":"Paragraph:a1d2c55f4d9a_204"},{"__ref":"Paragraph:a1d2c55f4d9a_205"},{"__ref":"Paragraph:a1d2c55f4d9a_206"},{"__ref":"Paragraph:a1d2c55f4d9a_207"},{"__ref":"Paragraph:a1d2c55f4d9a_208"},{"__ref":"Paragraph:a1d2c55f4d9a_209"},{"__ref":"Paragraph:a1d2c55f4d9a_210"},{"__ref":"Paragraph:a1d2c55f4d9a_211"},{"__ref":"Paragraph:a1d2c55f4d9a_212"},{"__ref":"Paragraph:a1d2c55f4d9a_213"},{"__ref":"Paragraph:a1d2c55f4d9a_214"},{"__ref":"Paragraph:a1d2c55f4d9a_215"},{"__ref":"Paragraph:a1d2c55f4d9a_216"},{"__ref":"Paragraph:a1d2c55f4d9a_217"},{"__ref":"Paragraph:a1d2c55f4d9a_218"},{"__ref":"Paragraph:a1d2c55f4d9a_219"},{"__ref":"Paragraph:a1d2c55f4d9a_220"},{"__ref":"Paragraph:a1d2c55f4d9a_221"},{"__ref":"Paragraph:a1d2c55f4d9a_222"},{"__ref":"Paragraph:a1d2c55f4d9a_223"},{"__ref":"Paragraph:a1d2c55f4d9a_224"},{"__ref":"Paragraph:a1d2c55f4d9a_225"},{"__ref":"Paragraph:a1d2c55f4d9a_226"},{"__ref":"Paragraph:a1d2c55f4d9a_227"},{"__ref":"Paragraph:a1d2c55f4d9a_228"},{"__ref":"Paragraph:a1d2c55f4d9a_229"},{"__ref":"Paragraph:a1d2c55f4d9a_230"},{"__ref":"Paragraph:a1d2c55f4d9a_231"},{"__ref":"Paragraph:a1d2c55f4d9a_232"},{"__ref":"Paragraph:a1d2c55f4d9a_233"},{"__ref":"Paragraph:a1d2c55f4d9a_234"},{"__ref":"Paragraph:a1d2c55f4d9a_235"},{"__ref":"Paragraph:a1d2c55f4d9a_236"},{"__ref":"Paragraph:a1d2c55f4d9a_237"},{"__ref":"Paragraph:a1d2c55f4d9a_238"},{"__ref":"Paragraph:a1d2c55f4d9a_239"},{"__ref":"Paragraph:a1d2c55f4d9a_240"},{"__ref":"Paragraph:a1d2c55f4d9a_241"},{"__ref":"Paragraph:a1d2c55f4d9a_242"},{"__ref":"Paragraph:a1d2c55f4d9a_243"},{"__ref":"Paragraph:a1d2c55f4d9a_244"},{"__ref":"Paragraph:a1d2c55f4d9a_245"},{"__ref":"Paragraph:a1d2c55f4d9a_246"},{"__ref":"Paragraph:a1d2c55f4d9a_247"},{"__ref":"Paragraph:a1d2c55f4d9a_248"},{"__ref":"Paragraph:a1d2c55f4d9a_249"},{"__ref":"Paragraph:a1d2c55f4d9a_250"},{"__ref":"Paragraph:a1d2c55f4d9a_251"},{"__ref":"Paragraph:a1d2c55f4d9a_252"},{"__ref":"Paragraph:a1d2c55f4d9a_253"},{"__ref":"Paragraph:a1d2c55f4d9a_254"},{"__ref":"Paragraph:a1d2c55f4d9a_255"},{"__ref":"Paragraph:a1d2c55f4d9a_256"},{"__ref":"Paragraph:a1d2c55f4d9a_257"},{"__ref":"Paragraph:a1d2c55f4d9a_258"},{"__ref":"Paragraph:a1d2c55f4d9a_259"},{"__ref":"Paragraph:a1d2c55f4d9a_260"},{"__ref":"Paragraph:a1d2c55f4d9a_261"},{"__ref":"Paragraph:a1d2c55f4d9a_262"},{"__ref":"Paragraph:a1d2c55f4d9a_263"},{"__ref":"Paragraph:a1d2c55f4d9a_264"},{"__ref":"Paragraph:a1d2c55f4d9a_265"},{"__ref":"Paragraph:a1d2c55f4d9a_266"},{"__ref":"Paragraph:a1d2c55f4d9a_267"},{"__ref":"Paragraph:a1d2c55f4d9a_268"},{"__ref":"Paragraph:a1d2c55f4d9a_269"},{"__ref":"Paragraph:a1d2c55f4d9a_270"},{"__ref":"Paragraph:a1d2c55f4d9a_271"},{"__ref":"Paragraph:a1d2c55f4d9a_272"},{"__ref":"Paragraph:a1d2c55f4d9a_273"},{"__ref":"Paragraph:a1d2c55f4d9a_274"},{"__ref":"Paragraph:a1d2c55f4d9a_275"},{"__ref":"Paragraph:a1d2c55f4d9a_276"},{"__ref":"Paragraph:a1d2c55f4d9a_277"},{"__ref":"Paragraph:a1d2c55f4d9a_278"},{"__ref":"Paragraph:a1d2c55f4d9a_279"},{"__ref":"Paragraph:a1d2c55f4d9a_280"},{"__ref":"Paragraph:a1d2c55f4d9a_281"},{"__ref":"Paragraph:a1d2c55f4d9a_282"},{"__ref":"Paragraph:a1d2c55f4d9a_283"},{"__ref":"Paragraph:a1d2c55f4d9a_284"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:b6a26fecee8e"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@ml.enesguler\u002Funderstanding-xgboost-from-basics-to-advanced-insights-d88536d87038","primaryTopic":null,"topics":[{"__typename":"Topic","slug":"machine-learning"},{"__typename":"Topic","slug":"data-science"}],"isLimitedState":false,"isPublished":true,"allowResponses":true,"responsesLocked":false,"visibility":"PUBLIC","latestPublishedVersion":"a1d2c55f4d9a","postResponses":{"__typename":"PostResponses","count":0},"responseDistribution":"NOT_DISTRIBUTED","clapCount":3,"title":"Understanding XGBoost: From Basics to Advanced Insights","isSeries":false,"sequence":null,"uniqueSlug":"understanding-xgboost-from-basics-to-advanced-insights-d88536d87038","socialTitle":"","socialDek":"","canonicalUrl":"https:\u002F\u002Fmedium.com\u002F@ml.enesguler\u002Fxgboost-basics-to-advanced-guide","metaDescription":"","latestPublishedAt":1762432612833,"readingTime":16.027672955974843,"previewContent":{"__typename":"PreviewContent","subtitle":"Explore XGBoost from fundamentals to advanced techniques, including hyperparameter tuning, interpretability, and practical applications."},"previewImage":{"__ref":"ImageMetadata:1*y0Zpd2U2nGIPmha5XniRgw.png"},"isShortform":false,"seoMetaTags":{"__typename":"SEOMetaTags","jsonLd":"{\"@context\":\"https:\u002F\u002Fschema.org\",\"@id\":\"https:\u002F\u002Fmedium.com\u002F@ml.enesguler\u002Fxgboost-basics-to-advanced-guide\",\"@type\":\"SocialMediaPosting\",\"image\":[\"https:\u002F\u002Fmiro.medium.com\u002F1*y0Zpd2U2nGIPmha5XniRgw.png\"],\"url\":\"https:\u002F\u002Fmedium.com\u002F@ml.enesguler\u002Fxgboost-basics-to-advanced-guide\",\"dateCreated\":\"2025-09-27T07:25:24Z\",\"datePublished\":\"2025-09-27T07:25:24Z\",\"dateModified\":\"2025-11-06T12:36:52Z\",\"headline\":\"Understanding XGBoost: From Basics to Advanced Insights\",\"name\":\"Understanding XGBoost: From Basics to Advanced Insights\",\"description\":\"Unlock the power of XGBoost, the leading gradient boosting algorithm. Learn its core principles, from decision trees to regularization, and implement it effectively in Python for superior model performance.\",\"identifier\":\"d88536d87038\",\"author\":{\"@context\":\"https:\u002F\u002Fschema.org\",\"@id\":\"https:\u002F\u002Fmedium.com\u002F@ml.enesguler\",\"@type\":\"Person\",\"identifier\":\"ml.enesguler\",\"name\":\"Enes Güler\",\"url\":\"https:\u002F\u002Fmedium.com\u002F@ml.enesguler\"},\"creator\":{\"@context\":\"https:\u002F\u002Fschema.org\",\"@id\":\"https:\u002F\u002Fmedium.com\u002F@ml.enesguler\",\"@type\":\"Person\",\"identifier\":\"ml.enesguler\",\"name\":\"Enes Güler\",\"url\":\"https:\u002F\u002Fmedium.com\u002F@ml.enesguler\"},\"publisher\":{\"@context\":\"https:\u002F\u002Fschema.org\",\"@type\":\"Organization\",\"@id\":\"https:\u002F\u002Fmedium.com\",\"name\":\"Medium\",\"url\":\"https:\u002F\u002Fmedium.com\",\"logo\":{\"@type\":\"ImageObject\",\"width\":500,\"height\":110,\"url\":\"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:500\u002F7%2AV1_7XP4snlmqrc_0Njontw.png\"}},\"mainEntityOfPage\":\"https:\u002F\u002Fmedium.com\u002F@ml.enesguler\u002Fxgboost-basics-to-advanced-guide\",\"isAccessibleForFree\":true}"},"seoDescription":"Unlock the power of XGBoost, the leading gradient boosting algorithm. Learn its core principles, from decision trees to regularization, and implement it effectively in Python for superior model performance.","shortformType":"SHORTFORM_TYPE_LINK","firstPublishedAt":1758957924888,"viewerEdge":{"__ref":"PostViewerEdge:postId:d88536d87038-viewerId:lo_dc62f1b31c7a"},"seoTitle":"XGBoost Guide: From Basics to Advanced Optimization in Python ML","isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:xgboost"},{"__ref":"Tag:data-science"},{"__ref":"Tag:ai"},{"__ref":"Tag:supervised-learning"},{"__ref":"Tag:machine-learning"}],"isFeaturedInPublishedPublication":false,"isNewsletter":false,"statusForCollection":null,"pendingCollection":null,"detectedLanguage":"en","wordCount":3947}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":""},"cache":{"cacheStatus":"HIT"}}</script><script src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/manifest.3dde725d.js.Download"></script><script src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/5565.1c03f808.js.Download"></script><script src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/main.519835a5.js.Download"></script><script id="__LOADABLE_REQUIRED_CHUNKS__" type="application/json">[6183,2951,5052,628,6062,7566,3777,7908,3927,8640,9967,6372,4811,5429,1085,7381,9347,4929,6834,8441,7979,3877,7975,9256,8768,6509,4269,3666,1069,6026,258,5304,2698,3974,2527,2886,5258]</script>
<script id="__LOADABLE_REQUIRED_CHUNKS___ext" type="application/json">{"namedChunks":["instrumentation","reporting","PostPage.MainContent","PostResponsesContent","responses.editor"]}</script>
<script async="" data-chunk="instrumentation" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/instrumentation.434115b9.chunk.js.Download"></script>
<script async="" data-chunk="reporting" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/reporting.851fdaca.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/5052.eb638269.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/628.add32a62.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/6062.c3638afc.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/7566.14491814.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/3777.80666e51.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/7908.9ea3c3f3.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/3927.2f9f3eed.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/8640.9dfdf08f.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/9967.64a50867.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/6372.c6e20496.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/4811.10448dbf.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/5429.b7b13eac.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1085.b52082d9.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/7381.c53435ab.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/9347.1410edb1.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/4929.f2eb0b78.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/6834.6c66e3cc.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/8441.a82e4973.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/7979.35c5b2af.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/3877.769556c7.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/7975.3f8d607c.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/9256.c0f021df.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/8768.71979c5d.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/6509.774c7f97.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/4269.6f94ed97.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/3666.122df09d.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/1069.bbe95674.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/6026.904e1f2d.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/258.bb71743c.chunk.js.Download"></script>
<script async="" data-chunk="PostPage.MainContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/PostPage.MainContent.0353cbd8.chunk.js.Download"></script>
<script async="" data-chunk="PostResponsesContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/2698.9eecb474.chunk.js.Download"></script>
<script async="" data-chunk="PostResponsesContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/3974.82493a33.chunk.js.Download"></script>
<script async="" data-chunk="PostResponsesContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/2527.ed913434.chunk.js.Download"></script>
<script async="" data-chunk="PostResponsesContent" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/PostResponsesContent.d08ab001.chunk.js.Download"></script>
<script async="" data-chunk="responses.editor" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/responses.editor.9c1c2479.chunk.js.Download"></script><script>window.main();</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'9ba5f81df99ef968',t:'MTc2NzgxNTI3MC4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script><iframe height="1" width="1" style="position: absolute; top: 0px; left: 0px; border: none; visibility: hidden;" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/saved_resource(1).html"></iframe><script defer="" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/vcd15cbe7772f49c399c6a5babf22c1241717689176015" integrity="sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==" data-cf-beacon="{&quot;rayId&quot;:&quot;9ba5f81df99ef968&quot;,&quot;serverTiming&quot;:{&quot;name&quot;:{&quot;cfExtPri&quot;:true,&quot;cfEdge&quot;:true,&quot;cfOrigin&quot;:true,&quot;cfL4&quot;:true,&quot;cfSpeedBrain&quot;:true,&quot;cfCacheStatus&quot;:true}},&quot;version&quot;:&quot;2025.9.1&quot;,&quot;token&quot;:&quot;0b5f665943484354a59c39c6833f7078&quot;}" crossorigin="anonymous"></script>
<div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; display: block; transition: right 0.3s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" width="256" height="60" role="presentation" name="a-cwy6i51wjfw8" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/anchor.html"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;" src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/saved_resource(2).html"></iframe></div><div><div class="wo o yl ym ty yn yo yp yq yr ys yt yu yv yw co bq yx yy yz ln za zb"><div class="bg b ec ab ew"><div class="ac cw zc zd"><div class="m" role="alert">To make Medium work, we log user data. By using Medium, you agree to our <a class="ah ai aj fo al am an ao ap aq ar ze zf ru" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9" rel="noopener follow" target="_blank">Privacy Policy</a>, including cookie policy.</div><div class="zg oj zh zi zj zk m zl cb zm"><div class="m fr o zn"><button class="ah ai aj fo al am an ao ap aq ar ze zf zo zp ac" data-testid="close-button" aria-label="close"><svg xmlns="http://www.w3.org/2000/svg" width="19" height="19" viewBox="0 0 19 19" class="ex ew"><path fill-rule="evenodd" d="m13.792 4.6-4.29 4.29-4.29-4.29-.612.613 4.29 4.29-4.29 4.29.613.612 4.29-4.29 4.29 4.29.612-.613-4.29-4.29 4.29-4.29"></path></svg></button></div></div></div></div></div></div><script src="./XGBoost Guide_ From Basics to Advanced Optimization in Python ML _ Medium_files/client" async=""></script></body></html>